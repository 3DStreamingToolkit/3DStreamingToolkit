diff --git a/.gitignore b/.gitignore
index 90c43dfb82..cfd7b30678 100644
--- a/.gitignore
+++ b/.gitignore
@@ -43,6 +43,7 @@
 /ios
 /mojo
 /out
+/out-test
 /testing
 /third_party
 /tools
diff --git a/webrtc/api/video/video_frame.h b/webrtc/api/video/video_frame.h
index 3ee381b091..447d4b8b48 100644
--- a/webrtc/api/video/video_frame.h
+++ b/webrtc/api/video/video_frame.h
@@ -74,6 +74,12 @@ class VideoFrame {
   // TODO(nisse): Deprecated. Migrate all users to timestamp_us().
   int64_t ntp_time_ms() const { return ntp_time_ms_; }
 
+  // Set prediction timestamp in 100-nanosecond intervals.
+  void set_prediction_timestamp(int64_t prediction_timestamp) { prediction_timestamp_ = prediction_timestamp; }
+
+  // Get prediction timestamp in 100-nanosecond intervals.
+  int64_t prediction_timestamp() const { return prediction_timestamp_; }
+
   // Naming convention for Coordination of Video Orientation. Please see
   // http://www.etsi.org/deliver/etsi_ts/126100_126199/126114/12.07.00_60/ts_126114v120700p.pdf
   //
@@ -101,6 +107,12 @@ class VideoFrame {
     return video_frame_buffer()->type() == VideoFrameBuffer::Type::kNative;
   }
 
+  // Set OpenGL frame buffer.
+  void set_frame_buffer(uint8_t* frame_buffer) { frame_buffer_ = frame_buffer; }
+
+  // Get frame buffer.
+  uint8_t* frame_buffer() const { return frame_buffer_; }
+
  private:
   // An opaque reference counted handle that stores the pixel data.
   rtc::scoped_refptr<webrtc::VideoFrameBuffer> video_frame_buffer_;
@@ -108,6 +120,8 @@ class VideoFrame {
   int64_t ntp_time_ms_;
   int64_t timestamp_us_;
   VideoRotation rotation_;
+  uint8_t* frame_buffer_;
+  int64_t prediction_timestamp_;
 };
 
 }  // namespace webrtc
diff --git a/webrtc/common_types.h b/webrtc/common_types.h
index ac5c2e2e7b..c01bd9c03a 100644
--- a/webrtc/common_types.h
+++ b/webrtc/common_types.h
@@ -810,6 +810,7 @@ struct RTPHeaderExtension {
   // ts_126114v120700p.pdf
   bool hasVideoRotation;
   VideoRotation videoRotation;
+  int64_t prediction_timestamp;
 
   // TODO(ilnik): Refactor this and one above to be rtc::Optional() and remove
   // a corresponding bool flag.
diff --git a/webrtc/common_video/include/video_frame.h b/webrtc/common_video/include/video_frame.h
index 99e0b8f2a0..27a4e2cf86 100644
--- a/webrtc/common_video/include/video_frame.h
+++ b/webrtc/common_video/include/video_frame.h
@@ -58,6 +58,7 @@ class EncodedImage {
   bool _completeFrame = false;
   AdaptReason adapt_reason_;
   int qp_ = -1;  // Quantizer value.
+  int64_t prediction_timestamp_;
 
   // When an application indicates non-zero values here, it is taken as an
   // indication that all future frames will be constrained with those limits
diff --git a/webrtc/config.cc b/webrtc/config.cc
index 19a9a96079..b46b62c385 100644
--- a/webrtc/config.cc
+++ b/webrtc/config.cc
@@ -84,6 +84,9 @@ const char RtpExtension::kVideoTimingUri[] =
     "http://www.webrtc.org/experiments/rtp-hdrext/video-timing";
 const int RtpExtension::kVideoTimingDefaultId = 8;
 
+const char RtpExtension::kVideoFrameMetadataUri[] = "https://github.com/CatalystCode/3dtoolkit/blob/master/Libraries/WebRTC/VideoFrameMetadata.md";
+const int RtpExtension::kVideoFrameMetadataDefaultId = 9;
+
 const char RtpExtension::kEncryptHeaderExtensionsUri[] =
     "urn:ietf:params:rtp-hdrext:encrypt";
 
@@ -102,6 +105,7 @@ bool RtpExtension::IsSupportedForVideo(const std::string& uri) {
          uri == webrtc::RtpExtension::kTransportSequenceNumberUri ||
          uri == webrtc::RtpExtension::kPlayoutDelayUri ||
          uri == webrtc::RtpExtension::kVideoContentTypeUri ||
+         uri == webrtc::RtpExtension::kVideoFrameMetadataUri ||
          uri == webrtc::RtpExtension::kVideoTimingUri;
 }
 
diff --git a/webrtc/config.h b/webrtc/config.h
index 962e0f2fb9..ac7a739940 100644
--- a/webrtc/config.h
+++ b/webrtc/config.h
@@ -120,6 +120,10 @@ struct RtpExtension {
   static const char kPlayoutDelayUri[];
   static const int kPlayoutDelayDefaultId;
 
+  // Header extension for video frame metadata
+  static const char kVideoFrameMetadataUri[];
+  static const int kVideoFrameMetadataDefaultId;
+
   // Encryption of Header Extensions, see RFC 6904 for details:
   // https://tools.ietf.org/html/rfc6904
   static const char kEncryptHeaderExtensionsUri[];
diff --git a/webrtc/media/base/mediaconstants.cc b/webrtc/media/base/mediaconstants.cc
index 759c1834a5..abfa9d9444 100644
--- a/webrtc/media/base/mediaconstants.cc
+++ b/webrtc/media/base/mediaconstants.cc
@@ -108,6 +108,7 @@ const char kH264FmtpLevelAsymmetryAllowed[] = "level-asymmetry-allowed";
 const char kH264FmtpPacketizationMode[] = "packetization-mode";
 const char kH264FmtpSpropParameterSets[] = "sprop-parameter-sets";
 const char kH264ProfileLevelConstrainedBaseline[] = "42e01f";
+const char kH264UseHWNvencode[] = "use-hw-nvencode";
 
 const int kDefaultVideoMaxFramerate = 60;
 }  // namespace cricket
diff --git a/webrtc/media/base/mediaconstants.h b/webrtc/media/base/mediaconstants.h
index 44d8c7ee01..b5921982b5 100644
--- a/webrtc/media/base/mediaconstants.h
+++ b/webrtc/media/base/mediaconstants.h
@@ -130,6 +130,7 @@ extern const char kH264FmtpLevelAsymmetryAllowed[];
 extern const char kH264FmtpPacketizationMode[];
 extern const char kH264FmtpSpropParameterSets[];
 extern const char kH264ProfileLevelConstrainedBaseline[];
+extern const char kH264UseHWNvencode[];
 
 extern const int kDefaultVideoMaxFramerate;
 }  // namespace cricket
diff --git a/webrtc/media/engine/webrtcvideoengine.cc b/webrtc/media/engine/webrtcvideoengine.cc
index 2904bcbda1..577e901d91 100644
--- a/webrtc/media/engine/webrtcvideoengine.cc
+++ b/webrtc/media/engine/webrtcvideoengine.cc
@@ -361,6 +361,10 @@ RtpCapabilities WebRtcVideoEngine::GetCapabilities() const {
   capabilities.header_extensions.push_back(
         webrtc::RtpExtension(webrtc::RtpExtension::kVideoTimingUri,
                              webrtc::RtpExtension::kVideoTimingDefaultId));
+  capabilities.header_extensions.push_back(
+	  webrtc::RtpExtension(webrtc::RtpExtension::kVideoFrameMetadataUri,
+		  webrtc::RtpExtension::kVideoFrameMetadataDefaultId));
+
   return capabilities;
 }
 
@@ -420,7 +424,16 @@ static void AppendVideoCodecs(const std::vector<VideoCodec>& input_codecs,
     if (FindMatchingCodec(*unified_codecs, codec))
       continue;
 
-    unified_codecs->push_back(codec);
+	if (CodecNamesEq(codec.name, kH264CodecName))
+	{
+		auto it = unified_codecs->begin();
+		unified_codecs->insert(it, codec);
+	}
+	else
+	{
+		unified_codecs->push_back(codec);
+	}
+
 
     // Add associated RTX codec for recognized codecs.
     // TODO(deadbeef): Should we add RTX codecs for external codecs whose names
@@ -1131,6 +1144,10 @@ void WebRtcVideoChannel::ConfigureReceiverRtp(
 
   config->rtp.extensions = recv_rtp_extensions_;
 
+  // Enable video frame metadata extenstion.
+  config->rtp.extensions.push_back(webrtc::RtpExtension(
+	  webrtc::RtpExtension::kVideoFrameMetadataUri, webrtc::RtpExtension::kVideoFrameMetadataDefaultId));
+
   // TODO(brandtr): Generalize when we add support for multistream protection.
   flexfec_config->payload_type = recv_flexfec_payload_type_;
   if (IsFlexfecAdvertisedFieldTrialEnabled() &&
diff --git a/webrtc/modules/include/module_common_types.h b/webrtc/modules/include/module_common_types.h
index 1ee428deed..dca5974df1 100644
--- a/webrtc/modules/include/module_common_types.h
+++ b/webrtc/modules/include/module_common_types.h
@@ -56,6 +56,7 @@ struct RTPVideoHeader {
   uint16_t width;  // size
   uint16_t height;
   VideoRotation rotation;
+  int64_t prediction_timestamp;
 
   PlayoutDelay playout_delay;
 
diff --git a/webrtc/modules/rtp_rtcp/include/rtp_rtcp_defines.h b/webrtc/modules/rtp_rtcp/include/rtp_rtcp_defines.h
index 7d54ea4b24..c7b96f9bed 100644
--- a/webrtc/modules/rtp_rtcp/include/rtp_rtcp_defines.h
+++ b/webrtc/modules/rtp_rtcp/include/rtp_rtcp_defines.h
@@ -81,6 +81,7 @@ enum RTPExtensionType {
   kRtpExtensionRtpStreamId,
   kRtpExtensionRepairedRtpStreamId,
   kRtpExtensionMid,
+  kRtpExtensionVideoFrameMetadata,
   kRtpExtensionNumberOfExtensions  // Must be the last entity in the enum.
 };
 
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map.cc b/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map.cc
index d65b11d5cf..17cf78eddc 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map.cc
@@ -32,17 +32,18 @@ constexpr ExtensionInfo CreateExtensionInfo() {
 }
 
 constexpr ExtensionInfo kExtensions[] = {
-    CreateExtensionInfo<TransmissionOffset>(),
-    CreateExtensionInfo<AudioLevel>(),
-    CreateExtensionInfo<AbsoluteSendTime>(),
-    CreateExtensionInfo<VideoOrientation>(),
-    CreateExtensionInfo<TransportSequenceNumber>(),
-    CreateExtensionInfo<PlayoutDelayLimits>(),
-    CreateExtensionInfo<VideoContentTypeExtension>(),
-    CreateExtensionInfo<VideoTimingExtension>(),
-    CreateExtensionInfo<RtpStreamId>(),
-    CreateExtensionInfo<RepairedRtpStreamId>(),
-    CreateExtensionInfo<RtpMid>(),
+  CreateExtensionInfo<TransmissionOffset>(),
+  CreateExtensionInfo<AudioLevel>(),
+  CreateExtensionInfo<AbsoluteSendTime>(),
+  CreateExtensionInfo<VideoOrientation>(),
+  CreateExtensionInfo<TransportSequenceNumber>(),
+  CreateExtensionInfo<PlayoutDelayLimits>(),
+  CreateExtensionInfo<VideoContentTypeExtension>(),
+  CreateExtensionInfo<VideoTimingExtension>(),
+  CreateExtensionInfo<RtpStreamId>(),
+  CreateExtensionInfo<RepairedRtpStreamId>(),
+  CreateExtensionInfo<RtpMid>(),
+  CreateExtensionInfo<VideoFrameMetadata>()
 };
 
 // Because of kRtpExtensionNone, NumberOfExtension is 1 bigger than the actual
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map_unittest.cc b/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map_unittest.cc
index e5accb1bf4..b27d96e9ed 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map_unittest.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_header_extension_map_unittest.cc
@@ -29,6 +29,17 @@ TEST(RtpHeaderExtensionTest, RegisterByType) {
   EXPECT_EQ(TransmissionOffset::kId, map.GetType(3));
 }
 
+TEST(RtpHeaderExtensionTest, RegisterFrameByType) {
+	RtpHeaderExtensionMap map;
+	EXPECT_FALSE(map.IsRegistered(VideoFrameMetadata::kId));
+
+	EXPECT_TRUE(map.RegisterByType(12, VideoFrameMetadata::kId));
+
+	EXPECT_TRUE(map.IsRegistered(VideoFrameMetadata::kId));
+	EXPECT_EQ(7, map.GetId(VideoFrameMetadata::kId));
+	EXPECT_EQ(VideoFrameMetadata::kId, map.GetType(12));
+}
+
 TEST(RtpHeaderExtensionTest, RegisterByUri) {
   RtpHeaderExtensionMap map;
 
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.cc b/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.cc
index d409d5a619..fd885dc761 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.cc
@@ -180,6 +180,25 @@ bool VideoOrientation::Write(uint8_t* data, uint8_t value) {
   return true;
 }
 
+// Coordination of video frame metadata in RTP streams.
+//
+constexpr RTPExtensionType VideoFrameMetadata::kId;
+constexpr uint8_t VideoFrameMetadata::kValueSizeBytes;
+constexpr const char VideoFrameMetadata::kUri[];
+
+bool VideoFrameMetadata::Parse(rtc::ArrayView<const uint8_t> data, int64_t* value) {
+  if (data.size() != 8)
+    return false;
+  
+  *value = ByteReader<int64_t>::ReadBigEndian(data.data());
+  return true;
+}
+
+bool VideoFrameMetadata::Write(uint8_t* data, int64_t value) {
+  ByteWriter<int64_t>::WriteBigEndian(data, value);
+  return true;
+}
+
 //   0                   1                   2                   3
 //   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
 //  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.h b/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.h
index dc63140271..1c4880921d 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.h
+++ b/webrtc/modules/rtp_rtcp/source/rtp_header_extensions.h
@@ -90,6 +90,17 @@ class VideoOrientation {
   static bool Write(uint8_t* data, uint8_t value);
 };
 
+class VideoFrameMetadata {
+public:
+  static constexpr RTPExtensionType kId = kRtpExtensionVideoFrameMetadata;
+  static constexpr uint8_t kValueSizeBytes = 8;
+  static constexpr const char kUri[] = "https://github.com/CatalystCode/3dtoolkit/blob/master/Libraries/WebRTC/VideoFrameMetadata.md";
+
+  static bool Parse(rtc::ArrayView<const uint8_t> data, int64_t* value);
+  static size_t ValueSize(int64_t value) { return kValueSizeBytes; }
+  static bool Write(uint8_t* data, int64_t value);
+};
+
 class PlayoutDelayLimits {
  public:
   static constexpr RTPExtensionType kId = kRtpExtensionPlayoutDelay;
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_packet.cc b/webrtc/modules/rtp_rtcp/source/rtp_packet.cc
index 2c9d0aea5a..9ee2cdb040 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_packet.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_packet.cc
@@ -180,6 +180,7 @@ void Packet::GetHeader(RTPHeader* header) const {
   GetExtension<RepairedRtpStreamId>(&header->extension.repaired_stream_id);
   GetExtension<RtpMid>(&header->extension.mid);
   GetExtension<PlayoutDelayLimits>(&header->extension.playout_delay);
+  GetExtension<VideoFrameMetadata>(&header->extension.prediction_timestamp);
 }
 
 size_t Packet::headers_size() const {
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc b/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc
index 106f056075..3156ef1633 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_receiver_video.cc
@@ -112,6 +112,10 @@ int32_t RTPReceiverVideo::ParseRtpPacket(WebRtcRTPHeader* rtp_header,
   rtp_header->type.Video.playout_delay =
       rtp_header->header.extension.playout_delay;
 
+  // Retrieve the prediction timestamp.
+  rtp_header->type.Video.prediction_timestamp = 
+	    rtp_header->header.extension.prediction_timestamp;
+
   return data_callback_->OnReceivedPayloadData(parsed_payload.payload,
                                                parsed_payload.payload_length,
                                                rtp_header) == 0
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_rtcp_impl.cc b/webrtc/modules/rtp_rtcp/source/rtp_rtcp_impl.cc
index 790319a996..dd242a9cdc 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_rtcp_impl.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_rtcp_impl.cc
@@ -50,6 +50,8 @@ RTPExtensionType StringToRtpExtensionType(const std::string& extension) {
     return kRtpExtensionVideoContentType;
   if (extension == RtpExtension::kVideoTimingUri)
     return kRtpExtensionVideoTiming;
+  if (extension == RtpExtension::kVideoFrameMetadataUri)
+	  return kRtpExtensionVideoFrameMetadata;
   RTC_NOTREACHED() << "Looking up unsupported RTP extension.";
   return kRtpExtensionNone;
 }
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc b/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc
index 38450742be..d38e108d92 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_sender_video.cc
@@ -336,6 +336,9 @@ bool RTPSenderVideo::SendVideo(RtpVideoCodecTypes video_type,
         last_packet->SetExtension<VideoTimingExtension>(
             video_header->video_timing);
       }
+	  
+	  // Sets the prediction timestamp.
+	  last_packet->SetExtension<VideoFrameMetadata>(video_header->prediction_timestamp);
     }
 
     // FEC settings.
diff --git a/webrtc/modules/rtp_rtcp/source/rtp_utility.cc b/webrtc/modules/rtp_rtcp/source/rtp_utility.cc
index fbcf731393..8a321c32dc 100644
--- a/webrtc/modules/rtp_rtcp/source/rtp_utility.cc
+++ b/webrtc/modules/rtp_rtcp/source/rtp_utility.cc
@@ -482,6 +482,10 @@ void RtpHeaderParser::ParseOneByteExtensionHeader(
           header->extension.mid.Set(rtc::MakeArrayView(ptr, len + 1));
           break;
         }
+        case kRtpExtensionVideoFrameMetadata: {
+          header->extension.prediction_timestamp = ByteReader<int64_t>::ReadBigEndian(ptr);
+          break;
+        }
         case kRtpExtensionNone:
         case kRtpExtensionNumberOfExtensions: {
           RTC_NOTREACHED() << "Invalid extension type: " << type;
diff --git a/webrtc/modules/video_coding/BUILD.gn b/webrtc/modules/video_coding/BUILD.gn
index a93d7f7c11..771deba118 100644
--- a/webrtc/modules/video_coding/BUILD.gn
+++ b/webrtc/modules/video_coding/BUILD.gn
@@ -181,6 +181,10 @@ rtc_static_library("webrtc_h264") {
       "../../common_video",
       "../../media:rtc_media_base",
       "//third_party/ffmpeg:ffmpeg",
+      "../../rtc_base:rtc_base",
+      "../../rtc_base:rtc_base_approved",
+      "../../rtc_base:rtc_json",
+      "//third_party:nvpipe",
       "//third_party/openh264:encoder",
     ]
   }
@@ -618,6 +622,7 @@ if (rtc_include_tests) {
       "../../rtc_base:rtc_base",
       "../../rtc_base:rtc_base_approved",
       "../../rtc_base:rtc_task_queue",
+      "../../rtc_base:rtc_json",
       "../../system_wrappers:metrics_default",
       "../../system_wrappers:system_wrappers",
       "../../test:field_trial",
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.cc b/webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.cc
index 290df944bd..f6b6ccf771 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.cc
+++ b/webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.cc
@@ -356,6 +356,7 @@ int32_t H264DecoderImpl::Decode(const EncodedImage& input_image,
   RTC_CHECK_EQ(av_frame_->data[kUPlaneIndex], i420_buffer->DataU());
   RTC_CHECK_EQ(av_frame_->data[kVPlaneIndex], i420_buffer->DataV());
   video_frame->set_timestamp(input_image._timeStamp);
+  video_frame->set_prediction_timestamp(input_image.prediction_timestamp_);
 
   rtc::Optional<uint8_t> qp;
   // TODO(sakal): Maybe it is possible to get QP directly from FFmpeg.
@@ -381,6 +382,7 @@ int32_t H264DecoderImpl::Decode(const EncodedImage& input_image,
     VideoFrame cropped_frame(
         cropped_buf, video_frame->timestamp(), video_frame->render_time_ms(),
         video_frame->rotation());
+	  cropped_frame.set_prediction_timestamp(input_image.prediction_timestamp_);
     // TODO(nisse): Timestamp and rotation are all zero here. Change decoder
     // interface to pass a VideoFrameBuffer instead of a VideoFrame?
     decoded_image_callback_->Decoded(cropped_frame, rtc::Optional<int32_t>(),
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
index f5a1910984..fedf8c9956 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
+++ b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
@@ -10,6 +10,8 @@
  */
 
 #include "webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h"
+#include "webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.h"
+#include "webrtc/common_video/h264/h264_common.h"
 
 #include <limits>
 #include <string>
@@ -25,12 +27,20 @@
 #include "webrtc/rtc_base/timeutils.h"
 #include "webrtc/system_wrappers/include/metrics.h"
 
+#include <memory>
+#include <utility>
+#include <vector>
+#include <iostream>
+#include <fstream>
+
+using namespace std;
+
+#define __cu(a) do { CUresult  ret; if ((ret = (a)) != CUDA_SUCCESS) { fprintf(stderr, "%s has returned CUDA error %d\n", #a, ret); return NV_ENC_ERR_GENERIC;}} while(0)
+
 namespace webrtc {
 
 namespace {
 
-const bool kOpenH264EncoderDetailedLogging = false;
-
 // Used by histograms. Values of entries should not be changed.
 enum H264EncoderImplEvent {
   kH264EncoderEventInit = 0,
@@ -38,6 +48,8 @@ enum H264EncoderImplEvent {
   kH264EncoderEventMax = 16,
 };
 
+const bool kOpenH264EncoderDetailedLogging = false;
+
 int NumberOfThreads(int width, int height, int number_of_cores) {
   // TODO(hbos): In Chromium, multiple threads do not work with sandbox on Mac,
   // see crbug.com/583348. Until further investigated, only use one thread.
@@ -70,7 +82,6 @@ FrameType ConvertToVideoFrameType(EVideoFrameType type) {
   RTC_NOTREACHED() << "Unexpected/invalid frame type: " << type;
   return kEmptyFrame;
 }
-
 }  // namespace
 
 // Helper method used by H264EncoderImpl::Encode.
@@ -153,28 +164,41 @@ static void RtpFragmentize(EncodedImage* encoded_image,
 }
 
 H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
-    : openh264_encoder_(nullptr),
-      width_(0),
-      height_(0),
-      max_frame_rate_(0.0f),
-      target_bps_(0),
-      max_bps_(0),
-      mode_(kRealtimeVideo),
-      frame_dropping_on_(false),
-      key_frame_interval_(0),
-      packetization_mode_(H264PacketizationMode::SingleNalUnit),
-      max_payload_size_(0),
-      number_of_cores_(0),
-      encoded_image_callback_(nullptr),
-      has_reported_init_(false),
-      has_reported_error_(false) {
-  RTC_CHECK(cricket::CodecNamesEq(codec.name, cricket::kH264CodecName));
-  std::string packetization_mode_string;
-  if (codec.GetParam(cricket::kH264FmtpPacketizationMode,
-                     &packetization_mode_string) &&
-      packetization_mode_string == "1") {
-    packetization_mode_ = H264PacketizationMode::NonInterleaved;
-  }
+	:
+	encoder_(nullptr),
+	number_of_cores_(0),
+	width_(0),
+	height_(0),
+	max_frame_rate_(0.0f),
+	target_bps_(0),
+	max_bps_(0),
+	mode_(kRealtimeVideo),
+	frame_dropping_on_(false),
+	m_use_software_encoding(true),
+	m_first_frame_sent(false),
+	// Nv pipe
+	m_pNvPipeEncoder(NULL),
+	key_frame_interval_(0),
+	packetization_mode_(H264PacketizationMode::SingleNalUnit),
+	max_payload_size_(0),
+	encoded_image_callback_(nullptr),
+	last_prediction_timestamp_(0),
+	has_reported_init_(false),
+	has_reported_error_(false) {
+	RTC_CHECK(cricket::CodecNamesEq(codec.name, cricket::kH264CodecName));
+	std::string packetization_mode_string;
+	if (codec.GetParam(cricket::kH264FmtpPacketizationMode,
+		&packetization_mode_string) &&
+		packetization_mode_string == "1") {
+		packetization_mode_ = H264PacketizationMode::NonInterleaved;
+	}
+
+	int useNvencode;
+	if (codec.GetParam(cricket::kH264UseHWNvencode,
+		&useNvencode) &&
+		useNvencode == 1) {
+		m_use_software_encoding = false;
+	}
 }
 
 H264EncoderImpl::~H264EncoderImpl() {
@@ -182,98 +206,172 @@ H264EncoderImpl::~H264EncoderImpl() {
 }
 
 int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
-                                    int32_t number_of_cores,
-                                    size_t max_payload_size) {
-  ReportInit();
-  if (!codec_settings ||
-      codec_settings->codecType != kVideoCodecH264) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-  }
-  if (codec_settings->maxFramerate == 0) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-  }
-  if (codec_settings->width < 1 || codec_settings->height < 1) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-  }
-
-  int32_t release_ret = Release();
-  if (release_ret != WEBRTC_VIDEO_CODEC_OK) {
-    ReportError();
-    return release_ret;
-  }
-  RTC_DCHECK(!openh264_encoder_);
-
-  // Create encoder.
-  if (WelsCreateSVCEncoder(&openh264_encoder_) != 0) {
-    // Failed to create encoder.
-    LOG(LS_ERROR) << "Failed to create OpenH264 encoder";
-    RTC_DCHECK(!openh264_encoder_);
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERROR;
-  }
-  RTC_DCHECK(openh264_encoder_);
-  if (kOpenH264EncoderDetailedLogging) {
-    int trace_level = WELS_LOG_DETAIL;
-    openh264_encoder_->SetOption(ENCODER_OPTION_TRACE_LEVEL,
-                                 &trace_level);
-  }
-  // else WELS_LOG_DEFAULT is used by default.
-
-  number_of_cores_ = number_of_cores;
-  // Set internal settings from codec_settings
-  width_ = codec_settings->width;
-  height_ = codec_settings->height;
-  max_frame_rate_ = static_cast<float>(codec_settings->maxFramerate);
-  mode_ = codec_settings->mode;
-  frame_dropping_on_ = codec_settings->H264().frameDroppingOn;
-  key_frame_interval_ = codec_settings->H264().keyFrameInterval;
-  max_payload_size_ = max_payload_size;
-
-  // Codec_settings uses kbits/second; encoder uses bits/second.
-  max_bps_ = codec_settings->maxBitrate * 1000;
-  if (codec_settings->targetBitrate == 0)
-    target_bps_ = codec_settings->startBitrate * 1000;
-  else
-    target_bps_ = codec_settings->targetBitrate * 1000;
-
-  SEncParamExt encoder_params = CreateEncoderParams();
-
-  // Initialize.
-  if (openh264_encoder_->InitializeExt(&encoder_params) != 0) {
-    LOG(LS_ERROR) << "Failed to initialize OpenH264 encoder";
-    Release();
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERROR;
-  }
-  // TODO(pbos): Base init params on these values before submitting.
-  int video_format = EVideoFormatType::videoFormatI420;
-  openh264_encoder_->SetOption(ENCODER_OPTION_DATAFORMAT,
-                               &video_format);
-
-  // Initialize encoded image. Default buffer size: size of unencoded data.
-  encoded_image_._size = CalcBufferSize(VideoType::kI420, codec_settings->width,
-                                        codec_settings->height);
-  encoded_image_._buffer = new uint8_t[encoded_image_._size];
-  encoded_image_buffer_.reset(encoded_image_._buffer);
-  encoded_image_._completeFrame = true;
-  encoded_image_._encodedWidth = 0;
-  encoded_image_._encodedHeight = 0;
-  encoded_image_._length = 0;
-  return WEBRTC_VIDEO_CODEC_OK;
+	int32_t number_of_cores,
+	size_t max_payload_size) {
+	ReportInit();
+	if (!codec_settings ||
+		codec_settings->codecType != kVideoCodecH264) {
+		ReportError();
+		return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+	}
+	if (codec_settings->maxFramerate == 0) {
+		ReportError();
+		return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+	}
+	if (codec_settings->width < 1 || codec_settings->height < 1) {
+		ReportError();
+		return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+	}
+
+	Json::Reader reader;
+	Json::Value root = NULL;
+	auto encoderConfigPath = ExePath("nvEncConfig.json");
+	std::ifstream file(encoderConfigPath);
+	if (file.good())
+	{
+		file >> root;
+		reader.parse(file, root, true);
+	}
+
+	int32_t release_ret = Release();
+	if (release_ret != WEBRTC_VIDEO_CODEC_OK) {
+		ReportError();
+		return release_ret;
+	}
+	RTC_DCHECK(!encoder_);
+
+	// Check if we can use Nvencode
+	m_use_software_encoding = CheckDeviceNVENCCapability() != NV_ENC_SUCCESS;
+
+	if (!m_use_software_encoding)
+	{
+		memset(&m_encodeConfig, 0, sizeof(EncodeConfig));
+
+		GetDefaultNvencodeConfig(m_encodeConfig, root);
+		m_encodeConfig.width = codec_settings->width;
+		m_encodeConfig.height = codec_settings->height;
+
+		hGetProcIDDLL = LoadLibrary(L"Nvpipe.dll");
+		if (hGetProcIDDLL == NULL) {
+			// Failed to load Nvpipe dll.
+			LOG(LS_ERROR) << "Failed to load Nvpipe dll";
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+
+		create_nvpipe_encoder = (nvpipe_create_encoder)GetProcAddress(hGetProcIDDLL, "nvpipe_create_encoder");
+		destroy_nvpipe_encoder = (nvpipe_destroy)GetProcAddress(hGetProcIDDLL, "nvpipe_destroy");
+		encode_nvpipe = (nvpipe_encode)GetProcAddress(hGetProcIDDLL, "nvpipe_encode");
+		reconfigure_nvpipe = (nvpipe_bitrate)GetProcAddress(hGetProcIDDLL, "nvpipe_bitrate");
+		
+		if (!create_nvpipe_encoder || !destroy_nvpipe_encoder || !encode_nvpipe || !reconfigure_nvpipe) 
+		{
+			// Failed to load Nvpipe functions.
+			LOG(LS_ERROR) << "Failed to load Nvpipe functions";
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+
+		m_pNvPipeEncoder = create_nvpipe_encoder(NVPIPE_H264_NV, m_encodeConfig.bitrate, m_encodeConfig.fps, m_encodeConfig.idrPeriod, m_encodeConfig.intraRefreshPeriod, m_encodeConfig.intraRefreshEnableFlag);
+
+		if (m_pNvPipeEncoder)
+		{
+			bufferSize = m_encodeConfig.width * m_encodeConfig.height * 4;
+			pFrameBuffer = new uint8_t[bufferSize];
+		}
+		else
+		{
+			// Failed to create encoder.
+			LOG(LS_ERROR) << "Failed to create Nvncode encoder";
+			RTC_DCHECK(!m_pNvPipeEncoder);
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+	}
+
+	if (m_use_software_encoding)
+	{
+		//codec_settings
+		// Create encoder.
+		if (WelsCreateSVCEncoder(&encoder_) != 0) {
+			// Failed to create encoder.
+			LOG(LS_ERROR) << "Failed to create OpenH264 encoder";
+			RTC_DCHECK(!encoder_);
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+		RTC_DCHECK(encoder_);
+		if (kOpenH264EncoderDetailedLogging) {
+			int trace_level = WELS_LOG_DETAIL;
+			encoder_->SetOption(ENCODER_OPTION_TRACE_LEVEL,
+				&trace_level);
+		}
+		// else WELS_LOG_DEFAULT is used by default.
+		
+		number_of_cores_ = number_of_cores;
+		// Set internal settings from codec_settings
+		width_ = codec_settings->width;
+		height_ = codec_settings->height;
+		max_frame_rate_ = static_cast<float>(codec_settings->maxFramerate);
+		mode_ = codec_settings->mode;
+		frame_dropping_on_ = codec_settings->H264().frameDroppingOn;
+		key_frame_interval_ = codec_settings->H264().keyFrameInterval;
+		max_payload_size_ = max_payload_size;
+
+		// Codec_settings uses kbits/second; encoder uses bits/second.
+		max_bps_ = codec_settings->maxBitrate * 1000;
+		if (codec_settings->targetBitrate == 0)
+			target_bps_ = codec_settings->startBitrate * 1000;
+		else
+			target_bps_ = codec_settings->targetBitrate * 1000;
+
+		SEncParamExt encoder_params = CreateEncoderParams();
+
+		// Initialize.
+		if (encoder_->InitializeExt(&encoder_params) != 0) {
+			LOG(LS_ERROR) << "Failed to initialize OpenH264 encoder";
+			Release();
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+		// TODO(pbos): Base init params on these values before submitting.
+		int video_format = EVideoFormatType::videoFormatI420;
+		encoder_->SetOption(ENCODER_OPTION_DATAFORMAT,
+			&video_format);
+	}
+
+	// Initialize encoded image. Default buffer size: size of unencoded data.
+	encoded_image_._size =
+	  CalcBufferSize(kI420, codec_settings->width, codec_settings->height);
+	encoded_image_._buffer = new uint8_t[encoded_image_._size];
+	encoded_image_buffer_.reset(encoded_image_._buffer);
+	encoded_image_._completeFrame = true;
+	encoded_image_._encodedWidth = 0;
+	encoded_image_._encodedHeight = 0;
+	encoded_image_._length = 0;
+	return WEBRTC_VIDEO_CODEC_OK;
 }
 
 int32_t H264EncoderImpl::Release() {
-  if (openh264_encoder_) {
-    RTC_CHECK_EQ(0, openh264_encoder_->Uninitialize());
-    WelsDestroySVCEncoder(openh264_encoder_);
-    openh264_encoder_ = nullptr;
-  }
-  encoded_image_._buffer = nullptr;
-  encoded_image_buffer_.reset();
-  return WEBRTC_VIDEO_CODEC_OK;
+	if (encoder_) {
+		RTC_CHECK_EQ(0, encoder_->Uninitialize());
+		WelsDestroySVCEncoder(encoder_);
+		encoder_ = nullptr;
+	}
+
+	if (m_pNvPipeEncoder)
+	{
+		destroy_nvpipe_encoder(m_pNvPipeEncoder);
+		m_pNvPipeEncoder = nullptr;
+		FreeLibrary((HMODULE)hGetProcIDDLL);
+
+		delete[] pFrameBuffer;
+		pFrameBuffer = nullptr;
+	}
+
+	encoded_image_._buffer = nullptr;
+	encoded_image_buffer_.reset();
+	return WEBRTC_VIDEO_CODEC_OK;
 }
 
 int32_t H264EncoderImpl::RegisterEncodeCompleteCallback(
@@ -291,109 +389,282 @@ int32_t H264EncoderImpl::SetRateAllocation(
   target_bps_ = bitrate_allocation.get_sum_bps();
   max_frame_rate_ = static_cast<float>(framerate);
 
-  SBitrateInfo target_bitrate;
-  memset(&target_bitrate, 0, sizeof(SBitrateInfo));
-  target_bitrate.iLayer = SPATIAL_LAYER_ALL,
-  target_bitrate.iBitrate = target_bps_;
-  openh264_encoder_->SetOption(ENCODER_OPTION_BITRATE,
-                               &target_bitrate);
-  openh264_encoder_->SetOption(ENCODER_OPTION_FRAME_RATE, &max_frame_rate_);
+  if (m_use_software_encoding)
+  {
+	  SBitrateInfo target_bitrate;
+	  memset(&target_bitrate, 0, sizeof(SBitrateInfo));
+	  target_bitrate.iLayer = SPATIAL_LAYER_ALL,
+		  target_bitrate.iBitrate = target_bps_;
+
+	  encoder_->SetOption(ENCODER_OPTION_BITRATE,
+		  &target_bitrate);
+	  encoder_->SetOption(ENCODER_OPTION_FRAME_RATE, &max_frame_rate_);
+  }
+  else
+  {
+	  m_encodeConfig.fps = max_frame_rate_;
+
+	  if (m_pNvPipeEncoder != nullptr && m_encodeConfig.minBitrate < (int)target_bps_)
+	  {
+		  m_encodeConfig.bitrate = target_bps_;
+		  reconfigure_nvpipe(m_pNvPipeEncoder, m_encodeConfig.bitrate, max_frame_rate_);
+	  }
+  }
+
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
+void H264EncoderImpl::GetDefaultNvencodeConfig(EncodeConfig &nvEncodeConfig, Json::Value rootValue = NULL)
+{
+	//Populate with default values
+	{
+		nvEncodeConfig.bitrate = 7741440;
+		nvEncodeConfig.minBitrate = 3870720;
+		nvEncodeConfig.fps = 60;
+		nvEncodeConfig.idrPeriod = 60;
+		nvEncodeConfig.intraRefreshPeriod = 30;
+		nvEncodeConfig.intraRefreshEnableFlag = false;
+	}
+
+	if (rootValue != NULL && rootValue.isMember("serverFrameCaptureFPS")) {
+		nvEncodeConfig.fps = rootValue.get("serverFrameCaptureFPS", nvEncodeConfig.fps).asInt();
+	}
+
+	if (rootValue != NULL && rootValue.isMember("NvencodeSettings"))
+	{
+		auto nvencodeRoot = rootValue.get("NvencodeSettings", NULL);
+		if (nvencodeRoot == NULL)
+			return;
+
+		if (nvencodeRoot.isMember("bitrate"))
+		{
+			nvEncodeConfig.bitrate = nvencodeRoot.get("bitrate", nvEncodeConfig.bitrate).asInt();
+		}
+
+		if (nvencodeRoot.isMember("minBitrate"))
+		{
+			nvEncodeConfig.minBitrate = nvencodeRoot.get("minBitrate", nvEncodeConfig.minBitrate).asInt();
+		}
+
+		if (nvencodeRoot.isMember("intraRefreshEnableFlag"))
+		{
+			nvEncodeConfig.intraRefreshEnableFlag = nvencodeRoot.get("intraRefreshEnableFlag", nvEncodeConfig.intraRefreshEnableFlag).asBool();
+		}
+
+		if (nvencodeRoot.isMember("intraRefreshPeriod"))
+		{
+			nvEncodeConfig.intraRefreshPeriod = nvencodeRoot.get("intraRefreshPeriod", nvEncodeConfig.intraRefreshPeriod).asInt();
+		}
+
+		if (nvencodeRoot.isMember("idrPeriod"))
+		{
+			nvEncodeConfig.idrPeriod = nvencodeRoot.get("idrPeriod", nvEncodeConfig.idrPeriod).asInt();
+		}
+	}
+}
+
 int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
-                                const CodecSpecificInfo* codec_specific_info,
-                                const std::vector<FrameType>* frame_types) {
-  if (!IsInitialized()) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
-  }
-  if (!encoded_image_callback_) {
-    LOG(LS_WARNING) << "InitEncode() has been called, but a callback function "
-                    << "has not been set with RegisterEncodeCompleteCallback()";
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
-  }
+	const CodecSpecificInfo* codec_specific_info,
+	const std::vector<FrameType>* frame_types) {
+
+	rtc::scoped_refptr<const VideoFrameBuffer> frame_buffer = input_frame.video_frame_buffer();
+	SFrameBSInfo info;
+	RTPFragmentationHeader frag_header;
+
+	if (m_use_software_encoding && !IsInitialized())
+	{
+		ReportError();
+		return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+	}
+
+	if (!encoded_image_callback_) {
+		LOG(LS_WARNING) << "InitEncode() has been called, but a callback function "
+			<< "has not been set with RegisterEncodeCompleteCallback()";
+		ReportError();
+		return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+	}
+
+	bool force_key_frame = false;
+	if (frame_types != nullptr) {
+		// We only support a single stream.
+		RTC_DCHECK_EQ(frame_types->size(), 1);
+		// Skip frame?
+		if ((*frame_types)[0] == kEmptyFrame) {
+			return WEBRTC_VIDEO_CODEC_OK;
+		}
+		// Force key frame?
+		force_key_frame = (*frame_types)[0] == kVideoFrameKey;
+	}
+	if (force_key_frame) {
+		// API doc says ForceIntraFrame(false) does nothing, but calling this
+		// function forces a key frame regardless of the |bIDR| argument's value.
+		// (If every frame is a key frame we get lag/delays.)
+		if (m_use_software_encoding)
+		{
+			encoder_->ForceIntraFrame(true);
+		}
+	}
+
+	if (m_use_software_encoding)
+	{
+		// EncodeFrame input.
+		SSourcePicture picture;
+		memset(&picture, 0, sizeof(SSourcePicture));
+		picture.iPicWidth = frame_buffer->width();
+		picture.iPicHeight = frame_buffer->height();
+		picture.iColorFormat = EVideoFormatType::videoFormatI420;
+		picture.uiTimeStamp = input_frame.ntp_time_ms();
+		picture.iStride[0] = frame_buffer->GetI420()->StrideY();
+		picture.iStride[1] = frame_buffer->GetI420()->StrideU();
+		picture.iStride[2] = frame_buffer->GetI420()->StrideV();
+		picture.pData[0] = const_cast<uint8_t*>(frame_buffer->GetI420()->DataY());
+		picture.pData[1] = const_cast<uint8_t*>(frame_buffer->GetI420()->DataU());
+		picture.pData[2] = const_cast<uint8_t*>(frame_buffer->GetI420()->DataV());
+
+		// EncodeFrame output.
+		memset(&info, 0, sizeof(SFrameBSInfo));
+
+		// Encode!
+		int enc_ret = encoder_->EncodeFrame(&picture, &info);
+		if (enc_ret != 0) {
+			LOG(LS_ERROR) << "OpenH264 frame encoding failed, EncodeFrame returned "
+				<< enc_ret << ".";
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+
+		encoded_image_._frameType = ConvertToVideoFrameType(info.eFrameType);
+	}
+	else
+	{
+		uint8_t* serverSendBuffer = input_frame.frame_buffer();
+		size_t frameSizeInBytes = bufferSize;
+
+		if (!serverSendBuffer)
+		{
+			LOG(LS_ERROR) << "Encode failed: Input buffer is empty. ";
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+
+		nvp_err_t encodeStatus = encode_nvpipe(m_pNvPipeEncoder, serverSendBuffer, bufferSize, pFrameBuffer, &frameSizeInBytes, m_encodeConfig.width, m_encodeConfig.height, m_encodeConfig.fps, NVPIPE_RGBA);
+		if (encodeStatus != NVPIPE_SUCCESS)
+		{
+			LOG(LS_ERROR) << "Nvpipe encode frame failed: ";
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+
+		if (!m_first_frame_sent) m_first_frame_sent = true;
+
+		size_t i_nal = 0;
+		auto p_nal = (uint8_t*)pFrameBuffer;
+		std::vector<H264::NaluIndex> NALUidx;
+
+		NALUidx = H264::FindNaluIndices(p_nal, frameSizeInBytes);
+		if (NALUidx.size() < 1)
+			return WEBRTC_VIDEO_CODEC_OK;
+
+		i_nal = NALUidx.size();
+		if (i_nal == 1)
+		{
+			NALUidx[0].payload_size = frameSizeInBytes - NALUidx[0].payload_start_offset;
+		}
+		else for (size_t i = 0; i < i_nal; i++)
+		{
+			NALUidx[i].payload_size = i + 1 >= i_nal ? frameSizeInBytes - NALUidx[i].payload_start_offset : NALUidx[i + 1].start_offset - NALUidx[i].payload_start_offset;
+		}
+
+		frag_header.VerifyAndAllocateFragmentationHeader(i_nal);
+
+		uint32_t totalNaluIndex = 0;
+		for (size_t nal_index = 0; nal_index < i_nal; nal_index++)
+		{
+			size_t currentNaluSize = 0;
+			currentNaluSize = NALUidx[nal_index].payload_size; //i_frame_size
+
+			frag_header.fragmentationOffset[totalNaluIndex] = NALUidx[nal_index].payload_start_offset;
+			frag_header.fragmentationLength[totalNaluIndex] = currentNaluSize;
+			frag_header.fragmentationPlType[totalNaluIndex] = H264::ParseNaluType(p_nal[NALUidx[nal_index].payload_start_offset]);
+			frag_header.fragmentationTimeDiff[totalNaluIndex] = 0;
+			totalNaluIndex++;
+		}
+
+		memcpy(encoded_image_._buffer, p_nal, frameSizeInBytes);
+		encoded_image_._length = frameSizeInBytes;
+		encoded_image_.qp_ = 5;
+	}
+
+	encoded_image_._encodedWidth = frame_buffer->width();
+	encoded_image_._encodedHeight = frame_buffer->height();
+	encoded_image_._timeStamp = input_frame.timestamp();
+	encoded_image_.ntp_time_ms_ = input_frame.ntp_time_ms();
+	encoded_image_.capture_time_ms_ = input_frame.render_time_ms();
+	encoded_image_.rotation_ = input_frame.rotation();
+	encoded_image_.prediction_timestamp_ = last_prediction_timestamp_;
+	last_prediction_timestamp_ = input_frame.prediction_timestamp();
+
+	// Split encoded image up into fragments. This also updates |encoded_image_|.
+	if (m_use_software_encoding)
+	{
+		RtpFragmentize(&encoded_image_, &encoded_image_buffer_, *frame_buffer, &info,
+			&frag_header);
+	}
+
+	// Encoder can skip frames to save bandwidth in which case
+	// |encoded_image_._length| == 0.
+	if (encoded_image_._length > 0) {
+
+		// Deliver encoded image.
+		CodecSpecificInfo codec_specific;
+		codec_specific.codecType = kVideoCodecH264;
+		codec_specific.codecSpecific.H264.packetization_mode = H264PacketizationMode::NonInterleaved;
+		encoded_image_callback_->OnEncodedImage(encoded_image_, &codec_specific,
+			&frag_header);
+	}
+	return WEBRTC_VIDEO_CODEC_OK;
+}
 
-  bool force_key_frame = false;
-  if (frame_types != nullptr) {
-    // We only support a single stream.
-    RTC_DCHECK_EQ(frame_types->size(), 1);
-    // Skip frame?
-    if ((*frame_types)[0] == kEmptyFrame) {
-      return WEBRTC_VIDEO_CODEC_OK;
-    }
-    // Force key frame?
-    force_key_frame = (*frame_types)[0] == kVideoFrameKey;
-  }
-  if (force_key_frame) {
-    // API doc says ForceIntraFrame(false) does nothing, but calling this
-    // function forces a key frame regardless of the |bIDR| argument's value.
-    // (If every frame is a key frame we get lag/delays.)
-    openh264_encoder_->ForceIntraFrame(true);
-  }
-  rtc::scoped_refptr<const I420BufferInterface> frame_buffer =
-      input_frame.video_frame_buffer()->ToI420();
-  // EncodeFrame input.
-  SSourcePicture picture;
-  memset(&picture, 0, sizeof(SSourcePicture));
-  picture.iPicWidth = frame_buffer->width();
-  picture.iPicHeight = frame_buffer->height();
-  picture.iColorFormat = EVideoFormatType::videoFormatI420;
-  picture.uiTimeStamp = input_frame.ntp_time_ms();
-  picture.iStride[0] = frame_buffer->StrideY();
-  picture.iStride[1] = frame_buffer->StrideU();
-  picture.iStride[2] = frame_buffer->StrideV();
-  picture.pData[0] = const_cast<uint8_t*>(frame_buffer->DataY());
-  picture.pData[1] = const_cast<uint8_t*>(frame_buffer->DataU());
-  picture.pData[2] = const_cast<uint8_t*>(frame_buffer->DataV());
-
-  // EncodeFrame output.
-  SFrameBSInfo info;
-  memset(&info, 0, sizeof(SFrameBSInfo));
-
-  // Encode!
-  int enc_ret = openh264_encoder_->EncodeFrame(&picture, &info);
-  if (enc_ret != 0) {
-    LOG(LS_ERROR) << "OpenH264 frame encoding failed, EncodeFrame returned "
-                  << enc_ret << ".";
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERROR;
-  }
 
-  encoded_image_._encodedWidth = frame_buffer->width();
-  encoded_image_._encodedHeight = frame_buffer->height();
-  encoded_image_._timeStamp = input_frame.timestamp();
-  encoded_image_.ntp_time_ms_ = input_frame.ntp_time_ms();
-  encoded_image_.capture_time_ms_ = input_frame.render_time_ms();
-  encoded_image_.rotation_ = input_frame.rotation();
-  encoded_image_.content_type_ = (mode_ == kScreensharing)
-                                     ? VideoContentType::SCREENSHARE
-                                     : VideoContentType::UNSPECIFIED;
-  encoded_image_.timing_.flags = TimingFrameFlags::kInvalid;
-  encoded_image_._frameType = ConvertToVideoFrameType(info.eFrameType);
-
-  // Split encoded image up into fragments. This also updates |encoded_image_|.
-  RTPFragmentationHeader frag_header;
-  RtpFragmentize(&encoded_image_, &encoded_image_buffer_, *frame_buffer, &info,
-                 &frag_header);
-
-  // Encoder can skip frames to save bandwidth in which case
-  // |encoded_image_._length| == 0.
-  if (encoded_image_._length > 0) {
-    // Parse QP.
-    h264_bitstream_parser_.ParseBitstream(encoded_image_._buffer,
-                                          encoded_image_._length);
-    h264_bitstream_parser_.GetLastSliceQp(&encoded_image_.qp_);
-
-    // Deliver encoded image.
-    CodecSpecificInfo codec_specific;
-    codec_specific.codecType = kVideoCodecH264;
-    codec_specific.codecSpecific.H264.packetization_mode = packetization_mode_;
-    encoded_image_callback_->OnEncodedImage(encoded_image_, &codec_specific,
-                                            &frag_header);
-  }
-  return WEBRTC_VIDEO_CODEC_OK;
+NVENCSTATUS H264EncoderImpl::CheckDeviceNVENCCapability()
+{
+	auto nvpipe = LoadLibrary(L"Nvpipe.dll");
+	if (nvpipe == NULL) {
+		return NV_ENC_ERR_NO_ENCODE_DEVICE;
+	}
+
+	int deviceID = 0;
+	CUdevice cuDevice = 0;
+	int deviceCount = 0;
+	int SMminor = 0;
+	int SMmajor = 0;
+
+#if defined(WIN32) || defined(_WIN32) || defined(WIN64) || defined(_WIN64)
+	typedef HMODULE CUDADRIVER;
+#else
+	typedef void *CUDADRIVER;
+#endif
+	CUDADRIVER hHandleDriver = 0;
+
+	// CUDA interfaces
+	__cu(cuInit(0, __CUDA_API_VERSION, hHandleDriver));
+
+	__cu(cuDeviceGetCount(&deviceCount));
+	if (deviceCount == 0)
+	{
+		return NV_ENC_ERR_NO_ENCODE_DEVICE;
+	}
+
+	// Now we get the actual device
+	__cu(cuDeviceGet(&cuDevice, deviceID));
+
+	__cu(cuDeviceComputeCapability(&SMmajor, &SMminor, deviceID));
+	if (((SMmajor << 4) + SMminor) < 0x30)
+	{
+		return NV_ENC_ERR_NO_ENCODE_DEVICE;
+	}
+
+	return NV_ENC_SUCCESS;
 }
 
 const char* H264EncoderImpl::ImplementationName() const {
@@ -401,7 +672,7 @@ const char* H264EncoderImpl::ImplementationName() const {
 }
 
 bool H264EncoderImpl::IsInitialized() const {
-  return openh264_encoder_ != nullptr;
+	return encoder_ != nullptr;
 }
 
 // Initialization parameters.
@@ -410,9 +681,9 @@ bool H264EncoderImpl::IsInitialized() const {
 // which is a superset of SEncParamBase (cleared with GetDefaultParams) used
 // in InitializeExt.
 SEncParamExt H264EncoderImpl::CreateEncoderParams() const {
-  RTC_DCHECK(openh264_encoder_);
+  RTC_DCHECK(encoder_);
   SEncParamExt encoder_params;
-  openh264_encoder_->GetDefaultParams(&encoder_params);
+  encoder_->GetDefaultParams(&encoder_params);
   if (mode_ == kRealtimeVideo) {
     encoder_params.iUsageType = CAMERA_VIDEO_REAL_TIME;
   } else if (mode_ == kScreensharing) {
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
index a455259bf2..cd144f8ceb 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
+++ b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
@@ -19,85 +19,120 @@
 #include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
 #include "webrtc/modules/video_coding/utility/quality_scaler.h"
 
+#include "webrtc/modules/video_coding/utility/quality_scaler.h"
+#include "webrtc/rtc_base/json.h"
 #include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
 
+#include "third_party/nvpipe/nvEncodeAPI.h"
+#include "third_party/nvpipe/dynlink_cuda.h"
+#include "third_party/nvpipe/nvpipe.h"
+
 class ISVCEncoder;
 
 namespace webrtc {
 
-class H264EncoderImpl : public H264Encoder {
- public:
-  explicit H264EncoderImpl(const cricket::VideoCodec& codec);
-  ~H264EncoderImpl() override;
-
-  // |max_payload_size| is ignored.
-  // The following members of |codec_settings| are used. The rest are ignored.
-  // - codecType (must be kVideoCodecH264)
-  // - targetBitrate
-  // - maxFramerate
-  // - width
-  // - height
-  int32_t InitEncode(const VideoCodec* codec_settings,
-                     int32_t number_of_cores,
-                     size_t max_payload_size) override;
-  int32_t Release() override;
-
-  int32_t RegisterEncodeCompleteCallback(
-      EncodedImageCallback* callback) override;
-  int32_t SetRateAllocation(const BitrateAllocation& bitrate_allocation,
-                            uint32_t framerate) override;
-
-  // The result of encoding - an EncodedImage and RTPFragmentationHeader - are
-  // passed to the encode complete callback.
-  int32_t Encode(const VideoFrame& frame,
-                 const CodecSpecificInfo* codec_specific_info,
-                 const std::vector<FrameType>* frame_types) override;
-
-  const char* ImplementationName() const override;
-
-  VideoEncoder::ScalingSettings GetScalingSettings() const override;
-
-  // Unsupported / Do nothing.
-  int32_t SetChannelParameters(uint32_t packet_loss, int64_t rtt) override;
-  int32_t SetPeriodicKeyFrames(bool enable) override;
-
-  // Exposed for testing.
-  H264PacketizationMode PacketizationModeForTesting() const {
-    return packetization_mode_;
-  }
-
- private:
-  bool IsInitialized() const;
-  SEncParamExt CreateEncoderParams() const;
-
-  webrtc::H264BitstreamParser h264_bitstream_parser_;
-  // Reports statistics with histograms.
-  void ReportInit();
-  void ReportError();
-
-  ISVCEncoder* openh264_encoder_;
-  // Settings that are used by this encoder.
-  int width_;
-  int height_;
-  float max_frame_rate_;
-  uint32_t target_bps_;
-  uint32_t max_bps_;
-  VideoCodecMode mode_;
-  // H.264 specifc parameters
-  bool frame_dropping_on_;
-  int key_frame_interval_;
-  H264PacketizationMode packetization_mode_;
-
-  size_t max_payload_size_;
-  int32_t number_of_cores_;
-
-  EncodedImage encoded_image_;
-  std::unique_ptr<uint8_t[]> encoded_image_buffer_;
-  EncodedImageCallback* encoded_image_callback_;
-
-  bool has_reported_init_;
-  bool has_reported_error_;
-};
+	static std::string ExePath(std::string fileName = "") {
+		TCHAR buffer[MAX_PATH];
+		GetModuleFileName(NULL, buffer, MAX_PATH);
+		char charPath[MAX_PATH];
+		wcstombs(charPath, buffer, wcslen(buffer) + 1);
+
+		std::string::size_type pos = std::string(charPath).find_last_of("\\/");
+		return std::string(charPath).substr(0, pos + 1) + fileName;
+	}
+
+	class H264EncoderImpl : public H264Encoder {
+	public:
+		explicit H264EncoderImpl(const cricket::VideoCodec& codec);
+		~H264EncoderImpl() override;
+
+		// |max_payload_size| is ignored.
+		// The following members of |codec_settings| are used. The rest are ignored.
+		// - codecType (must be kVideoCodecH264)
+		// - targetBitrate
+		// - maxFramerate
+		// - width
+		// - height
+		int32_t InitEncode(const VideoCodec* codec_settings,
+			int32_t number_of_cores,
+			size_t max_payload_size) override;
+		int32_t Release() override;
+
+		int32_t RegisterEncodeCompleteCallback(
+			EncodedImageCallback* callback) override;
+		int32_t SetRateAllocation(const BitrateAllocation& bitrate_allocation,
+			uint32_t framerate) override;
+
+		// The result of encoding - an EncodedImage and RTPFragmentationHeader - are
+		// passed to the encode complete callback.
+		int32_t Encode(const VideoFrame& frame,
+			const CodecSpecificInfo* codec_specific_info,
+			const std::vector<FrameType>* frame_types) override;
+
+		const char* ImplementationName() const override;
+
+		VideoEncoder::ScalingSettings GetScalingSettings() const override;
+		static NVENCSTATUS CheckDeviceNVENCCapability();
+
+		// Unsupported / Do nothing.
+		int32_t SetChannelParameters(uint32_t packet_loss, int64_t rtt) override;
+		int32_t SetPeriodicKeyFrames(bool enable) override;
+
+		// Exposed for testing.
+		H264PacketizationMode PacketizationModeForTesting() const {
+			return packetization_mode_;
+		}
+
+	private:
+		bool IsInitialized() const;
+		SEncParamExt CreateEncoderParams() const;
+		void GetDefaultNvencodeConfig(EncodeConfig &nvEncodeConfig, Json::Value rootValue);
+
+		webrtc::H264BitstreamParser h264_bitstream_parser_;
+		// Reports statistics with histograms.
+		void ReportInit();
+		void ReportError();
+
+		//Hw encoder
+		EncodeConfig				m_encodeConfig;
+
+		// Nv pipe
+		HINSTANCE hGetProcIDDLL;
+		nvpipe* m_pNvPipeEncoder;
+		uint8_t* pFrameBuffer;
+		size_t bufferSize;
+		nvpipe_create_encoder create_nvpipe_encoder;
+		nvpipe_destroy destroy_nvpipe_encoder;
+		nvpipe_encode encode_nvpipe;
+		nvpipe_bitrate reconfigure_nvpipe;
+
+		ISVCEncoder* encoder_;
+		// Settings that are used by this encoder.
+		int width_;
+		int height_;
+		float max_frame_rate_;
+		uint32_t target_bps_;
+		uint32_t max_bps_;
+		VideoCodecMode mode_;
+		// H.264 specifc parameters
+		bool frame_dropping_on_;
+		int key_frame_interval_;
+		H264PacketizationMode packetization_mode_;
+
+		size_t max_payload_size_;
+		int32_t number_of_cores_;
+
+		bool m_use_software_encoding;
+		bool m_first_frame_sent;
+
+		EncodedImage encoded_image_;
+		std::unique_ptr<uint8_t[]> encoded_image_buffer_;
+		EncodedImageCallback* encoded_image_callback_;
+		int64_t last_prediction_timestamp_;
+
+		bool has_reported_init_;
+		bool has_reported_error_;
+	};
 
 }  // namespace webrtc
 
diff --git a/webrtc/modules/video_coding/codecs/vp8/vp8_impl.cc b/webrtc/modules/video_coding/codecs/vp8/vp8_impl.cc
index 3bf85d57e1..7d6e69f346 100644
--- a/webrtc/modules/video_coding/codecs/vp8/vp8_impl.cc
+++ b/webrtc/modules/video_coding/codecs/vp8/vp8_impl.cc
@@ -1174,7 +1174,7 @@ int VP8DecoderImpl::Decode(const EncodedImage& input_image,
   vpx_codec_err_t vpx_ret =
       vpx_codec_control(decoder_, VPXD_GET_LAST_QUANTIZER, &qp);
   RTC_DCHECK_EQ(vpx_ret, VPX_CODEC_OK);
-  ret = ReturnFrame(img, input_image._timeStamp, input_image.ntp_time_ms_, qp);
+  ret = ReturnFrame(img, input_image._timeStamp, input_image.ntp_time_ms_, input_image.prediction_timestamp_, qp);
   if (ret != 0) {
     // Reset to avoid requesting key frames too often.
     if (ret < 0 && propagation_cnt_ > 0)
@@ -1193,6 +1193,7 @@ int VP8DecoderImpl::Decode(const EncodedImage& input_image,
 int VP8DecoderImpl::ReturnFrame(const vpx_image_t* img,
                                 uint32_t timestamp,
                                 int64_t ntp_time_ms,
+                                int64_t prediction_timestamp,
                                 int qp) {
   if (img == NULL) {
     // Decoder OK and NULL image => No show frame
@@ -1227,6 +1228,7 @@ int VP8DecoderImpl::ReturnFrame(const vpx_image_t* img,
 
   VideoFrame decoded_image(buffer, timestamp, 0, kVideoRotation_0);
   decoded_image.set_ntp_time_ms(ntp_time_ms);
+  decoded_image.set_prediction_timestamp(prediction_timestamp);
   decode_complete_callback_->Decoded(decoded_image, rtc::Optional<int32_t>(),
                                      rtc::Optional<uint8_t>(qp));
 
diff --git a/webrtc/modules/video_coding/codecs/vp8/vp8_impl.h b/webrtc/modules/video_coding/codecs/vp8/vp8_impl.h
index 30a4a1a642..e6d0a697f2 100644
--- a/webrtc/modules/video_coding/codecs/vp8/vp8_impl.h
+++ b/webrtc/modules/video_coding/codecs/vp8/vp8_impl.h
@@ -147,6 +147,7 @@ class VP8DecoderImpl : public VP8Decoder {
   int ReturnFrame(const vpx_image_t* img,
                   uint32_t timeStamp,
                   int64_t ntp_time_ms,
+                  int64_t prediction_timestamp,
                   int qp);
 
   const bool use_postproc_arm_;
diff --git a/webrtc/modules/video_coding/frame_object.cc b/webrtc/modules/video_coding/frame_object.cc
index 86bcffb092..66da34febe 100644
--- a/webrtc/modules/video_coding/frame_object.cc
+++ b/webrtc/modules/video_coding/frame_object.cc
@@ -49,6 +49,7 @@ RtpFrameObject::RtpFrameObject(PacketBuffer* packet_buffer,
   _payloadType = first_packet->payloadType;
   _timeStamp = first_packet->timestamp;
   ntp_time_ms_ = first_packet->ntp_time_ms_;
+  prediction_timestamp_ = first_packet->video_header.prediction_timestamp;
 
   // Setting frame's playout delays to the same values
   // as of the first packet's.
@@ -114,6 +115,7 @@ RtpFrameObject::RtpFrameObject(PacketBuffer* packet_buffer,
   rotation_ = last_packet->video_header.rotation;
   _rotation_set = true;
   content_type_ = last_packet->video_header.content_type;
+  prediction_timestamp_ = last_packet->video_header.prediction_timestamp;
   if (last_packet->video_header.video_timing.flags !=
       TimingFrameFlags::kInvalid) {
     // ntp_time_ms_ may be -1 if not estimated yet. This is not a problem,
diff --git a/webrtc/modules/video_coding/video_sender.cc b/webrtc/modules/video_coding/video_sender.cc
index f60b6873fb..98a5dc19ce 100644
--- a/webrtc/modules/video_coding/video_sender.cc
+++ b/webrtc/modules/video_coding/video_sender.cc
@@ -316,6 +316,7 @@ int32_t VideoSender::AddVideoFrame(const VideoFrame& videoFrame,
   if (_encoder == nullptr)
     return VCM_UNINITIALIZED;
   SetEncoderParameters(encoder_params, encoder_has_internal_source);
+#if 0
   if (_mediaOpt.DropFrame()) {
     LOG(LS_VERBOSE) << "Drop Frame "
                     << "target bitrate "
@@ -326,6 +327,7 @@ int32_t VideoSender::AddVideoFrame(const VideoFrame& videoFrame,
     post_encode_callback_->OnDroppedFrame();
     return VCM_OK;
   }
+#endif
   // TODO(pbos): Make sure setting send codec is synchronized with video
   // processing so frame size always matches.
   if (!_codecDataBase.MatchesCurrentResolution(videoFrame.width(),
diff --git a/webrtc/video/payload_router.cc b/webrtc/video/payload_router.cc
index eabde400aa..a9822af3f0 100644
--- a/webrtc/video/payload_router.cc
+++ b/webrtc/video/payload_router.cc
@@ -146,6 +146,7 @@ EncodedImageCallback::Result PayloadRouter::OnEncodedImage(
   }
   rtp_video_header.video_timing.flags = encoded_image.timing_.flags;
   rtp_video_header.playout_delay = encoded_image.playout_delay_;
+  rtp_video_header.prediction_timestamp = encoded_image.prediction_timestamp_;
 
   int stream_index = rtp_video_header.simulcastIdx;
   RTC_DCHECK_LT(stream_index, rtp_modules_.size());
diff --git a/webrtc/video/rtp_video_stream_receiver.cc b/webrtc/video/rtp_video_stream_receiver.cc
index 4678b8f0af..e99fa1564f 100644
--- a/webrtc/video/rtp_video_stream_receiver.cc
+++ b/webrtc/video/rtp_video_stream_receiver.cc
@@ -136,7 +136,7 @@ RtpVideoStreamReceiver::RtpVideoStreamReceiver(
 
   for (size_t i = 0; i < config_.rtp.extensions.size(); ++i) {
     EnableReceiveRtpHeaderExtension(config_.rtp.extensions[i].uri,
-                                    config_.rtp.extensions[i].id);
+		config_.rtp.extensions[i].id);
   }
 
   static const int kMaxPacketAgeToNack = 450;
@@ -281,6 +281,8 @@ int32_t RtpVideoStreamReceiver::OnReceivedPayloadData(
     packet.dataPtr = data;
   }
 
+  packet.video_header.prediction_timestamp = rtp_header->header.extension.prediction_timestamp;
+
   packet_buffer_->InsertPacket(&packet);
   return 0;
 }
@@ -556,6 +558,7 @@ void RtpVideoStreamReceiver::NotifyReceiverOfFecPacket(
     rtp_header.type.Video.video_timing = header.extension.video_timing;
   }
   rtp_header.type.Video.playout_delay = header.extension.playout_delay;
+  rtp_header.type.Video.prediction_timestamp = header.extension.prediction_timestamp;
 
   OnReceivedPayloadData(nullptr, 0, &rtp_header);
 }
diff --git a/webrtc/video/video_loopback.cc b/webrtc/video/video_loopback.cc
index bf0060986c..d0127fbb52 100644
--- a/webrtc/video/video_loopback.cc
+++ b/webrtc/video/video_loopback.cc
@@ -72,7 +72,7 @@ int NumTemporalLayers() {
 }
 
 // Flags common with screenshare loopback, with equal default values.
-DEFINE_string(codec, "VP8", "Video codec to use.");
+DEFINE_string(codec, "H264", "Video codec to use.");
 std::string Codec() {
   return static_cast<std::string>(FLAG_codec);
 }
@@ -315,7 +315,7 @@ void Loopback() {
   }
 }
 }  // namespace webrtc
-
+#if 1
 int main(int argc, char* argv[]) {
   ::testing::InitGoogleTest(&argc, argv);
   rtc::FlagList::SetFlagsFromCommandLine(&argc, argv, true);
@@ -332,3 +332,4 @@ int main(int argc, char* argv[]) {
   webrtc::test::RunTest(webrtc::Loopback);
   return 0;
 }
+#endif
