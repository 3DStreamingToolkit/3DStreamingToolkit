diff --git a/webrtc/api/video/i420_buffer.cc b/webrtc/api/video/i420_buffer.cc
index 031b159..4fc4830 100644
--- a/webrtc/api/video/i420_buffer.cc
+++ b/webrtc/api/video/i420_buffer.cc
@@ -1,260 +1,275 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-#include "webrtc/api/video/i420_buffer.h"
-
-#include <string.h>
-
-#include <algorithm>
-#include <utility>
-
-#include "webrtc/base/checks.h"
-#include "webrtc/base/keep_ref_until_done.h"
-#include "libyuv/convert.h"
-#include "libyuv/planar_functions.h"
-#include "libyuv/scale.h"
-
-// Aligning pointer to 64 bytes for improved performance, e.g. use SIMD.
-static const int kBufferAlignment = 64;
-
-namespace webrtc {
-
-namespace {
-
-int I420DataSize(int height, int stride_y, int stride_u, int stride_v) {
-  return stride_y * height + (stride_u + stride_v) * ((height + 1) / 2);
-}
-
-}  // namespace
-
-I420Buffer::I420Buffer(int width, int height)
-    : I420Buffer(width, height, width, (width + 1) / 2, (width + 1) / 2) {
-}
-
-I420Buffer::I420Buffer(int width,
-                       int height,
-                       int stride_y,
-                       int stride_u,
-                       int stride_v)
-    : width_(width),
-      height_(height),
-      stride_y_(stride_y),
-      stride_u_(stride_u),
-      stride_v_(stride_v),
-      data_(static_cast<uint8_t*>(AlignedMalloc(
-          I420DataSize(height, stride_y, stride_u, stride_v),
-          kBufferAlignment))) {
-  RTC_DCHECK_GT(width, 0);
-  RTC_DCHECK_GT(height, 0);
-  RTC_DCHECK_GE(stride_y, width);
-  RTC_DCHECK_GE(stride_u, (width + 1) / 2);
-  RTC_DCHECK_GE(stride_v, (width + 1) / 2);
-}
-
-I420Buffer::~I420Buffer() {
-}
-
-// static
-rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width, int height) {
-  return new rtc::RefCountedObject<I420Buffer>(width, height);
-}
-
-// static
-rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width,
-                                                  int height,
-                                                  int stride_y,
-                                                  int stride_u,
-                                                  int stride_v) {
-  return new rtc::RefCountedObject<I420Buffer>(
-      width, height, stride_y, stride_u, stride_v);
-}
-
-// static
-rtc::scoped_refptr<I420Buffer> I420Buffer::Copy(
-    const VideoFrameBuffer& source) {
-  return Copy(source.width(), source.height(),
-              source.DataY(), source.StrideY(),
-              source.DataU(), source.StrideU(),
-              source.DataV(), source.StrideV());
-}
-
-// static
-rtc::scoped_refptr<I420Buffer> I420Buffer::Copy(
-      int width, int height,
-      const uint8_t* data_y, int stride_y,
-      const uint8_t* data_u, int stride_u,
-      const uint8_t* data_v, int stride_v) {
-  // Note: May use different strides than the input data.
-  rtc::scoped_refptr<I420Buffer> buffer = Create(width, height);
-  RTC_CHECK_EQ(0, libyuv::I420Copy(data_y, stride_y,
-                                   data_u, stride_u,
-                                   data_v, stride_v,
-                                   buffer->MutableDataY(), buffer->StrideY(),
-                                   buffer->MutableDataU(), buffer->StrideU(),
-                                   buffer->MutableDataV(), buffer->StrideV(),
-                                   width, height));
-  return buffer;
-}
-
-// static
-rtc::scoped_refptr<I420Buffer> I420Buffer::Rotate(
-    const VideoFrameBuffer& src, VideoRotation rotation) {
-  RTC_CHECK(src.DataY());
-  RTC_CHECK(src.DataU());
-  RTC_CHECK(src.DataV());
-
-  int rotated_width = src.width();
-  int rotated_height = src.height();
-  if (rotation == webrtc::kVideoRotation_90 ||
-      rotation == webrtc::kVideoRotation_270) {
-    std::swap(rotated_width, rotated_height);
-  }
-
-  rtc::scoped_refptr<webrtc::I420Buffer> buffer =
-      I420Buffer::Create(rotated_width, rotated_height);
-
-  RTC_CHECK_EQ(0, libyuv::I420Rotate(
-      src.DataY(), src.StrideY(),
-      src.DataU(), src.StrideU(),
-      src.DataV(), src.StrideV(),
-      buffer->MutableDataY(), buffer->StrideY(), buffer->MutableDataU(),
-      buffer->StrideU(), buffer->MutableDataV(), buffer->StrideV(),
-      src.width(), src.height(),
-      static_cast<libyuv::RotationMode>(rotation)));
-
-  return buffer;
-}
-
-// static
-rtc::scoped_refptr<VideoFrameBuffer> I420Buffer::Rotate(
-    rtc::scoped_refptr<VideoFrameBuffer> src,
-    VideoRotation rotation) {
-  if (rotation == webrtc::kVideoRotation_0) {
-    return src;
-  } else {
-    return Rotate(*src, rotation);
-  }
-}
-
-void I420Buffer::InitializeData() {
-  memset(data_.get(), 0,
-         I420DataSize(height_, stride_y_, stride_u_, stride_v_));
-}
-
-int I420Buffer::width() const {
-  return width_;
-}
-
-int I420Buffer::height() const {
-  return height_;
-}
-
-const uint8_t* I420Buffer::DataY() const {
-  return data_.get();
-}
-const uint8_t* I420Buffer::DataU() const {
-  return data_.get() + stride_y_ * height_;
-}
-const uint8_t* I420Buffer::DataV() const {
-  return data_.get() + stride_y_ * height_ + stride_u_ * ((height_ + 1) / 2);
-}
-
-int I420Buffer::StrideY() const {
-  return stride_y_;
-}
-int I420Buffer::StrideU() const {
-  return stride_u_;
-}
-int I420Buffer::StrideV() const {
-  return stride_v_;
-}
-
-void* I420Buffer::native_handle() const {
-  return nullptr;
-}
-
-rtc::scoped_refptr<VideoFrameBuffer> I420Buffer::NativeToI420Buffer() {
-  RTC_NOTREACHED();
-  return nullptr;
-}
-
-uint8_t* I420Buffer::MutableDataY() {
-  return const_cast<uint8_t*>(DataY());
-}
-uint8_t* I420Buffer::MutableDataU() {
-  return const_cast<uint8_t*>(DataU());
-}
-uint8_t* I420Buffer::MutableDataV() {
-  return const_cast<uint8_t*>(DataV());
-}
-
-// static
-void I420Buffer::SetBlack(I420Buffer* buffer) {
-  RTC_CHECK(libyuv::I420Rect(buffer->MutableDataY(), buffer->StrideY(),
-                             buffer->MutableDataU(), buffer->StrideU(),
-                             buffer->MutableDataV(), buffer->StrideV(),
-                             0, 0, buffer->width(), buffer->height(),
-                             0, 128, 128) == 0);
-}
-
-void I420Buffer::CropAndScaleFrom(
-    const VideoFrameBuffer& src,
-    int offset_x,
-    int offset_y,
-    int crop_width,
-    int crop_height) {
-  RTC_CHECK_LE(crop_width, src.width());
-  RTC_CHECK_LE(crop_height, src.height());
-  RTC_CHECK_LE(crop_width + offset_x, src.width());
-  RTC_CHECK_LE(crop_height + offset_y, src.height());
-  RTC_CHECK_GE(offset_x, 0);
-  RTC_CHECK_GE(offset_y, 0);
-
-  // Make sure offset is even so that u/v plane becomes aligned.
-  const int uv_offset_x = offset_x / 2;
-  const int uv_offset_y = offset_y / 2;
-  offset_x = uv_offset_x * 2;
-  offset_y = uv_offset_y * 2;
-
-  const uint8_t* y_plane =
-      src.DataY() + src.StrideY() * offset_y + offset_x;
-  const uint8_t* u_plane =
-      src.DataU() + src.StrideU() * uv_offset_y + uv_offset_x;
-  const uint8_t* v_plane =
-      src.DataV() + src.StrideV() * uv_offset_y + uv_offset_x;
-  int res = libyuv::I420Scale(y_plane, src.StrideY(),
-                              u_plane, src.StrideU(),
-                              v_plane, src.StrideV(),
-                              crop_width, crop_height,
-                              MutableDataY(), StrideY(),
-                              MutableDataU(), StrideU(),
-                              MutableDataV(), StrideV(),
-                              width(), height(), libyuv::kFilterBox);
-
-  RTC_DCHECK_EQ(res, 0);
-}
-
-void I420Buffer::CropAndScaleFrom(
-    const VideoFrameBuffer& src) {
-  const int crop_width =
-      std::min(src.width(), width() * src.height() / height());
-  const int crop_height =
-      std::min(src.height(), height() * src.width() / width());
-
-  CropAndScaleFrom(
-      src,
-      (src.width() - crop_width) / 2, (src.height() - crop_height) / 2,
-      crop_width, crop_height);
-}
-
-void I420Buffer::ScaleFrom(const VideoFrameBuffer& src) {
-  CropAndScaleFrom(src, 0, 0, src.width(), src.height());
-}
-
-}  // namespace webrtc
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "webrtc/api/video/i420_buffer.h"
+
+#include <string.h>
+
+#include <algorithm>
+#include <utility>
+
+#include "webrtc/base/checks.h"
+#include "webrtc/base/keep_ref_until_done.h"
+#include "libyuv/convert.h"
+#include "libyuv/planar_functions.h"
+#include "libyuv/scale.h"
+
+// Aligning pointer to 64 bytes for improved performance, e.g. use SIMD.
+static const int kBufferAlignment = 64;
+
+namespace webrtc {
+
+namespace {
+
+int I420DataSize(int height, int stride_y, int stride_u, int stride_v) {
+  return stride_y * height + (stride_u + stride_v) * ((height + 1) / 2);
+}
+
+}  // namespace
+
+I420Buffer::I420Buffer(int width, int height)
+    : I420Buffer(width, height, 0, width, (width + 1) / 2, (width + 1) / 2) {
+}
+
+I420Buffer::I420Buffer(int width, int height, int encoded_length)
+	: I420Buffer(width, height, encoded_length, width, (width + 1) / 2, (width + 1) / 2) {
+}
+
+
+I420Buffer::I420Buffer(int width,
+                       int height,
+					   int encoded_length,
+                       int stride_y,
+                       int stride_u,
+                       int stride_v)
+    : width_(width),
+      height_(height),
+	  encoded_length_(encoded_length),
+      stride_y_(stride_y),
+      stride_u_(stride_u),
+      stride_v_(stride_v),
+      data_(static_cast<uint8_t*>(AlignedMalloc(
+		  encoded_length > 0 ? encoded_length : I420DataSize(height, stride_y, stride_u, stride_v),
+          kBufferAlignment))) {
+  RTC_DCHECK_GT(width, 0);
+  RTC_DCHECK_GT(height, 0);
+  RTC_DCHECK_GE(stride_y, width);
+  RTC_DCHECK_GE(stride_u, (width + 1) / 2);
+  RTC_DCHECK_GE(stride_v, (width + 1) / 2);
+}
+
+I420Buffer::~I420Buffer() {
+}
+
+// static
+rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width, int height) {
+  return new rtc::RefCountedObject<I420Buffer>(width, height);
+}
+
+rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width, int height, int encoded_length) {
+	return new rtc::RefCountedObject<I420Buffer>(width, height, encoded_length);
+}
+
+// static
+rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width,
+                                                  int height,
+                                                  int stride_y,
+                                                  int stride_u,
+                                                  int stride_v) {
+  return new rtc::RefCountedObject<I420Buffer>(
+      width, height, 0, stride_y, stride_u, stride_v);
+}
+
+// static
+rtc::scoped_refptr<I420Buffer> I420Buffer::Copy(
+    const VideoFrameBuffer& source) {
+  return Copy(source.width(), source.height(),
+              source.DataY(), source.StrideY(),
+              source.DataU(), source.StrideU(),
+              source.DataV(), source.StrideV());
+}
+
+// static
+rtc::scoped_refptr<I420Buffer> I420Buffer::Copy(
+      int width, int height,
+      const uint8_t* data_y, int stride_y,
+      const uint8_t* data_u, int stride_u,
+      const uint8_t* data_v, int stride_v) {
+  // Note: May use different strides than the input data.
+  rtc::scoped_refptr<I420Buffer> buffer = Create(width, height);
+  RTC_CHECK_EQ(0, libyuv::I420Copy(data_y, stride_y,
+                                   data_u, stride_u,
+                                   data_v, stride_v,
+                                   buffer->MutableDataY(), buffer->StrideY(),
+                                   buffer->MutableDataU(), buffer->StrideU(),
+                                   buffer->MutableDataV(), buffer->StrideV(),
+                                   width, height));
+  return buffer;
+}
+
+// static
+rtc::scoped_refptr<I420Buffer> I420Buffer::Rotate(
+    const VideoFrameBuffer& src, VideoRotation rotation) {
+  RTC_CHECK(src.DataY());
+  RTC_CHECK(src.DataU());
+  RTC_CHECK(src.DataV());
+
+  int rotated_width = src.width();
+  int rotated_height = src.height();
+  if (rotation == webrtc::kVideoRotation_90 ||
+      rotation == webrtc::kVideoRotation_270) {
+    std::swap(rotated_width, rotated_height);
+  }
+
+  rtc::scoped_refptr<webrtc::I420Buffer> buffer =
+      I420Buffer::Create(rotated_width, rotated_height);
+
+  RTC_CHECK_EQ(0, libyuv::I420Rotate(
+      src.DataY(), src.StrideY(),
+      src.DataU(), src.StrideU(),
+      src.DataV(), src.StrideV(),
+      buffer->MutableDataY(), buffer->StrideY(), buffer->MutableDataU(),
+      buffer->StrideU(), buffer->MutableDataV(), buffer->StrideV(),
+      src.width(), src.height(),
+      static_cast<libyuv::RotationMode>(rotation)));
+
+  return buffer;
+}
+
+// static
+rtc::scoped_refptr<VideoFrameBuffer> I420Buffer::Rotate(
+    rtc::scoped_refptr<VideoFrameBuffer> src,
+    VideoRotation rotation) {
+  if (rotation == webrtc::kVideoRotation_0) {
+    return src;
+  } else {
+    return Rotate(*src, rotation);
+  }
+}
+
+void I420Buffer::InitializeData() {
+  memset(data_.get(), 0,
+         I420DataSize(height_, stride_y_, stride_u_, stride_v_));
+}
+
+int I420Buffer::width() const {
+  return width_;
+}
+
+int I420Buffer::height() const {
+  return height_;
+}
+
+int I420Buffer::encoded_length() const {
+	return encoded_length_;
+}
+
+const uint8_t* I420Buffer::DataY() const {
+  return data_.get();
+}
+const uint8_t* I420Buffer::DataU() const {
+  return data_.get() + stride_y_ * height_;
+}
+const uint8_t* I420Buffer::DataV() const {
+  return data_.get() + stride_y_ * height_ + stride_u_ * ((height_ + 1) / 2);
+}
+
+int I420Buffer::StrideY() const {
+  return stride_y_;
+}
+int I420Buffer::StrideU() const {
+  return stride_u_;
+}
+int I420Buffer::StrideV() const {
+  return stride_v_;
+}
+
+void* I420Buffer::native_handle() const {
+  return nullptr;
+}
+
+rtc::scoped_refptr<VideoFrameBuffer> I420Buffer::NativeToI420Buffer() {
+  RTC_NOTREACHED();
+  return nullptr;
+}
+
+uint8_t* I420Buffer::MutableDataY() {
+  return const_cast<uint8_t*>(DataY());
+}
+uint8_t* I420Buffer::MutableDataU() {
+  return const_cast<uint8_t*>(DataU());
+}
+uint8_t* I420Buffer::MutableDataV() {
+  return const_cast<uint8_t*>(DataV());
+}
+
+// static
+void I420Buffer::SetBlack(I420Buffer* buffer) {
+  RTC_CHECK(libyuv::I420Rect(buffer->MutableDataY(), buffer->StrideY(),
+                             buffer->MutableDataU(), buffer->StrideU(),
+                             buffer->MutableDataV(), buffer->StrideV(),
+                             0, 0, buffer->width(), buffer->height(),
+                             0, 128, 128) == 0);
+}
+
+void I420Buffer::CropAndScaleFrom(
+    const VideoFrameBuffer& src,
+    int offset_x,
+    int offset_y,
+    int crop_width,
+    int crop_height) {
+  RTC_CHECK_LE(crop_width, src.width());
+  RTC_CHECK_LE(crop_height, src.height());
+  RTC_CHECK_LE(crop_width + offset_x, src.width());
+  RTC_CHECK_LE(crop_height + offset_y, src.height());
+  RTC_CHECK_GE(offset_x, 0);
+  RTC_CHECK_GE(offset_y, 0);
+
+  // Make sure offset is even so that u/v plane becomes aligned.
+  const int uv_offset_x = offset_x / 2;
+  const int uv_offset_y = offset_y / 2;
+  offset_x = uv_offset_x * 2;
+  offset_y = uv_offset_y * 2;
+
+  const uint8_t* y_plane =
+      src.DataY() + src.StrideY() * offset_y + offset_x;
+  const uint8_t* u_plane =
+      src.DataU() + src.StrideU() * uv_offset_y + uv_offset_x;
+  const uint8_t* v_plane =
+      src.DataV() + src.StrideV() * uv_offset_y + uv_offset_x;
+  int res = libyuv::I420Scale(y_plane, src.StrideY(),
+                              u_plane, src.StrideU(),
+                              v_plane, src.StrideV(),
+                              crop_width, crop_height,
+                              MutableDataY(), StrideY(),
+                              MutableDataU(), StrideU(),
+                              MutableDataV(), StrideV(),
+                              width(), height(), libyuv::kFilterBox);
+
+  RTC_DCHECK_EQ(res, 0);
+}
+
+void I420Buffer::CropAndScaleFrom(
+    const VideoFrameBuffer& src) {
+  const int crop_width =
+      std::min(src.width(), width() * src.height() / height());
+  const int crop_height =
+      std::min(src.height(), height() * src.width() / width());
+
+  CropAndScaleFrom(
+      src,
+      (src.width() - crop_width) / 2, (src.height() - crop_height) / 2,
+      crop_width, crop_height);
+}
+
+void I420Buffer::ScaleFrom(const VideoFrameBuffer& src) {
+  CropAndScaleFrom(src, 0, 0, src.width(), src.height());
+}
+
+}  // namespace webrtc
diff --git a/webrtc/api/video/i420_buffer.h b/webrtc/api/video/i420_buffer.h
index 388a3dd..cc6fb8d 100644
--- a/webrtc/api/video/i420_buffer.h
+++ b/webrtc/api/video/i420_buffer.h
@@ -1,116 +1,120 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-
-#ifndef WEBRTC_API_VIDEO_I420_BUFFER_H_
-#define WEBRTC_API_VIDEO_I420_BUFFER_H_
-
-#include <memory>
-
-#include "webrtc/api/video/video_rotation.h"
-#include "webrtc/api/video/video_frame_buffer.h"
-#include "webrtc/system_wrappers/include/aligned_malloc.h"
-
-namespace webrtc {
-
-// Plain I420 buffer in standard memory.
-class I420Buffer : public VideoFrameBuffer {
- public:
-  static rtc::scoped_refptr<I420Buffer> Create(int width, int height);
-  static rtc::scoped_refptr<I420Buffer> Create(int width,
-                                               int height,
-                                               int stride_y,
-                                               int stride_u,
-                                               int stride_v);
-
-  // Create a new buffer and copy the pixel data.
-  static rtc::scoped_refptr<I420Buffer> Copy(const VideoFrameBuffer& buffer);
-
-  static rtc::scoped_refptr<I420Buffer> Copy(
-      int width, int height,
-      const uint8_t* data_y, int stride_y,
-      const uint8_t* data_u, int stride_u,
-      const uint8_t* data_v, int stride_v);
-
-  // Returns a rotated copy of |src|.
-  static rtc::scoped_refptr<I420Buffer> Rotate(const VideoFrameBuffer& src,
-                                               VideoRotation rotation);
-
-  // Sets the buffer to all black.
-  static void SetBlack(I420Buffer* buffer);
-
-  // Sets all three planes to all zeros. Used to work around for
-  // quirks in memory checkers
-  // (https://bugs.chromium.org/p/libyuv/issues/detail?id=377) and
-  // ffmpeg (http://crbug.com/390941).
-  // TODO(nisse): Deprecated. Should be deleted if/when those issues
-  // are resolved in a better way. Or in the mean time, use SetBlack.
-  void InitializeData();
-
-  // TODO(nisse): Deprecated, use static method instead.
-  void SetToBlack() { SetBlack(this); }
-
-  int width() const override;
-  int height() const override;
-  const uint8_t* DataY() const override;
-  const uint8_t* DataU() const override;
-  const uint8_t* DataV() const override;
-
-  int StrideY() const override;
-  int StrideU() const override;
-  int StrideV() const override;
-
-  void* native_handle() const override;
-  rtc::scoped_refptr<VideoFrameBuffer> NativeToI420Buffer() override;
-
-  uint8_t* MutableDataY();
-  uint8_t* MutableDataU();
-  uint8_t* MutableDataV();
-
-  // Scale the cropped area of |src| to the size of |this| buffer, and
-  // write the result into |this|.
-  void CropAndScaleFrom(const VideoFrameBuffer& src,
-                        int offset_x,
-                        int offset_y,
-                        int crop_width,
-                        int crop_height);
-
-  // The common case of a center crop, when needed to adjust the
-  // aspect ratio without distorting the image.
-  void CropAndScaleFrom(const VideoFrameBuffer& src);
-
-  // Scale all of |src| to the size of |this| buffer, with no cropping.
-  void ScaleFrom(const VideoFrameBuffer& src);
-
-  // TODO(nisse): Deprecated, delete once downstream applications are updated.
-  // Returns a rotated versions of |src|. Native buffers are not
-  // supported. The reason this function doesn't return an I420Buffer,
-  // is that it returns |src| unchanged in case |rotation| is zero.
-  static rtc::scoped_refptr<VideoFrameBuffer> Rotate(
-      rtc::scoped_refptr<VideoFrameBuffer> src,
-      VideoRotation rotation);
-
- protected:
-  I420Buffer(int width, int height);
-  I420Buffer(int width, int height, int stride_y, int stride_u, int stride_v);
-
-  ~I420Buffer() override;
-
- private:
-  const int width_;
-  const int height_;
-  const int stride_y_;
-  const int stride_u_;
-  const int stride_v_;
-  const std::unique_ptr<uint8_t, AlignedFreeDeleter> data_;
-};
-
-}  // namespace webrtc
-
-#endif  // WEBRTC_API_VIDEO_I420_BUFFER_H_
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef WEBRTC_API_VIDEO_I420_BUFFER_H_
+#define WEBRTC_API_VIDEO_I420_BUFFER_H_
+
+#include <memory>
+
+#include "webrtc/api/video/video_rotation.h"
+#include "webrtc/api/video/video_frame_buffer.h"
+#include "webrtc/system_wrappers/include/aligned_malloc.h"
+
+namespace webrtc {
+
+// Plain I420 buffer in standard memory.
+class I420Buffer : public VideoFrameBuffer {
+ public:
+  static rtc::scoped_refptr<I420Buffer> Create(int width, int height);
+  static rtc::scoped_refptr<I420Buffer> Create(int width, int height, int encoded_length);
+  static rtc::scoped_refptr<I420Buffer> Create(int width,
+                                               int height,
+                                               int stride_y,
+                                               int stride_u,
+                                               int stride_v);
+
+  // Create a new buffer and copy the pixel data.
+  static rtc::scoped_refptr<I420Buffer> Copy(const VideoFrameBuffer& buffer);
+
+  static rtc::scoped_refptr<I420Buffer> Copy(
+      int width, int height,
+      const uint8_t* data_y, int stride_y,
+      const uint8_t* data_u, int stride_u,
+      const uint8_t* data_v, int stride_v);
+
+  // Returns a rotated copy of |src|.
+  static rtc::scoped_refptr<I420Buffer> Rotate(const VideoFrameBuffer& src,
+                                               VideoRotation rotation);
+
+  // Sets the buffer to all black.
+  static void SetBlack(I420Buffer* buffer);
+
+  // Sets all three planes to all zeros. Used to work around for
+  // quirks in memory checkers
+  // (https://bugs.chromium.org/p/libyuv/issues/detail?id=377) and
+  // ffmpeg (http://crbug.com/390941).
+  // TODO(nisse): Deprecated. Should be deleted if/when those issues
+  // are resolved in a better way. Or in the mean time, use SetBlack.
+  void InitializeData();
+
+  // TODO(nisse): Deprecated, use static method instead.
+  void SetToBlack() { SetBlack(this); }
+
+  int width() const override;
+  int height() const override;
+  int encoded_length() const override;
+  const uint8_t* DataY() const override;
+  const uint8_t* DataU() const override;
+  const uint8_t* DataV() const override;
+
+  int StrideY() const override;
+  int StrideU() const override;
+  int StrideV() const override;
+
+  void* native_handle() const override;
+  rtc::scoped_refptr<VideoFrameBuffer> NativeToI420Buffer() override;
+
+  uint8_t* MutableDataY();
+  uint8_t* MutableDataU();
+  uint8_t* MutableDataV();
+
+  // Scale the cropped area of |src| to the size of |this| buffer, and
+  // write the result into |this|.
+  void CropAndScaleFrom(const VideoFrameBuffer& src,
+                        int offset_x,
+                        int offset_y,
+                        int crop_width,
+                        int crop_height);
+
+  // The common case of a center crop, when needed to adjust the
+  // aspect ratio without distorting the image.
+  void CropAndScaleFrom(const VideoFrameBuffer& src);
+
+  // Scale all of |src| to the size of |this| buffer, with no cropping.
+  void ScaleFrom(const VideoFrameBuffer& src);
+
+  // TODO(nisse): Deprecated, delete once downstream applications are updated.
+  // Returns a rotated versions of |src|. Native buffers are not
+  // supported. The reason this function doesn't return an I420Buffer,
+  // is that it returns |src| unchanged in case |rotation| is zero.
+  static rtc::scoped_refptr<VideoFrameBuffer> Rotate(
+      rtc::scoped_refptr<VideoFrameBuffer> src,
+      VideoRotation rotation);
+
+ protected:
+  I420Buffer(int width, int height);
+  I420Buffer(int width, int height, int encoded_length);
+  I420Buffer(int width, int height, int encoded_length, int stride_y, int stride_u, int stride_v);
+
+  ~I420Buffer() override;
+
+ private:
+  const int width_;
+  const int height_;
+  const int encoded_length_;
+  const int stride_y_;
+  const int stride_u_;
+  const int stride_v_;
+  const std::unique_ptr<uint8_t, AlignedFreeDeleter> data_;
+};
+
+}  // namespace webrtc
+
+#endif  // WEBRTC_API_VIDEO_I420_BUFFER_H_
diff --git a/webrtc/api/video/video_frame_buffer.h b/webrtc/api/video/video_frame_buffer.h
index c8c2e5d..39e2d72 100644
--- a/webrtc/api/video/video_frame_buffer.h
+++ b/webrtc/api/video/video_frame_buffer.h
@@ -1,55 +1,56 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-
-#ifndef WEBRTC_API_VIDEO_VIDEO_FRAME_BUFFER_H_
-#define WEBRTC_API_VIDEO_VIDEO_FRAME_BUFFER_H_
-
-#include <stdint.h>
-
-#include "webrtc/base/refcount.h"
-#include "webrtc/base/scoped_ref_ptr.h"
-
-namespace webrtc {
-
-// Interface of a simple frame buffer containing pixel data. This interface does
-// not contain any frame metadata such as rotation, timestamp, pixel_width, etc.
-class VideoFrameBuffer : public rtc::RefCountInterface {
- public:
-  // The resolution of the frame in pixels. For formats where some planes are
-  // subsampled, this is the highest-resolution plane.
-  virtual int width() const = 0;
-  virtual int height() const = 0;
-
-  // Returns pointer to the pixel data for a given plane. The memory is owned by
-  // the VideoFrameBuffer object and must not be freed by the caller.
-  virtual const uint8_t* DataY() const = 0;
-  virtual const uint8_t* DataU() const = 0;
-  virtual const uint8_t* DataV() const = 0;
-
-  // Returns the number of bytes between successive rows for a given plane.
-  virtual int StrideY() const = 0;
-  virtual int StrideU() const = 0;
-  virtual int StrideV() const = 0;
-
-  // Return the handle of the underlying video frame. This is used when the
-  // frame is backed by a texture.
-  virtual void* native_handle() const = 0;
-
-  // Returns a new memory-backed frame buffer converted from this buffer's
-  // native handle.
-  virtual rtc::scoped_refptr<VideoFrameBuffer> NativeToI420Buffer() = 0;
-
- protected:
-  ~VideoFrameBuffer() override {}
-};
-
-}  // namespace webrtc
-
-#endif  // WEBRTC_API_VIDEO_VIDEO_FRAME_BUFFER_H_
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef WEBRTC_API_VIDEO_VIDEO_FRAME_BUFFER_H_
+#define WEBRTC_API_VIDEO_VIDEO_FRAME_BUFFER_H_
+
+#include <stdint.h>
+
+#include "webrtc/base/refcount.h"
+#include "webrtc/base/scoped_ref_ptr.h"
+
+namespace webrtc {
+
+// Interface of a simple frame buffer containing pixel data. This interface does
+// not contain any frame metadata such as rotation, timestamp, pixel_width, etc.
+class VideoFrameBuffer : public rtc::RefCountInterface {
+ public:
+  // The resolution of the frame in pixels. For formats where some planes are
+  // subsampled, this is the highest-resolution plane.
+  virtual int width() const = 0;
+  virtual int height() const = 0;
+  virtual int encoded_length() const = 0;
+
+  // Returns pointer to the pixel data for a given plane. The memory is owned by
+  // the VideoFrameBuffer object and must not be freed by the caller.
+  virtual const uint8_t* DataY() const = 0;
+  virtual const uint8_t* DataU() const = 0;
+  virtual const uint8_t* DataV() const = 0;
+
+  // Returns the number of bytes between successive rows for a given plane.
+  virtual int StrideY() const = 0;
+  virtual int StrideU() const = 0;
+  virtual int StrideV() const = 0;
+
+  // Return the handle of the underlying video frame. This is used when the
+  // frame is backed by a texture.
+  virtual void* native_handle() const = 0;
+
+  // Returns a new memory-backed frame buffer converted from this buffer's
+  // native handle.
+  virtual rtc::scoped_refptr<VideoFrameBuffer> NativeToI420Buffer() = 0;
+
+ protected:
+  ~VideoFrameBuffer() override {}
+};
+
+}  // namespace webrtc
+
+#endif  // WEBRTC_API_VIDEO_VIDEO_FRAME_BUFFER_H_
diff --git a/webrtc/common_video/include/video_frame_buffer.h b/webrtc/common_video/include/video_frame_buffer.h
index dfdd480..f52bfc4 100644
--- a/webrtc/common_video/include/video_frame_buffer.h
+++ b/webrtc/common_video/include/video_frame_buffer.h
@@ -1,92 +1,94 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-
-#ifndef WEBRTC_COMMON_VIDEO_INCLUDE_VIDEO_FRAME_BUFFER_H_
-#define WEBRTC_COMMON_VIDEO_INCLUDE_VIDEO_FRAME_BUFFER_H_
-
-#include <memory>
-
-#include "webrtc/api/video/video_frame_buffer.h"
-// TODO(nisse): For backwards compatibility, files including this file
-// expect it to declare I420Buffer. Delete after callers are updated.
-#include "webrtc/api/video/i420_buffer.h"
-#include "webrtc/base/callback.h"
-#include "webrtc/base/scoped_ref_ptr.h"
-
-namespace webrtc {
-
-// Base class for native-handle buffer is a wrapper around a |native_handle|.
-// This is used for convenience as most native-handle implementations can share
-// many VideoFrame implementations, but need to implement a few others (such
-// as their own destructors or conversion methods back to software I420).
-class NativeHandleBuffer : public VideoFrameBuffer {
- public:
-  NativeHandleBuffer(void* native_handle, int width, int height);
-
-  int width() const override;
-  int height() const override;
-  const uint8_t* DataY() const override;
-  const uint8_t* DataU() const override;
-  const uint8_t* DataV() const override;
-  int StrideY() const override;
-  int StrideU() const override;
-  int StrideV() const override;
-
-  void* native_handle() const override;
-
- protected:
-  void* native_handle_;
-  const int width_;
-  const int height_;
-};
-
-class WrappedI420Buffer : public webrtc::VideoFrameBuffer {
- public:
-  WrappedI420Buffer(int width,
-                    int height,
-                    const uint8_t* y_plane,
-                    int y_stride,
-                    const uint8_t* u_plane,
-                    int u_stride,
-                    const uint8_t* v_plane,
-                    int v_stride,
-                    const rtc::Callback0<void>& no_longer_used);
-  int width() const override;
-  int height() const override;
-
-  const uint8_t* DataY() const override;
-  const uint8_t* DataU() const override;
-  const uint8_t* DataV() const override;
-  int StrideY() const override;
-  int StrideU() const override;
-  int StrideV() const override;
-
-  void* native_handle() const override;
-
-  rtc::scoped_refptr<VideoFrameBuffer> NativeToI420Buffer() override;
-
- private:
-  friend class rtc::RefCountedObject<WrappedI420Buffer>;
-  ~WrappedI420Buffer() override;
-
-  const int width_;
-  const int height_;
-  const uint8_t* const y_plane_;
-  const uint8_t* const u_plane_;
-  const uint8_t* const v_plane_;
-  const int y_stride_;
-  const int u_stride_;
-  const int v_stride_;
-  rtc::Callback0<void> no_longer_used_cb_;
-};
-
-}  // namespace webrtc
-
-#endif  // WEBRTC_COMMON_VIDEO_INCLUDE_VIDEO_FRAME_BUFFER_H_
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#ifndef WEBRTC_COMMON_VIDEO_INCLUDE_VIDEO_FRAME_BUFFER_H_
+#define WEBRTC_COMMON_VIDEO_INCLUDE_VIDEO_FRAME_BUFFER_H_
+
+#include <memory>
+
+#include "webrtc/api/video/video_frame_buffer.h"
+// TODO(nisse): For backwards compatibility, files including this file
+// expect it to declare I420Buffer. Delete after callers are updated.
+#include "webrtc/api/video/i420_buffer.h"
+#include "webrtc/base/callback.h"
+#include "webrtc/base/scoped_ref_ptr.h"
+
+namespace webrtc {
+
+// Base class for native-handle buffer is a wrapper around a |native_handle|.
+// This is used for convenience as most native-handle implementations can share
+// many VideoFrame implementations, but need to implement a few others (such
+// as their own destructors or conversion methods back to software I420).
+class NativeHandleBuffer : public VideoFrameBuffer {
+ public:
+  NativeHandleBuffer(void* native_handle, int width, int height);
+
+  int width() const override;
+  int height() const override;
+  const uint8_t* DataY() const override;
+  const uint8_t* DataU() const override;
+  const uint8_t* DataV() const override;
+  int StrideY() const override;
+  int StrideU() const override;
+  int StrideV() const override;
+
+  void* native_handle() const override;
+
+ protected:
+  void* native_handle_;
+  const int width_;
+  const int height_;
+};
+
+class WrappedI420Buffer : public webrtc::VideoFrameBuffer {
+ public:
+  WrappedI420Buffer(int width,
+                    int height,
+                    const uint8_t* y_plane,
+                    int y_stride,
+                    const uint8_t* u_plane,
+                    int u_stride,
+                    const uint8_t* v_plane,
+                    int v_stride,
+                    const rtc::Callback0<void>& no_longer_used);
+  int width() const override;
+  int height() const override;
+  int encoded_length() const override;
+
+  const uint8_t* DataY() const override;
+  const uint8_t* DataU() const override;
+  const uint8_t* DataV() const override;
+  int StrideY() const override;
+  int StrideU() const override;
+  int StrideV() const override;
+
+  void* native_handle() const override;
+
+  rtc::scoped_refptr<VideoFrameBuffer> NativeToI420Buffer() override;
+
+ private:
+  friend class rtc::RefCountedObject<WrappedI420Buffer>;
+  ~WrappedI420Buffer() override;
+
+  const int width_;
+  const int height_;
+  const int encoded_length_;
+  const uint8_t* const y_plane_;
+  const uint8_t* const u_plane_;
+  const uint8_t* const v_plane_;
+  const int y_stride_;
+  const int u_stride_;
+  const int v_stride_;
+  rtc::Callback0<void> no_longer_used_cb_;
+};
+
+}  // namespace webrtc
+
+#endif  // WEBRTC_COMMON_VIDEO_INCLUDE_VIDEO_FRAME_BUFFER_H_
diff --git a/webrtc/common_video/video_frame_buffer.cc b/webrtc/common_video/video_frame_buffer.cc
index 4646bf4..3e62c06 100644
--- a/webrtc/common_video/video_frame_buffer.cc
+++ b/webrtc/common_video/video_frame_buffer.cc
@@ -1,132 +1,136 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-#include "webrtc/common_video/include/video_frame_buffer.h"
-
-#include <string.h>
-
-#include <algorithm>
-
-#include "webrtc/base/checks.h"
-#include "webrtc/base/keep_ref_until_done.h"
-#include "libyuv/convert.h"
-#include "libyuv/planar_functions.h"
-#include "libyuv/scale.h"
-
-namespace webrtc {
-
-NativeHandleBuffer::NativeHandleBuffer(void* native_handle,
-                                       int width,
-                                       int height)
-    : native_handle_(native_handle), width_(width), height_(height) {
-  RTC_DCHECK(native_handle != nullptr);
-  RTC_DCHECK_GT(width, 0);
-  RTC_DCHECK_GT(height, 0);
-}
-
-int NativeHandleBuffer::width() const {
-  return width_;
-}
-
-int NativeHandleBuffer::height() const {
-  return height_;
-}
-
-const uint8_t* NativeHandleBuffer::DataY() const {
-  RTC_NOTREACHED();  // Should not be called.
-  return nullptr;
-}
-const uint8_t* NativeHandleBuffer::DataU() const {
-  RTC_NOTREACHED();  // Should not be called.
-  return nullptr;
-}
-const uint8_t* NativeHandleBuffer::DataV() const {
-  RTC_NOTREACHED();  // Should not be called.
-  return nullptr;
-}
-
-int NativeHandleBuffer::StrideY() const {
-  RTC_NOTREACHED();  // Should not be called.
-  return 0;
-}
-int NativeHandleBuffer::StrideU() const {
-  RTC_NOTREACHED();  // Should not be called.
-  return 0;
-}
-int NativeHandleBuffer::StrideV() const {
-  RTC_NOTREACHED();  // Should not be called.
-  return 0;
-}
-
-void* NativeHandleBuffer::native_handle() const {
-  return native_handle_;
-}
-
-WrappedI420Buffer::WrappedI420Buffer(int width,
-                                     int height,
-                                     const uint8_t* y_plane,
-                                     int y_stride,
-                                     const uint8_t* u_plane,
-                                     int u_stride,
-                                     const uint8_t* v_plane,
-                                     int v_stride,
-                                     const rtc::Callback0<void>& no_longer_used)
-    : width_(width),
-      height_(height),
-      y_plane_(y_plane),
-      u_plane_(u_plane),
-      v_plane_(v_plane),
-      y_stride_(y_stride),
-      u_stride_(u_stride),
-      v_stride_(v_stride),
-      no_longer_used_cb_(no_longer_used) {
-}
-
-WrappedI420Buffer::~WrappedI420Buffer() {
-  no_longer_used_cb_();
-}
-
-int WrappedI420Buffer::width() const {
-  return width_;
-}
-
-int WrappedI420Buffer::height() const {
-  return height_;
-}
-
-const uint8_t* WrappedI420Buffer::DataY() const {
-  return y_plane_;
-}
-const uint8_t* WrappedI420Buffer::DataU() const {
-  return u_plane_;
-}
-const uint8_t* WrappedI420Buffer::DataV() const {
-  return v_plane_;
-}
-
-int WrappedI420Buffer::StrideY() const {
-  return y_stride_;
-}
-int WrappedI420Buffer::StrideU() const {
-  return u_stride_;
-}
-int WrappedI420Buffer::StrideV() const {
-  return v_stride_;
-}
-
-void* WrappedI420Buffer::native_handle() const {
-  return nullptr;
-}
-
-rtc::scoped_refptr<VideoFrameBuffer> WrappedI420Buffer::NativeToI420Buffer() {
-  RTC_NOTREACHED();
-  return nullptr;
-}
-
-}  // namespace webrtc
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+#include "webrtc/common_video/include/video_frame_buffer.h"
+
+#include <string.h>
+
+#include <algorithm>
+
+#include "webrtc/base/checks.h"
+#include "webrtc/base/keep_ref_until_done.h"
+#include "libyuv/convert.h"
+#include "libyuv/planar_functions.h"
+#include "libyuv/scale.h"
+
+namespace webrtc {
+
+NativeHandleBuffer::NativeHandleBuffer(void* native_handle,
+                                       int width,
+                                       int height)
+    : native_handle_(native_handle), width_(width), height_(height) {
+  RTC_DCHECK(native_handle != nullptr);
+  RTC_DCHECK_GT(width, 0);
+  RTC_DCHECK_GT(height, 0);
+}
+
+int NativeHandleBuffer::width() const {
+  return width_;
+}
+
+int NativeHandleBuffer::height() const {
+  return height_;
+}
+
+const uint8_t* NativeHandleBuffer::DataY() const {
+  RTC_NOTREACHED();  // Should not be called.
+  return nullptr;
+}
+const uint8_t* NativeHandleBuffer::DataU() const {
+  RTC_NOTREACHED();  // Should not be called.
+  return nullptr;
+}
+const uint8_t* NativeHandleBuffer::DataV() const {
+  RTC_NOTREACHED();  // Should not be called.
+  return nullptr;
+}
+
+int NativeHandleBuffer::StrideY() const {
+  RTC_NOTREACHED();  // Should not be called.
+  return 0;
+}
+int NativeHandleBuffer::StrideU() const {
+  RTC_NOTREACHED();  // Should not be called.
+  return 0;
+}
+int NativeHandleBuffer::StrideV() const {
+  RTC_NOTREACHED();  // Should not be called.
+  return 0;
+}
+
+void* NativeHandleBuffer::native_handle() const {
+  return native_handle_;
+}
+
+WrappedI420Buffer::WrappedI420Buffer(int width,
+                                     int height,
+                                     const uint8_t* y_plane,
+                                     int y_stride,
+                                     const uint8_t* u_plane,
+                                     int u_stride,
+                                     const uint8_t* v_plane,
+                                     int v_stride,
+                                     const rtc::Callback0<void>& no_longer_used)
+    : width_(width),
+      height_(height),
+	  encoded_length_(0),
+      y_plane_(y_plane),
+      u_plane_(u_plane),
+      v_plane_(v_plane),
+      y_stride_(y_stride),
+      u_stride_(u_stride),
+      v_stride_(v_stride),
+      no_longer_used_cb_(no_longer_used) {
+}
+
+WrappedI420Buffer::~WrappedI420Buffer() {
+  no_longer_used_cb_();
+}
+
+int WrappedI420Buffer::width() const {
+  return width_;
+}
+
+int WrappedI420Buffer::height() const {
+  return height_;
+}
+
+int WrappedI420Buffer::encoded_length() const {
+	return encoded_length_;
+}
+const uint8_t* WrappedI420Buffer::DataY() const {
+  return y_plane_;
+}
+const uint8_t* WrappedI420Buffer::DataU() const {
+  return u_plane_;
+}
+const uint8_t* WrappedI420Buffer::DataV() const {
+  return v_plane_;
+}
+
+int WrappedI420Buffer::StrideY() const {
+  return y_stride_;
+}
+int WrappedI420Buffer::StrideU() const {
+  return u_stride_;
+}
+int WrappedI420Buffer::StrideV() const {
+  return v_stride_;
+}
+
+void* WrappedI420Buffer::native_handle() const {
+  return nullptr;
+}
+
+rtc::scoped_refptr<VideoFrameBuffer> WrappedI420Buffer::NativeToI420Buffer() {
+  RTC_NOTREACHED();
+  return nullptr;
+}
+
+}  // namespace webrtc
diff --git a/webrtc/media/engine/webrtcvideoengine2.cc b/webrtc/media/engine/webrtcvideoengine2.cc
index 3639472..b61e548 100644
--- a/webrtc/media/engine/webrtcvideoengine2.cc
+++ b/webrtc/media/engine/webrtcvideoengine2.cc
@@ -1,2552 +1,2561 @@
-/*
- *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-
-#include "webrtc/media/engine/webrtcvideoengine2.h"
-
-#include <stdio.h>
-#include <algorithm>
-#include <set>
-#include <string>
-#include <utility>
-
-#include "webrtc/api/video/i420_buffer.h"
-#include "webrtc/base/copyonwritebuffer.h"
-#include "webrtc/base/logging.h"
-#include "webrtc/base/stringutils.h"
-#include "webrtc/base/timeutils.h"
-#include "webrtc/base/trace_event.h"
-#include "webrtc/call/call.h"
-#include "webrtc/common_video/h264/profile_level_id.h"
-#include "webrtc/media/engine/constants.h"
-#include "webrtc/media/engine/internalencoderfactory.h"
-#include "webrtc/media/engine/internaldecoderfactory.h"
-#include "webrtc/media/engine/simulcast.h"
-#include "webrtc/media/engine/videoencodersoftwarefallbackwrapper.h"
-#include "webrtc/media/engine/videodecodersoftwarefallbackwrapper.h"
-#include "webrtc/media/engine/webrtcmediaengine.h"
-#include "webrtc/media/engine/webrtcvideoencoderfactory.h"
-#include "webrtc/media/engine/webrtcvoiceengine.h"
-#include "webrtc/modules/video_coding/codecs/vp8/simulcast_encoder_adapter.h"
-#include "webrtc/system_wrappers/include/field_trial.h"
-#include "webrtc/video_decoder.h"
-#include "webrtc/video_encoder.h"
-
-namespace cricket {
-namespace {
-
-// If this field trial is enabled, we will enable sending FlexFEC and disable
-// sending ULPFEC whenever the former has been negotiated. Receiving FlexFEC
-// is enabled whenever FlexFEC has been negotiated.
-bool IsFlexfecFieldTrialEnabled() {
-  return webrtc::field_trial::FindFullName("WebRTC-FlexFEC-03") == "Enabled";
-}
-
-// Wrap cricket::WebRtcVideoEncoderFactory as a webrtc::VideoEncoderFactory.
-class EncoderFactoryAdapter : public webrtc::VideoEncoderFactory {
- public:
-  // EncoderFactoryAdapter doesn't take ownership of |factory|, which is owned
-  // by e.g. PeerConnectionFactory.
-  explicit EncoderFactoryAdapter(cricket::WebRtcVideoEncoderFactory* factory)
-      : factory_(factory) {}
-  virtual ~EncoderFactoryAdapter() {}
-
-  // Implement webrtc::VideoEncoderFactory.
-  webrtc::VideoEncoder* Create() override {
-    return factory_->CreateVideoEncoder(VideoCodec(kVp8CodecName));
-  }
-
-  void Destroy(webrtc::VideoEncoder* encoder) override {
-    return factory_->DestroyVideoEncoder(encoder);
-  }
-
- private:
-  cricket::WebRtcVideoEncoderFactory* const factory_;
-};
-
-// An encoder factory that wraps Create requests for simulcastable codec types
-// with a webrtc::SimulcastEncoderAdapter. Non simulcastable codec type
-// requests are just passed through to the contained encoder factory.
-class WebRtcSimulcastEncoderFactory
-    : public cricket::WebRtcVideoEncoderFactory {
- public:
-  // WebRtcSimulcastEncoderFactory doesn't take ownership of |factory|, which is
-  // owned by e.g. PeerConnectionFactory.
-  explicit WebRtcSimulcastEncoderFactory(
-      cricket::WebRtcVideoEncoderFactory* factory)
-      : factory_(factory) {}
-
-  static bool UseSimulcastEncoderFactory(
-      const std::vector<cricket::VideoCodec>& codecs) {
-    // If any codec is VP8, use the simulcast factory. If asked to create a
-    // non-VP8 codec, we'll just return a contained factory encoder directly.
-    for (const auto& codec : codecs) {
-      if (CodecNamesEq(codec.name.c_str(), kVp8CodecName)) {
-        return true;
-      }
-    }
-    return false;
-  }
-
-  webrtc::VideoEncoder* CreateVideoEncoder(
-      const cricket::VideoCodec& codec) override {
-    RTC_DCHECK(factory_ != NULL);
-    // If it's a codec type we can simulcast, create a wrapped encoder.
-    if (CodecNamesEq(codec.name.c_str(), kVp8CodecName)) {
-      return new webrtc::SimulcastEncoderAdapter(
-          new EncoderFactoryAdapter(factory_));
-    }
-    webrtc::VideoEncoder* encoder = factory_->CreateVideoEncoder(codec);
-    if (encoder) {
-      non_simulcast_encoders_.push_back(encoder);
-    }
-    return encoder;
-  }
-
-  const std::vector<cricket::VideoCodec>& supported_codecs() const override {
-    return factory_->supported_codecs();
-  }
-
-  bool EncoderTypeHasInternalSource(
-      webrtc::VideoCodecType type) const override {
-    return factory_->EncoderTypeHasInternalSource(type);
-  }
-
-  void DestroyVideoEncoder(webrtc::VideoEncoder* encoder) override {
-    // Check first to see if the encoder wasn't wrapped in a
-    // SimulcastEncoderAdapter. In that case, ask the factory to destroy it.
-    if (std::remove(non_simulcast_encoders_.begin(),
-                    non_simulcast_encoders_.end(),
-                    encoder) != non_simulcast_encoders_.end()) {
-      factory_->DestroyVideoEncoder(encoder);
-      return;
-    }
-
-    // Otherwise, SimulcastEncoderAdapter can be deleted directly, and will call
-    // DestroyVideoEncoder on the factory for individual encoder instances.
-    delete encoder;
-  }
-
- private:
-  // Disable overloaded virtual function warning. TODO(magjed): Remove once
-  // http://crbug/webrtc/6402 is fixed.
-  using cricket::WebRtcVideoEncoderFactory::CreateVideoEncoder;
-
-  cricket::WebRtcVideoEncoderFactory* factory_;
-  // A list of encoders that were created without being wrapped in a
-  // SimulcastEncoderAdapter.
-  std::vector<webrtc::VideoEncoder*> non_simulcast_encoders_;
-};
-
-void AddDefaultFeedbackParams(VideoCodec* codec) {
-  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamCcm, kRtcpFbCcmParamFir));
-  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamNack, kParamValueEmpty));
-  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamNack, kRtcpFbNackParamPli));
-  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamRemb, kParamValueEmpty));
-  codec->AddFeedbackParam(
-      FeedbackParam(kRtcpFbParamTransportCc, kParamValueEmpty));
-}
-
-static std::string CodecVectorToString(const std::vector<VideoCodec>& codecs) {
-  std::stringstream out;
-  out << '{';
-  for (size_t i = 0; i < codecs.size(); ++i) {
-    out << codecs[i].ToString();
-    if (i != codecs.size() - 1) {
-      out << ", ";
-    }
-  }
-  out << '}';
-  return out.str();
-}
-
-static bool ValidateCodecFormats(const std::vector<VideoCodec>& codecs) {
-  bool has_video = false;
-  for (size_t i = 0; i < codecs.size(); ++i) {
-    if (!codecs[i].ValidateCodecFormat()) {
-      return false;
-    }
-    if (codecs[i].GetCodecType() == VideoCodec::CODEC_VIDEO) {
-      has_video = true;
-    }
-  }
-  if (!has_video) {
-    LOG(LS_ERROR) << "Setting codecs without a video codec is invalid: "
-                  << CodecVectorToString(codecs);
-    return false;
-  }
-  return true;
-}
-
-static bool ValidateStreamParams(const StreamParams& sp) {
-  if (sp.ssrcs.empty()) {
-    LOG(LS_ERROR) << "No SSRCs in stream parameters: " << sp.ToString();
-    return false;
-  }
-
-  std::vector<uint32_t> primary_ssrcs;
-  sp.GetPrimarySsrcs(&primary_ssrcs);
-  std::vector<uint32_t> rtx_ssrcs;
-  sp.GetFidSsrcs(primary_ssrcs, &rtx_ssrcs);
-  for (uint32_t rtx_ssrc : rtx_ssrcs) {
-    bool rtx_ssrc_present = false;
-    for (uint32_t sp_ssrc : sp.ssrcs) {
-      if (sp_ssrc == rtx_ssrc) {
-        rtx_ssrc_present = true;
-        break;
-      }
-    }
-    if (!rtx_ssrc_present) {
-      LOG(LS_ERROR) << "RTX SSRC '" << rtx_ssrc
-                    << "' missing from StreamParams ssrcs: " << sp.ToString();
-      return false;
-    }
-  }
-  if (!rtx_ssrcs.empty() && primary_ssrcs.size() != rtx_ssrcs.size()) {
-    LOG(LS_ERROR)
-        << "RTX SSRCs exist, but don't cover all SSRCs (unsupported): "
-        << sp.ToString();
-    return false;
-  }
-
-  return true;
-}
-
-// Returns true if the given codec is disallowed from doing simulcast.
-bool IsCodecBlacklistedForSimulcast(const std::string& codec_name) {
-  return CodecNamesEq(codec_name, kH264CodecName) ||
-         CodecNamesEq(codec_name, kVp9CodecName);
-}
-
-// The selected thresholds for QVGA and VGA corresponded to a QP around 10.
-// The change in QP declined above the selected bitrates.
-static int GetMaxDefaultVideoBitrateKbps(int width, int height) {
-  if (width * height <= 320 * 240) {
-    return 600;
-  } else if (width * height <= 640 * 480) {
-    return 1700;
-  } else if (width * height <= 960 * 540) {
-    return 2000;
-  } else {
-    return 2500;
-  }
-}
-
-bool GetVp9LayersFromFieldTrialGroup(int* num_spatial_layers,
-                                     int* num_temporal_layers) {
-  std::string group = webrtc::field_trial::FindFullName("WebRTC-SupportVP9SVC");
-  if (group.empty())
-    return false;
-
-  if (sscanf(group.c_str(), "EnabledByFlag_%dSL%dTL", num_spatial_layers,
-             num_temporal_layers) != 2) {
-    return false;
-  }
-  const int kMaxSpatialLayers = 2;
-  if (*num_spatial_layers > kMaxSpatialLayers || *num_spatial_layers < 1)
-    return false;
-
-  const int kMaxTemporalLayers = 3;
-  if (*num_temporal_layers > kMaxTemporalLayers || *num_temporal_layers < 1)
-    return false;
-
-  return true;
-}
-
-int GetDefaultVp9SpatialLayers() {
-  int num_sl;
-  int num_tl;
-  if (GetVp9LayersFromFieldTrialGroup(&num_sl, &num_tl)) {
-    return num_sl;
-  }
-  return 1;
-}
-
-int GetDefaultVp9TemporalLayers() {
-  int num_sl;
-  int num_tl;
-  if (GetVp9LayersFromFieldTrialGroup(&num_sl, &num_tl)) {
-    return num_tl;
-  }
-  return 1;
-}
-
-class EncoderStreamFactory
-    : public webrtc::VideoEncoderConfig::VideoStreamFactoryInterface {
- public:
-  EncoderStreamFactory(std::string codec_name,
-                       int max_qp,
-                       int max_framerate,
-                       bool is_screencast,
-                       bool conference_mode)
-      : codec_name_(codec_name),
-        max_qp_(max_qp),
-        max_framerate_(max_framerate),
-        is_screencast_(is_screencast),
-        conference_mode_(conference_mode) {}
-
- private:
-  std::vector<webrtc::VideoStream> CreateEncoderStreams(
-      int width,
-      int height,
-      const webrtc::VideoEncoderConfig& encoder_config) override {
-    if (is_screencast_ &&
-        (!conference_mode_ || !cricket::UseSimulcastScreenshare())) {
-      RTC_DCHECK_EQ(1, encoder_config.number_of_streams);
-    }
-    if (encoder_config.number_of_streams > 1 ||
-        (CodecNamesEq(codec_name_, kVp8CodecName) && is_screencast_ &&
-         conference_mode_)) {
-      return GetSimulcastConfig(encoder_config.number_of_streams, width, height,
-                                encoder_config.max_bitrate_bps, max_qp_,
-                                max_framerate_, is_screencast_);
-    }
-
-    // For unset max bitrates set default bitrate for non-simulcast.
-    int max_bitrate_bps =
-        (encoder_config.max_bitrate_bps > 0)
-            ? encoder_config.max_bitrate_bps
-            : GetMaxDefaultVideoBitrateKbps(width, height) * 1000;
-
-    webrtc::VideoStream stream;
-    stream.width = width;
-    stream.height = height;
-    stream.max_framerate = max_framerate_;
-    stream.min_bitrate_bps = kMinVideoBitrateKbps * 1000;
-    stream.target_bitrate_bps = stream.max_bitrate_bps = max_bitrate_bps;
-    stream.max_qp = max_qp_;
-
-    if (CodecNamesEq(codec_name_, kVp9CodecName) && !is_screencast_) {
-      stream.temporal_layer_thresholds_bps.resize(
-          GetDefaultVp9TemporalLayers() - 1);
-    }
-
-    std::vector<webrtc::VideoStream> streams;
-    streams.push_back(stream);
-    return streams;
-  }
-
-  const std::string codec_name_;
-  const int max_qp_;
-  const int max_framerate_;
-  const bool is_screencast_;
-  const bool conference_mode_;
-};
-
-}  // namespace
-
-// Constants defined in webrtc/media/engine/constants.h
-// TODO(pbos): Move these to a separate constants.cc file.
-const int kMinVideoBitrateKbps = 30;
-
-const int kVideoMtu = 1200;
-const int kVideoRtpBufferSize = 65536;
-
-// This constant is really an on/off, lower-level configurable NACK history
-// duration hasn't been implemented.
-static const int kNackHistoryMs = 1000;
-
-static const int kDefaultQpMax = 56;
-
-static const int kDefaultRtcpReceiverReportSsrc = 1;
-
-// Minimum time interval for logging stats.
-static const int64_t kStatsLogIntervalMs = 10000;
-
-static std::vector<VideoCodec> GetSupportedCodecs(
-    const WebRtcVideoEncoderFactory* external_encoder_factory);
-
-rtc::scoped_refptr<webrtc::VideoEncoderConfig::EncoderSpecificSettings>
-WebRtcVideoChannel2::WebRtcVideoSendStream::ConfigureVideoEncoderSettings(
-    const VideoCodec& codec) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  bool is_screencast = parameters_.options.is_screencast.value_or(false);
-  // No automatic resizing when using simulcast or screencast.
-  bool automatic_resize =
-      !is_screencast && parameters_.config.rtp.ssrcs.size() == 1;
-  bool frame_dropping = !is_screencast;
-  bool denoising;
-  bool codec_default_denoising = false;
-  if (is_screencast) {
-    denoising = false;
-  } else {
-    // Use codec default if video_noise_reduction is unset.
-    codec_default_denoising = !parameters_.options.video_noise_reduction;
-    denoising = parameters_.options.video_noise_reduction.value_or(false);
-  }
-
-  if (CodecNamesEq(codec.name, kH264CodecName)) {
-    webrtc::VideoCodecH264 h264_settings =
-        webrtc::VideoEncoder::GetDefaultH264Settings();
-    h264_settings.frameDroppingOn = frame_dropping;
-    return new rtc::RefCountedObject<
-        webrtc::VideoEncoderConfig::H264EncoderSpecificSettings>(h264_settings);
-  }
-  if (CodecNamesEq(codec.name, kVp8CodecName)) {
-    webrtc::VideoCodecVP8 vp8_settings =
-        webrtc::VideoEncoder::GetDefaultVp8Settings();
-    vp8_settings.automaticResizeOn = automatic_resize;
-    // VP8 denoising is enabled by default.
-    vp8_settings.denoisingOn = codec_default_denoising ? true : denoising;
-    vp8_settings.frameDroppingOn = frame_dropping;
-    return new rtc::RefCountedObject<
-        webrtc::VideoEncoderConfig::Vp8EncoderSpecificSettings>(vp8_settings);
-  }
-  if (CodecNamesEq(codec.name, kVp9CodecName)) {
-    webrtc::VideoCodecVP9 vp9_settings =
-        webrtc::VideoEncoder::GetDefaultVp9Settings();
-    if (is_screencast) {
-      // TODO(asapersson): Set to 2 for now since there is a DCHECK in
-      // VideoSendStream::ReconfigureVideoEncoder.
-      vp9_settings.numberOfSpatialLayers = 2;
-    } else {
-      vp9_settings.numberOfSpatialLayers = GetDefaultVp9SpatialLayers();
-    }
-    // VP9 denoising is disabled by default.
-    vp9_settings.denoisingOn = codec_default_denoising ? false : denoising;
-    vp9_settings.frameDroppingOn = frame_dropping;
-    return new rtc::RefCountedObject<
-        webrtc::VideoEncoderConfig::Vp9EncoderSpecificSettings>(vp9_settings);
-  }
-  return nullptr;
-}
-
-DefaultUnsignalledSsrcHandler::DefaultUnsignalledSsrcHandler()
-    : default_recv_ssrc_(0), default_sink_(NULL) {}
-
-UnsignalledSsrcHandler::Action DefaultUnsignalledSsrcHandler::OnUnsignalledSsrc(
-    WebRtcVideoChannel2* channel,
-    uint32_t ssrc) {
-  if (default_recv_ssrc_ != 0) {  // Already one default stream, so replace it.
-    channel->RemoveRecvStream(default_recv_ssrc_);
-    default_recv_ssrc_ = 0;
-  }
-
-  StreamParams sp;
-  sp.ssrcs.push_back(ssrc);
-  LOG(LS_INFO) << "Creating default receive stream for SSRC=" << ssrc << ".";
-  if (!channel->AddRecvStream(sp, true)) {
-    LOG(LS_WARNING) << "Could not create default receive stream.";
-  }
-
-  channel->SetSink(ssrc, default_sink_);
-  default_recv_ssrc_ = ssrc;
-  return kDeliverPacket;
-}
-
-rtc::VideoSinkInterface<webrtc::VideoFrame>*
-DefaultUnsignalledSsrcHandler::GetDefaultSink() const {
-  return default_sink_;
-}
-
-void DefaultUnsignalledSsrcHandler::SetDefaultSink(
-    VideoMediaChannel* channel,
-    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
-  default_sink_ = sink;
-  if (default_recv_ssrc_ != 0) {
-    channel->SetSink(default_recv_ssrc_, default_sink_);
-  }
-}
-
-WebRtcVideoEngine2::WebRtcVideoEngine2()
-    : initialized_(false),
-      external_decoder_factory_(NULL),
-      external_encoder_factory_(NULL) {
-  LOG(LS_INFO) << "WebRtcVideoEngine2::WebRtcVideoEngine2()";
-}
-
-WebRtcVideoEngine2::~WebRtcVideoEngine2() {
-  LOG(LS_INFO) << "WebRtcVideoEngine2::~WebRtcVideoEngine2";
-}
-
-void WebRtcVideoEngine2::Init() {
-  LOG(LS_INFO) << "WebRtcVideoEngine2::Init";
-  initialized_ = true;
-}
-
-WebRtcVideoChannel2* WebRtcVideoEngine2::CreateChannel(
-    webrtc::Call* call,
-    const MediaConfig& config,
-    const VideoOptions& options) {
-  RTC_DCHECK(initialized_);
-  LOG(LS_INFO) << "CreateChannel. Options: " << options.ToString();
-  return new WebRtcVideoChannel2(call, config, options,
-                                 external_encoder_factory_,
-                                 external_decoder_factory_);
-}
-
-std::vector<VideoCodec> WebRtcVideoEngine2::codecs() const {
-  return GetSupportedCodecs(external_encoder_factory_);
-}
-
-RtpCapabilities WebRtcVideoEngine2::GetCapabilities() const {
-  RtpCapabilities capabilities;
-  capabilities.header_extensions.push_back(
-      webrtc::RtpExtension(webrtc::RtpExtension::kTimestampOffsetUri,
-                           webrtc::RtpExtension::kTimestampOffsetDefaultId));
-  capabilities.header_extensions.push_back(
-      webrtc::RtpExtension(webrtc::RtpExtension::kAbsSendTimeUri,
-                           webrtc::RtpExtension::kAbsSendTimeDefaultId));
-  capabilities.header_extensions.push_back(
-      webrtc::RtpExtension(webrtc::RtpExtension::kVideoRotationUri,
-                           webrtc::RtpExtension::kVideoRotationDefaultId));
-  capabilities.header_extensions.push_back(webrtc::RtpExtension(
-      webrtc::RtpExtension::kTransportSequenceNumberUri,
-      webrtc::RtpExtension::kTransportSequenceNumberDefaultId));
-  capabilities.header_extensions.push_back(
-      webrtc::RtpExtension(webrtc::RtpExtension::kPlayoutDelayUri,
-                           webrtc::RtpExtension::kPlayoutDelayDefaultId));
-  return capabilities;
-}
-
-void WebRtcVideoEngine2::SetExternalDecoderFactory(
-    WebRtcVideoDecoderFactory* decoder_factory) {
-  RTC_DCHECK(!initialized_);
-  external_decoder_factory_ = decoder_factory;
-}
-
-void WebRtcVideoEngine2::SetExternalEncoderFactory(
-    WebRtcVideoEncoderFactory* encoder_factory) {
-  RTC_DCHECK(!initialized_);
-  if (external_encoder_factory_ == encoder_factory)
-    return;
-
-  // No matter what happens we shouldn't hold on to a stale
-  // WebRtcSimulcastEncoderFactory.
-  simulcast_encoder_factory_.reset();
-
-  if (encoder_factory &&
-      WebRtcSimulcastEncoderFactory::UseSimulcastEncoderFactory(
-          encoder_factory->supported_codecs())) {
-    simulcast_encoder_factory_.reset(
-        new WebRtcSimulcastEncoderFactory(encoder_factory));
-    encoder_factory = simulcast_encoder_factory_.get();
-  }
-  external_encoder_factory_ = encoder_factory;
-}
-
-// This is a helper function for AppendVideoCodecs below. It will return the
-// first unused dynamic payload type (in the range [96, 127]), or nothing if no
-// payload type is unused.
-static rtc::Optional<int> NextFreePayloadType(
-    const std::vector<VideoCodec>& codecs) {
-  static const int kFirstDynamicPayloadType = 96;
-  static const int kLastDynamicPayloadType = 127;
-  bool is_payload_used[1 + kLastDynamicPayloadType - kFirstDynamicPayloadType] =
-      {false};
-  for (const VideoCodec& codec : codecs) {
-    if (kFirstDynamicPayloadType <= codec.id &&
-        codec.id <= kLastDynamicPayloadType) {
-      is_payload_used[codec.id - kFirstDynamicPayloadType] = true;
-    }
-  }
-  for (int i = kFirstDynamicPayloadType; i <= kLastDynamicPayloadType; ++i) {
-    if (!is_payload_used[i - kFirstDynamicPayloadType])
-      return rtc::Optional<int>(i);
-  }
-  // No free payload type.
-  return rtc::Optional<int>();
-}
-
-// This is a helper function for GetSupportedCodecs below. It will append new
-// unique codecs from |input_codecs| to |unified_codecs|. It will add default
-// feedback params to the codecs and will also add an associated RTX codec for
-// recognized codecs (VP8, VP9, H264, and RED).
-static void AppendVideoCodecs(const std::vector<VideoCodec>& input_codecs,
-                              std::vector<VideoCodec>* unified_codecs) {
-  for (VideoCodec codec : input_codecs) {
-    const rtc::Optional<int> payload_type =
-        NextFreePayloadType(*unified_codecs);
-    if (!payload_type)
-      return;
-    codec.id = *payload_type;
-    // TODO(magjed): Move the responsibility of setting these parameters to the
-    // encoder factories instead.
-    if (codec.name != kRedCodecName && codec.name != kUlpfecCodecName &&
-        codec.name != kFlexfecCodecName)
-      AddDefaultFeedbackParams(&codec);
-    // Don't add same codec twice.
-    if (FindMatchingCodec(*unified_codecs, codec))
-      continue;
-
-    unified_codecs->push_back(codec);
-
-    // Add associated RTX codec for recognized codecs.
-    // TODO(deadbeef): Should we add RTX codecs for external codecs whose names
-    // we don't recognize?
-    if (CodecNamesEq(codec.name, kVp8CodecName) ||
-        CodecNamesEq(codec.name, kVp9CodecName) ||
-        CodecNamesEq(codec.name, kH264CodecName) ||
-        CodecNamesEq(codec.name, kRedCodecName)) {
-      const rtc::Optional<int> rtx_payload_type =
-          NextFreePayloadType(*unified_codecs);
-      if (!rtx_payload_type)
-        return;
-      unified_codecs->push_back(
-          VideoCodec::CreateRtxCodec(*rtx_payload_type, codec.id));
-    }
-  }
-}
-
-static std::vector<VideoCodec> GetSupportedCodecs(
-    const WebRtcVideoEncoderFactory* external_encoder_factory) {
-  const std::vector<VideoCodec> internal_codecs =
-      InternalEncoderFactory().supported_codecs();
-  LOG(LS_INFO) << "Internally supported codecs: "
-               << CodecVectorToString(internal_codecs);
-
-  std::vector<VideoCodec> unified_codecs;
-  AppendVideoCodecs(internal_codecs, &unified_codecs);
-
-  if (external_encoder_factory != nullptr) {
-    const std::vector<VideoCodec>& external_codecs =
-        external_encoder_factory->supported_codecs();
-    AppendVideoCodecs(external_codecs, &unified_codecs);
-    LOG(LS_INFO) << "Codecs supported by the external encoder factory: "
-                 << CodecVectorToString(external_codecs);
-  }
-
-  return unified_codecs;
-}
-
-WebRtcVideoChannel2::WebRtcVideoChannel2(
-    webrtc::Call* call,
-    const MediaConfig& config,
-    const VideoOptions& options,
-    WebRtcVideoEncoderFactory* external_encoder_factory,
-    WebRtcVideoDecoderFactory* external_decoder_factory)
-    : VideoMediaChannel(config),
-      call_(call),
-      unsignalled_ssrc_handler_(&default_unsignalled_ssrc_handler_),
-      video_config_(config.video),
-      external_encoder_factory_(external_encoder_factory),
-      external_decoder_factory_(external_decoder_factory),
-      default_send_options_(options),
-      last_stats_log_ms_(-1) {
-  RTC_DCHECK(thread_checker_.CalledOnValidThread());
-
-  rtcp_receiver_report_ssrc_ = kDefaultRtcpReceiverReportSsrc;
-  sending_ = false;
-  recv_codecs_ = MapCodecs(GetSupportedCodecs(external_encoder_factory));
-}
-
-WebRtcVideoChannel2::~WebRtcVideoChannel2() {
-  for (auto& kv : send_streams_)
-    delete kv.second;
-  for (auto& kv : receive_streams_)
-    delete kv.second;
-}
-
-rtc::Optional<WebRtcVideoChannel2::VideoCodecSettings>
-WebRtcVideoChannel2::SelectSendVideoCodec(
-    const std::vector<VideoCodecSettings>& remote_mapped_codecs) const {
-  const std::vector<VideoCodec> local_supported_codecs =
-      GetSupportedCodecs(external_encoder_factory_);
-  // Select the first remote codec that is supported locally.
-  for (const VideoCodecSettings& remote_mapped_codec : remote_mapped_codecs) {
-    // For H264, we will limit the encode level to the remote offered level
-    // regardless if level asymmetry is allowed or not. This is strictly not
-    // following the spec in https://tools.ietf.org/html/rfc6184#section-8.2.2
-    // since we should limit the encode level to the lower of local and remote
-    // level when level asymmetry is not allowed.
-    if (FindMatchingCodec(local_supported_codecs, remote_mapped_codec.codec))
-      return rtc::Optional<VideoCodecSettings>(remote_mapped_codec);
-  }
-  // No remote codec was supported.
-  return rtc::Optional<VideoCodecSettings>();
-}
-
-bool WebRtcVideoChannel2::ReceiveCodecsHaveChanged(
-    std::vector<VideoCodecSettings> before,
-    std::vector<VideoCodecSettings> after) {
-  if (before.size() != after.size()) {
-    return true;
-  }
-  // The receive codec order doesn't matter, so we sort the codecs before
-  // comparing. This is necessary because currently the
-  // only way to change the send codec is to munge SDP, which causes
-  // the receive codec list to change order, which causes the streams
-  // to be recreates which causes a "blink" of black video.  In order
-  // to support munging the SDP in this way without recreating receive
-  // streams, we ignore the order of the received codecs so that
-  // changing the order doesn't cause this "blink".
-  auto comparison =
-      [](const VideoCodecSettings& codec1, const VideoCodecSettings& codec2) {
-        return codec1.codec.id > codec2.codec.id;
-      };
-  std::sort(before.begin(), before.end(), comparison);
-  std::sort(after.begin(), after.end(), comparison);
-  return before != after;
-}
-
-bool WebRtcVideoChannel2::GetChangedSendParameters(
-    const VideoSendParameters& params,
-    ChangedSendParameters* changed_params) const {
-  if (!ValidateCodecFormats(params.codecs) ||
-      !ValidateRtpExtensions(params.extensions)) {
-    return false;
-  }
-
-  // Select one of the remote codecs that will be used as send codec.
-  const rtc::Optional<VideoCodecSettings> selected_send_codec =
-      SelectSendVideoCodec(MapCodecs(params.codecs));
-
-  if (!selected_send_codec) {
-    LOG(LS_ERROR) << "No video codecs supported.";
-    return false;
-  }
-
-  if (!send_codec_ || *selected_send_codec != *send_codec_)
-    changed_params->codec = selected_send_codec;
-
-  // Handle RTP header extensions.
-  std::vector<webrtc::RtpExtension> filtered_extensions = FilterRtpExtensions(
-      params.extensions, webrtc::RtpExtension::IsSupportedForVideo, true);
-  if (!send_rtp_extensions_ || (*send_rtp_extensions_ != filtered_extensions)) {
-    changed_params->rtp_header_extensions =
-        rtc::Optional<std::vector<webrtc::RtpExtension>>(filtered_extensions);
-  }
-
-  // Handle max bitrate.
-  if (params.max_bandwidth_bps != send_params_.max_bandwidth_bps &&
-      params.max_bandwidth_bps >= 0) {
-    // 0 uncaps max bitrate (-1).
-    changed_params->max_bandwidth_bps = rtc::Optional<int>(
-        params.max_bandwidth_bps == 0 ? -1 : params.max_bandwidth_bps);
-  }
-
-  // Handle conference mode.
-  if (params.conference_mode != send_params_.conference_mode) {
-    changed_params->conference_mode =
-        rtc::Optional<bool>(params.conference_mode);
-  }
-
-  // Handle RTCP mode.
-  if (params.rtcp.reduced_size != send_params_.rtcp.reduced_size) {
-    changed_params->rtcp_mode = rtc::Optional<webrtc::RtcpMode>(
-        params.rtcp.reduced_size ? webrtc::RtcpMode::kReducedSize
-                                 : webrtc::RtcpMode::kCompound);
-  }
-
-  return true;
-}
-
-rtc::DiffServCodePoint WebRtcVideoChannel2::PreferredDscp() const {
-  return rtc::DSCP_AF41;
-}
-
-bool WebRtcVideoChannel2::SetSendParameters(const VideoSendParameters& params) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetSendParameters");
-  LOG(LS_INFO) << "SetSendParameters: " << params.ToString();
-  ChangedSendParameters changed_params;
-  if (!GetChangedSendParameters(params, &changed_params)) {
-    return false;
-  }
-
-  if (changed_params.codec) {
-    const VideoCodecSettings& codec_settings = *changed_params.codec;
-    send_codec_ = rtc::Optional<VideoCodecSettings>(codec_settings);
-    LOG(LS_INFO) << "Using codec: " << codec_settings.codec.ToString();
-  }
-
-  if (changed_params.rtp_header_extensions) {
-    send_rtp_extensions_ = changed_params.rtp_header_extensions;
-  }
-
-  if (changed_params.codec || changed_params.max_bandwidth_bps) {
-    if (send_codec_) {
-      // TODO(holmer): Changing the codec parameters shouldn't necessarily mean
-      // that we change the min/max of bandwidth estimation. Reevaluate this.
-      bitrate_config_ = GetBitrateConfigForCodec(send_codec_->codec);
-      if (!changed_params.codec) {
-        // If the codec isn't changing, set the start bitrate to -1 which means
-        // "unchanged" so that BWE isn't affected.
-        bitrate_config_.start_bitrate_bps = -1;
-      }
-    }
-    if (params.max_bandwidth_bps >= 0) {
-      // Note that max_bandwidth_bps intentionally takes priority over the
-      // bitrate config for the codec. This allows FEC to be applied above the
-      // codec target bitrate.
-      // TODO(pbos): Figure out whether b=AS means max bitrate for this
-      // WebRtcVideoChannel2 (in which case we're good), or per sender (SSRC),
-      // in which case this should not set a Call::BitrateConfig but rather
-      // reconfigure all senders.
-      bitrate_config_.max_bitrate_bps =
-          params.max_bandwidth_bps == 0 ? -1 : params.max_bandwidth_bps;
-    }
-    call_->SetBitrateConfig(bitrate_config_);
-  }
-
-  {
-    rtc::CritScope stream_lock(&stream_crit_);
-    for (auto& kv : send_streams_) {
-      kv.second->SetSendParameters(changed_params);
-    }
-    if (changed_params.codec || changed_params.rtcp_mode) {
-      // Update receive feedback parameters from new codec or RTCP mode.
-      LOG(LS_INFO)
-          << "SetFeedbackOptions on all the receive streams because the send "
-             "codec or RTCP mode has changed.";
-      for (auto& kv : receive_streams_) {
-        RTC_DCHECK(kv.second != nullptr);
-        kv.second->SetFeedbackParameters(
-            HasNack(send_codec_->codec), HasRemb(send_codec_->codec),
-            HasTransportCc(send_codec_->codec),
-            params.rtcp.reduced_size ? webrtc::RtcpMode::kReducedSize
-                                     : webrtc::RtcpMode::kCompound);
-      }
-    }
-  }
-  send_params_ = params;
-  return true;
-}
-
-webrtc::RtpParameters WebRtcVideoChannel2::GetRtpSendParameters(
-    uint32_t ssrc) const {
-  rtc::CritScope stream_lock(&stream_crit_);
-  auto it = send_streams_.find(ssrc);
-  if (it == send_streams_.end()) {
-    LOG(LS_WARNING) << "Attempting to get RTP send parameters for stream "
-                    << "with ssrc " << ssrc << " which doesn't exist.";
-    return webrtc::RtpParameters();
-  }
-
-  webrtc::RtpParameters rtp_params = it->second->GetRtpParameters();
-  // Need to add the common list of codecs to the send stream-specific
-  // RTP parameters.
-  for (const VideoCodec& codec : send_params_.codecs) {
-    rtp_params.codecs.push_back(codec.ToCodecParameters());
-  }
-  return rtp_params;
-}
-
-bool WebRtcVideoChannel2::SetRtpSendParameters(
-    uint32_t ssrc,
-    const webrtc::RtpParameters& parameters) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetRtpSendParameters");
-  rtc::CritScope stream_lock(&stream_crit_);
-  auto it = send_streams_.find(ssrc);
-  if (it == send_streams_.end()) {
-    LOG(LS_ERROR) << "Attempting to set RTP send parameters for stream "
-                  << "with ssrc " << ssrc << " which doesn't exist.";
-    return false;
-  }
-
-  // TODO(deadbeef): Handle setting parameters with a list of codecs in a
-  // different order (which should change the send codec).
-  webrtc::RtpParameters current_parameters = GetRtpSendParameters(ssrc);
-  if (current_parameters.codecs != parameters.codecs) {
-    LOG(LS_ERROR) << "Using SetParameters to change the set of codecs "
-                  << "is not currently supported.";
-    return false;
-  }
-
-  return it->second->SetRtpParameters(parameters);
-}
-
-webrtc::RtpParameters WebRtcVideoChannel2::GetRtpReceiveParameters(
-    uint32_t ssrc) const {
-  rtc::CritScope stream_lock(&stream_crit_);
-  auto it = receive_streams_.find(ssrc);
-  if (it == receive_streams_.end()) {
-    LOG(LS_WARNING) << "Attempting to get RTP receive parameters for stream "
-                    << "with ssrc " << ssrc << " which doesn't exist.";
-    return webrtc::RtpParameters();
-  }
-
-  // TODO(deadbeef): Return stream-specific parameters.
-  webrtc::RtpParameters rtp_params = CreateRtpParametersWithOneEncoding();
-  for (const VideoCodec& codec : recv_params_.codecs) {
-    rtp_params.codecs.push_back(codec.ToCodecParameters());
-  }
-  rtp_params.encodings[0].ssrc = it->second->GetFirstPrimarySsrc();
-  return rtp_params;
-}
-
-bool WebRtcVideoChannel2::SetRtpReceiveParameters(
-    uint32_t ssrc,
-    const webrtc::RtpParameters& parameters) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetRtpReceiveParameters");
-  rtc::CritScope stream_lock(&stream_crit_);
-  auto it = receive_streams_.find(ssrc);
-  if (it == receive_streams_.end()) {
-    LOG(LS_ERROR) << "Attempting to set RTP receive parameters for stream "
-                  << "with ssrc " << ssrc << " which doesn't exist.";
-    return false;
-  }
-
-  webrtc::RtpParameters current_parameters = GetRtpReceiveParameters(ssrc);
-  if (current_parameters != parameters) {
-    LOG(LS_ERROR) << "Changing the RTP receive parameters is currently "
-                  << "unsupported.";
-    return false;
-  }
-  return true;
-}
-
-bool WebRtcVideoChannel2::GetChangedRecvParameters(
-    const VideoRecvParameters& params,
-    ChangedRecvParameters* changed_params) const {
-  if (!ValidateCodecFormats(params.codecs) ||
-      !ValidateRtpExtensions(params.extensions)) {
-    return false;
-  }
-
-  // Handle receive codecs.
-  const std::vector<VideoCodecSettings> mapped_codecs =
-      MapCodecs(params.codecs);
-  if (mapped_codecs.empty()) {
-    LOG(LS_ERROR) << "SetRecvParameters called without any video codecs.";
-    return false;
-  }
-
-  // Verify that every mapped codec is supported locally.
-  const std::vector<VideoCodec> local_supported_codecs =
-      GetSupportedCodecs(external_encoder_factory_);
-  for (const VideoCodecSettings& mapped_codec : mapped_codecs) {
-    if (!FindMatchingCodec(local_supported_codecs, mapped_codec.codec)) {
-      LOG(LS_ERROR) << "SetRecvParameters called with unsupported video codec: "
-                    << mapped_codec.codec.ToString();
-      return false;
-    }
-  }
-
-  if (ReceiveCodecsHaveChanged(recv_codecs_, mapped_codecs)) {
-    changed_params->codec_settings =
-        rtc::Optional<std::vector<VideoCodecSettings>>(mapped_codecs);
-  }
-
-  // Handle RTP header extensions.
-  std::vector<webrtc::RtpExtension> filtered_extensions = FilterRtpExtensions(
-      params.extensions, webrtc::RtpExtension::IsSupportedForVideo, false);
-  if (filtered_extensions != recv_rtp_extensions_) {
-    changed_params->rtp_header_extensions =
-        rtc::Optional<std::vector<webrtc::RtpExtension>>(filtered_extensions);
-  }
-
-  return true;
-}
-
-bool WebRtcVideoChannel2::SetRecvParameters(const VideoRecvParameters& params) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetRecvParameters");
-  LOG(LS_INFO) << "SetRecvParameters: " << params.ToString();
-  ChangedRecvParameters changed_params;
-  if (!GetChangedRecvParameters(params, &changed_params)) {
-    return false;
-  }
-  if (changed_params.rtp_header_extensions) {
-    recv_rtp_extensions_ = *changed_params.rtp_header_extensions;
-  }
-  if (changed_params.codec_settings) {
-    LOG(LS_INFO) << "Changing recv codecs from "
-                 << CodecSettingsVectorToString(recv_codecs_) << " to "
-                 << CodecSettingsVectorToString(*changed_params.codec_settings);
-    recv_codecs_ = *changed_params.codec_settings;
-  }
-
-  {
-    rtc::CritScope stream_lock(&stream_crit_);
-    for (auto& kv : receive_streams_) {
-      kv.second->SetRecvParameters(changed_params);
-    }
-  }
-  recv_params_ = params;
-  return true;
-}
-
-std::string WebRtcVideoChannel2::CodecSettingsVectorToString(
-    const std::vector<VideoCodecSettings>& codecs) {
-  std::stringstream out;
-  out << '{';
-  for (size_t i = 0; i < codecs.size(); ++i) {
-    out << codecs[i].codec.ToString();
-    if (i != codecs.size() - 1) {
-      out << ", ";
-    }
-  }
-  out << '}';
-  return out.str();
-}
-
-bool WebRtcVideoChannel2::GetSendCodec(VideoCodec* codec) {
-  if (!send_codec_) {
-    LOG(LS_VERBOSE) << "GetSendCodec: No send codec set.";
-    return false;
-  }
-  *codec = send_codec_->codec;
-  return true;
-}
-
-bool WebRtcVideoChannel2::SetSend(bool send) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetSend");
-  LOG(LS_VERBOSE) << "SetSend: " << (send ? "true" : "false");
-  if (send && !send_codec_) {
-    LOG(LS_ERROR) << "SetSend(true) called before setting codec.";
-    return false;
-  }
-  {
-    rtc::CritScope stream_lock(&stream_crit_);
-    for (const auto& kv : send_streams_) {
-      kv.second->SetSend(send);
-    }
-  }
-  sending_ = send;
-  return true;
-}
-
-// TODO(nisse): The enable argument was used for mute logic which has
-// been moved to VideoBroadcaster. So remove the argument from this
-// method.
-bool WebRtcVideoChannel2::SetVideoSend(
-    uint32_t ssrc,
-    bool enable,
-    const VideoOptions* options,
-    rtc::VideoSourceInterface<webrtc::VideoFrame>* source) {
-  TRACE_EVENT0("webrtc", "SetVideoSend");
-  RTC_DCHECK(ssrc != 0);
-  LOG(LS_INFO) << "SetVideoSend (ssrc= " << ssrc << ", enable = " << enable
-               << ", options: " << (options ? options->ToString() : "nullptr")
-               << ", source = " << (source ? "(source)" : "nullptr") << ")";
-
-  rtc::CritScope stream_lock(&stream_crit_);
-  const auto& kv = send_streams_.find(ssrc);
-  if (kv == send_streams_.end()) {
-    // Allow unknown ssrc only if source is null.
-    RTC_CHECK(source == nullptr);
-    LOG(LS_ERROR) << "No sending stream on ssrc " << ssrc;
-    return false;
-  }
-
-  return kv->second->SetVideoSend(enable, options, source);
-}
-
-bool WebRtcVideoChannel2::ValidateSendSsrcAvailability(
-    const StreamParams& sp) const {
-  for (uint32_t ssrc : sp.ssrcs) {
-    if (send_ssrcs_.find(ssrc) != send_ssrcs_.end()) {
-      LOG(LS_ERROR) << "Send stream with SSRC '" << ssrc << "' already exists.";
-      return false;
-    }
-  }
-  return true;
-}
-
-bool WebRtcVideoChannel2::ValidateReceiveSsrcAvailability(
-    const StreamParams& sp) const {
-  for (uint32_t ssrc : sp.ssrcs) {
-    if (receive_ssrcs_.find(ssrc) != receive_ssrcs_.end()) {
-      LOG(LS_ERROR) << "Receive stream with SSRC '" << ssrc
-                    << "' already exists.";
-      return false;
-    }
-  }
-  return true;
-}
-
-bool WebRtcVideoChannel2::AddSendStream(const StreamParams& sp) {
-  LOG(LS_INFO) << "AddSendStream: " << sp.ToString();
-  if (!ValidateStreamParams(sp))
-    return false;
-
-  rtc::CritScope stream_lock(&stream_crit_);
-
-  if (!ValidateSendSsrcAvailability(sp))
-    return false;
-
-  for (uint32_t used_ssrc : sp.ssrcs)
-    send_ssrcs_.insert(used_ssrc);
-
-  webrtc::VideoSendStream::Config config(this);
-  config.suspend_below_min_bitrate = video_config_.suspend_below_min_bitrate;
-  config.periodic_alr_bandwidth_probing =
-      video_config_.periodic_alr_bandwidth_probing;
-  WebRtcVideoSendStream* stream = new WebRtcVideoSendStream(
-      call_, sp, std::move(config), default_send_options_,
-      external_encoder_factory_, video_config_.enable_cpu_overuse_detection,
-      bitrate_config_.max_bitrate_bps, send_codec_, send_rtp_extensions_,
-      send_params_);
-
-  uint32_t ssrc = sp.first_ssrc();
-  RTC_DCHECK(ssrc != 0);
-  send_streams_[ssrc] = stream;
-
-  if (rtcp_receiver_report_ssrc_ == kDefaultRtcpReceiverReportSsrc) {
-    rtcp_receiver_report_ssrc_ = ssrc;
-    LOG(LS_INFO) << "SetLocalSsrc on all the receive streams because we added "
-                    "a send stream.";
-    for (auto& kv : receive_streams_)
-      kv.second->SetLocalSsrc(ssrc);
-  }
-  if (sending_) {
-    stream->SetSend(true);
-  }
-
-  return true;
-}
-
-bool WebRtcVideoChannel2::RemoveSendStream(uint32_t ssrc) {
-  LOG(LS_INFO) << "RemoveSendStream: " << ssrc;
-
-  WebRtcVideoSendStream* removed_stream;
-  {
-    rtc::CritScope stream_lock(&stream_crit_);
-    std::map<uint32_t, WebRtcVideoSendStream*>::iterator it =
-        send_streams_.find(ssrc);
-    if (it == send_streams_.end()) {
-      return false;
-    }
-
-    for (uint32_t old_ssrc : it->second->GetSsrcs())
-      send_ssrcs_.erase(old_ssrc);
-
-    removed_stream = it->second;
-    send_streams_.erase(it);
-
-    // Switch receiver report SSRCs, the one in use is no longer valid.
-    if (rtcp_receiver_report_ssrc_ == ssrc) {
-      rtcp_receiver_report_ssrc_ = send_streams_.empty()
-                                       ? kDefaultRtcpReceiverReportSsrc
-                                       : send_streams_.begin()->first;
-      LOG(LS_INFO) << "SetLocalSsrc on all the receive streams because the "
-                      "previous local SSRC was removed.";
-
-      for (auto& kv : receive_streams_) {
-        kv.second->SetLocalSsrc(rtcp_receiver_report_ssrc_);
-      }
-    }
-  }
-
-  delete removed_stream;
-
-  return true;
-}
-
-void WebRtcVideoChannel2::DeleteReceiveStream(
-    WebRtcVideoChannel2::WebRtcVideoReceiveStream* stream) {
-  for (uint32_t old_ssrc : stream->GetSsrcs())
-    receive_ssrcs_.erase(old_ssrc);
-  delete stream;
-}
-
-bool WebRtcVideoChannel2::AddRecvStream(const StreamParams& sp) {
-  return AddRecvStream(sp, false);
-}
-
-bool WebRtcVideoChannel2::AddRecvStream(const StreamParams& sp,
-                                        bool default_stream) {
-  RTC_DCHECK(thread_checker_.CalledOnValidThread());
-
-  LOG(LS_INFO) << "AddRecvStream" << (default_stream ? " (default stream)" : "")
-               << ": " << sp.ToString();
-  if (!ValidateStreamParams(sp))
-    return false;
-
-  uint32_t ssrc = sp.first_ssrc();
-  RTC_DCHECK(ssrc != 0);  // TODO(pbos): Is this ever valid?
-
-  rtc::CritScope stream_lock(&stream_crit_);
-  // Remove running stream if this was a default stream.
-  const auto& prev_stream = receive_streams_.find(ssrc);
-  if (prev_stream != receive_streams_.end()) {
-    if (default_stream || !prev_stream->second->IsDefaultStream()) {
-      LOG(LS_ERROR) << "Receive stream for SSRC '" << ssrc
-                    << "' already exists.";
-      return false;
-    }
-    DeleteReceiveStream(prev_stream->second);
-    receive_streams_.erase(prev_stream);
-  }
-
-  if (!ValidateReceiveSsrcAvailability(sp))
-    return false;
-
-  for (uint32_t used_ssrc : sp.ssrcs)
-    receive_ssrcs_.insert(used_ssrc);
-
-  webrtc::VideoReceiveStream::Config config(this);
-  webrtc::FlexfecReceiveStream::Config flexfec_config(this);
-  ConfigureReceiverRtp(&config, &flexfec_config, sp);
-
-  config.disable_prerenderer_smoothing =
-      video_config_.disable_prerenderer_smoothing;
-  config.sync_group = sp.sync_label;
-
-  receive_streams_[ssrc] = new WebRtcVideoReceiveStream(
-      call_, sp, std::move(config), external_decoder_factory_, default_stream,
-      recv_codecs_, flexfec_config);
-
-  return true;
-}
-
-void WebRtcVideoChannel2::ConfigureReceiverRtp(
-    webrtc::VideoReceiveStream::Config* config,
-    webrtc::FlexfecReceiveStream::Config* flexfec_config,
-    const StreamParams& sp) const {
-  uint32_t ssrc = sp.first_ssrc();
-
-  config->rtp.remote_ssrc = ssrc;
-  config->rtp.local_ssrc = rtcp_receiver_report_ssrc_;
-
-  // TODO(pbos): This protection is against setting the same local ssrc as
-  // remote which is not permitted by the lower-level API. RTCP requires a
-  // corresponding sender SSRC. Figure out what to do when we don't have
-  // (receive-only) or know a good local SSRC.
-  if (config->rtp.remote_ssrc == config->rtp.local_ssrc) {
-    if (config->rtp.local_ssrc != kDefaultRtcpReceiverReportSsrc) {
-      config->rtp.local_ssrc = kDefaultRtcpReceiverReportSsrc;
-    } else {
-      config->rtp.local_ssrc = kDefaultRtcpReceiverReportSsrc + 1;
-    }
-  }
-
-  // Whether or not the receive stream sends reduced size RTCP is determined
-  // by the send params.
-  // TODO(deadbeef): Once we change "send_params" to "sender_params" and
-  // "recv_params" to "receiver_params", we should get this out of
-  // receiver_params_.
-  config->rtp.rtcp_mode = send_params_.rtcp.reduced_size
-                              ? webrtc::RtcpMode::kReducedSize
-                              : webrtc::RtcpMode::kCompound;
-
-  config->rtp.remb = send_codec_ ? HasRemb(send_codec_->codec) : false;
-  config->rtp.transport_cc =
-      send_codec_ ? HasTransportCc(send_codec_->codec) : false;
-
-  sp.GetFidSsrc(ssrc, &config->rtp.rtx_ssrc);
-
-  config->rtp.extensions = recv_rtp_extensions_;
-
-  // TODO(brandtr): Generalize when we add support for multistream protection.
-  if (sp.GetFecFrSsrc(ssrc, &flexfec_config->remote_ssrc)) {
-    flexfec_config->protected_media_ssrcs = {ssrc};
-    flexfec_config->local_ssrc = config->rtp.local_ssrc;
-    flexfec_config->rtcp_mode = config->rtp.rtcp_mode;
-    // TODO(brandtr): We should be spec-compliant and set |transport_cc| here
-    // based on the rtcp-fb for the FlexFEC codec, not the media codec.
-    flexfec_config->transport_cc = config->rtp.transport_cc;
-    flexfec_config->rtp_header_extensions = config->rtp.extensions;
-  }
-}
-
-bool WebRtcVideoChannel2::RemoveRecvStream(uint32_t ssrc) {
-  LOG(LS_INFO) << "RemoveRecvStream: " << ssrc;
-  if (ssrc == 0) {
-    LOG(LS_ERROR) << "RemoveRecvStream with 0 ssrc is not supported.";
-    return false;
-  }
-
-  rtc::CritScope stream_lock(&stream_crit_);
-  std::map<uint32_t, WebRtcVideoReceiveStream*>::iterator stream =
-      receive_streams_.find(ssrc);
-  if (stream == receive_streams_.end()) {
-    LOG(LS_ERROR) << "Stream not found for ssrc: " << ssrc;
-    return false;
-  }
-  DeleteReceiveStream(stream->second);
-  receive_streams_.erase(stream);
-
-  return true;
-}
-
-bool WebRtcVideoChannel2::SetSink(
-    uint32_t ssrc,
-    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
-  LOG(LS_INFO) << "SetSink: ssrc:" << ssrc << " "
-               << (sink ? "(ptr)" : "nullptr");
-  if (ssrc == 0) {
-    default_unsignalled_ssrc_handler_.SetDefaultSink(this, sink);
-    return true;
-  }
-
-  rtc::CritScope stream_lock(&stream_crit_);
-  std::map<uint32_t, WebRtcVideoReceiveStream*>::iterator it =
-      receive_streams_.find(ssrc);
-  if (it == receive_streams_.end()) {
-    return false;
-  }
-
-  it->second->SetSink(sink);
-  return true;
-}
-
-bool WebRtcVideoChannel2::GetStats(VideoMediaInfo* info) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::GetStats");
-
-  // Log stats periodically.
-  bool log_stats = false;
-  int64_t now_ms = rtc::TimeMillis();
-  if (last_stats_log_ms_ == -1 ||
-      now_ms - last_stats_log_ms_ > kStatsLogIntervalMs) {
-    last_stats_log_ms_ = now_ms;
-    log_stats = true;
-  }
-
-  info->Clear();
-  FillSenderStats(info, log_stats);
-  FillReceiverStats(info, log_stats);
-  FillSendAndReceiveCodecStats(info);
-  webrtc::Call::Stats stats = call_->GetStats();
-  FillBandwidthEstimationStats(stats, info);
-  if (stats.rtt_ms != -1) {
-    for (size_t i = 0; i < info->senders.size(); ++i) {
-      info->senders[i].rtt_ms = stats.rtt_ms;
-    }
-  }
-
-  if (log_stats)
-    LOG(LS_INFO) << stats.ToString(now_ms);
-
-  return true;
-}
-
-void WebRtcVideoChannel2::FillSenderStats(VideoMediaInfo* video_media_info,
-                                          bool log_stats) {
-  rtc::CritScope stream_lock(&stream_crit_);
-  for (std::map<uint32_t, WebRtcVideoSendStream*>::iterator it =
-           send_streams_.begin();
-       it != send_streams_.end(); ++it) {
-    video_media_info->senders.push_back(
-        it->second->GetVideoSenderInfo(log_stats));
-  }
-}
-
-void WebRtcVideoChannel2::FillReceiverStats(VideoMediaInfo* video_media_info,
-                                            bool log_stats) {
-  rtc::CritScope stream_lock(&stream_crit_);
-  for (std::map<uint32_t, WebRtcVideoReceiveStream*>::iterator it =
-           receive_streams_.begin();
-       it != receive_streams_.end(); ++it) {
-    video_media_info->receivers.push_back(
-        it->second->GetVideoReceiverInfo(log_stats));
-  }
-}
-
-void WebRtcVideoChannel2::FillBandwidthEstimationStats(
-    const webrtc::Call::Stats& stats,
-    VideoMediaInfo* video_media_info) {
-  BandwidthEstimationInfo bwe_info;
-  bwe_info.available_send_bandwidth = stats.send_bandwidth_bps;
-  bwe_info.available_recv_bandwidth = stats.recv_bandwidth_bps;
-  bwe_info.bucket_delay = stats.pacer_delay_ms;
-
-  // Get send stream bitrate stats.
-  rtc::CritScope stream_lock(&stream_crit_);
-  for (std::map<uint32_t, WebRtcVideoSendStream*>::iterator stream =
-           send_streams_.begin();
-       stream != send_streams_.end(); ++stream) {
-    stream->second->FillBandwidthEstimationInfo(&bwe_info);
-  }
-  video_media_info->bw_estimations.push_back(bwe_info);
-}
-
-void WebRtcVideoChannel2::FillSendAndReceiveCodecStats(
-    VideoMediaInfo* video_media_info) {
-  for (const VideoCodec& codec : send_params_.codecs) {
-    webrtc::RtpCodecParameters codec_params = codec.ToCodecParameters();
-    video_media_info->send_codecs.insert(
-        std::make_pair(codec_params.payload_type, std::move(codec_params)));
-  }
-  for (const VideoCodec& codec : recv_params_.codecs) {
-    webrtc::RtpCodecParameters codec_params = codec.ToCodecParameters();
-    video_media_info->receive_codecs.insert(
-        std::make_pair(codec_params.payload_type, std::move(codec_params)));
-  }
-}
-
-void WebRtcVideoChannel2::OnPacketReceived(
-    rtc::CopyOnWriteBuffer* packet,
-    const rtc::PacketTime& packet_time) {
-  const webrtc::PacketTime webrtc_packet_time(packet_time.timestamp,
-                                              packet_time.not_before);
-  const webrtc::PacketReceiver::DeliveryStatus delivery_result =
-      call_->Receiver()->DeliverPacket(
-          webrtc::MediaType::VIDEO,
-          packet->cdata(), packet->size(),
-          webrtc_packet_time);
-  switch (delivery_result) {
-    case webrtc::PacketReceiver::DELIVERY_OK:
-      return;
-    case webrtc::PacketReceiver::DELIVERY_PACKET_ERROR:
-      return;
-    case webrtc::PacketReceiver::DELIVERY_UNKNOWN_SSRC:
-      break;
-  }
-
-  uint32_t ssrc = 0;
-  if (!GetRtpSsrc(packet->cdata(), packet->size(), &ssrc)) {
-    return;
-  }
-
-  int payload_type = 0;
-  if (!GetRtpPayloadType(packet->cdata(), packet->size(), &payload_type)) {
-    return;
-  }
-
-  // See if this payload_type is registered as one that usually gets its own
-  // SSRC (RTX) or at least is safe to drop either way (FEC). If it is, and
-  // it wasn't handled above by DeliverPacket, that means we don't know what
-  // stream it associates with, and we shouldn't ever create an implicit channel
-  // for these.
-  for (auto& codec : recv_codecs_) {
-    if (payload_type == codec.rtx_payload_type ||
-        payload_type == codec.ulpfec.red_rtx_payload_type ||
-        payload_type == codec.ulpfec.ulpfec_payload_type ||
-        payload_type == codec.flexfec_payload_type) {
-      return;
-    }
-  }
-
-  switch (unsignalled_ssrc_handler_->OnUnsignalledSsrc(this, ssrc)) {
-    case UnsignalledSsrcHandler::kDropPacket:
-      return;
-    case UnsignalledSsrcHandler::kDeliverPacket:
-      break;
-  }
-
-  if (call_->Receiver()->DeliverPacket(
-          webrtc::MediaType::VIDEO,
-          packet->cdata(), packet->size(),
-          webrtc_packet_time) != webrtc::PacketReceiver::DELIVERY_OK) {
-    LOG(LS_WARNING) << "Failed to deliver RTP packet on re-delivery.";
-    return;
-  }
-}
-
-void WebRtcVideoChannel2::OnRtcpReceived(
-    rtc::CopyOnWriteBuffer* packet,
-    const rtc::PacketTime& packet_time) {
-  const webrtc::PacketTime webrtc_packet_time(packet_time.timestamp,
-                                              packet_time.not_before);
-  // TODO(pbos): Check webrtc::PacketReceiver::DELIVERY_OK once we deliver
-  // for both audio and video on the same path. Since BundleFilter doesn't
-  // filter RTCP anymore incoming RTCP packets could've been going to audio (so
-  // logging failures spam the log).
-  call_->Receiver()->DeliverPacket(
-      webrtc::MediaType::VIDEO,
-      packet->cdata(), packet->size(),
-      webrtc_packet_time);
-}
-
-void WebRtcVideoChannel2::OnReadyToSend(bool ready) {
-  LOG(LS_VERBOSE) << "OnReadyToSend: " << (ready ? "Ready." : "Not ready.");
-  call_->SignalChannelNetworkState(
-      webrtc::MediaType::VIDEO,
-      ready ? webrtc::kNetworkUp : webrtc::kNetworkDown);
-}
-
-void WebRtcVideoChannel2::OnNetworkRouteChanged(
-    const std::string& transport_name,
-    const rtc::NetworkRoute& network_route) {
-  call_->OnNetworkRouteChanged(transport_name, network_route);
-}
-
-void WebRtcVideoChannel2::OnTransportOverheadChanged(
-    int transport_overhead_per_packet) {
-  call_->OnTransportOverheadChanged(webrtc::MediaType::VIDEO,
-                                    transport_overhead_per_packet);
-}
-
-void WebRtcVideoChannel2::SetInterface(NetworkInterface* iface) {
-  MediaChannel::SetInterface(iface);
-  // Set the RTP recv/send buffer to a bigger size
-  MediaChannel::SetOption(NetworkInterface::ST_RTP,
-                          rtc::Socket::OPT_RCVBUF,
-                          kVideoRtpBufferSize);
-
-  // Speculative change to increase the outbound socket buffer size.
-  // In b/15152257, we are seeing a significant number of packets discarded
-  // due to lack of socket buffer space, although it's not yet clear what the
-  // ideal value should be.
-  MediaChannel::SetOption(NetworkInterface::ST_RTP,
-                          rtc::Socket::OPT_SNDBUF,
-                          kVideoRtpBufferSize);
-}
-
-bool WebRtcVideoChannel2::SendRtp(const uint8_t* data,
-                                  size_t len,
-                                  const webrtc::PacketOptions& options) {
-  rtc::CopyOnWriteBuffer packet(data, len, kMaxRtpPacketLen);
-  rtc::PacketOptions rtc_options;
-  rtc_options.packet_id = options.packet_id;
-  return MediaChannel::SendPacket(&packet, rtc_options);
-}
-
-bool WebRtcVideoChannel2::SendRtcp(const uint8_t* data, size_t len) {
-  rtc::CopyOnWriteBuffer packet(data, len, kMaxRtpPacketLen);
-  return MediaChannel::SendRtcp(&packet, rtc::PacketOptions());
-}
-
-WebRtcVideoChannel2::WebRtcVideoSendStream::VideoSendStreamParameters::
-    VideoSendStreamParameters(
-        webrtc::VideoSendStream::Config config,
-        const VideoOptions& options,
-        int max_bitrate_bps,
-        const rtc::Optional<VideoCodecSettings>& codec_settings)
-    : config(std::move(config)),
-      options(options),
-      max_bitrate_bps(max_bitrate_bps),
-      conference_mode(false),
-      codec_settings(codec_settings) {}
-
-WebRtcVideoChannel2::WebRtcVideoSendStream::AllocatedEncoder::AllocatedEncoder(
-    webrtc::VideoEncoder* encoder,
-    const cricket::VideoCodec& codec,
-    bool external)
-    : encoder(encoder),
-      external_encoder(nullptr),
-      codec(codec),
-      external(external) {
-  if (external) {
-    external_encoder = encoder;
-    this->encoder =
-        new webrtc::VideoEncoderSoftwareFallbackWrapper(codec, encoder);
-  }
-}
-
-WebRtcVideoChannel2::WebRtcVideoSendStream::WebRtcVideoSendStream(
-    webrtc::Call* call,
-    const StreamParams& sp,
-    webrtc::VideoSendStream::Config config,
-    const VideoOptions& options,
-    WebRtcVideoEncoderFactory* external_encoder_factory,
-    bool enable_cpu_overuse_detection,
-    int max_bitrate_bps,
-    const rtc::Optional<VideoCodecSettings>& codec_settings,
-    const rtc::Optional<std::vector<webrtc::RtpExtension>>& rtp_extensions,
-    // TODO(deadbeef): Don't duplicate information between send_params,
-    // rtp_extensions, options, etc.
-    const VideoSendParameters& send_params)
-    : worker_thread_(rtc::Thread::Current()),
-      ssrcs_(sp.ssrcs),
-      ssrc_groups_(sp.ssrc_groups),
-      call_(call),
-      enable_cpu_overuse_detection_(enable_cpu_overuse_detection),
-      source_(nullptr),
-      external_encoder_factory_(external_encoder_factory),
-      internal_encoder_factory_(new InternalEncoderFactory()),
-      stream_(nullptr),
-      encoder_sink_(nullptr),
-      parameters_(std::move(config), options, max_bitrate_bps, codec_settings),
-      rtp_parameters_(CreateRtpParametersWithOneEncoding()),
-      allocated_encoder_(nullptr, cricket::VideoCodec(), false),
-      sending_(false) {
-  parameters_.config.rtp.max_packet_size = kVideoMtu;
-  parameters_.conference_mode = send_params.conference_mode;
-
-  sp.GetPrimarySsrcs(&parameters_.config.rtp.ssrcs);
-
-  // ValidateStreamParams should prevent this from happening.
-  RTC_CHECK(!parameters_.config.rtp.ssrcs.empty());
-  rtp_parameters_.encodings[0].ssrc =
-      rtc::Optional<uint32_t>(parameters_.config.rtp.ssrcs[0]);
-
-  // RTX.
-  sp.GetFidSsrcs(parameters_.config.rtp.ssrcs,
-                 &parameters_.config.rtp.rtx.ssrcs);
-
-  // FlexFEC SSRCs.
-  // TODO(brandtr): This code needs to be generalized when we add support for
-  // multistream protection.
-  if (IsFlexfecFieldTrialEnabled()) {
-    uint32_t flexfec_ssrc;
-    bool flexfec_enabled = false;
-    for (uint32_t primary_ssrc : parameters_.config.rtp.ssrcs) {
-      if (sp.GetFecFrSsrc(primary_ssrc, &flexfec_ssrc)) {
-        if (flexfec_enabled) {
-          LOG(LS_INFO) << "Multiple FlexFEC streams proposed by remote, but "
-                          "our implementation only supports a single FlexFEC "
-                          "stream. Will not enable FlexFEC for proposed "
-                          "stream with SSRC: "
-                       << flexfec_ssrc << ".";
-          continue;
-        }
-
-        flexfec_enabled = true;
-        parameters_.config.rtp.flexfec.ssrc = flexfec_ssrc;
-        parameters_.config.rtp.flexfec.protected_media_ssrcs = {primary_ssrc};
-      }
-    }
-  }
-
-  parameters_.config.rtp.c_name = sp.cname;
-  if (rtp_extensions) {
-    parameters_.config.rtp.extensions = *rtp_extensions;
-  }
-  parameters_.config.rtp.rtcp_mode = send_params.rtcp.reduced_size
-                                         ? webrtc::RtcpMode::kReducedSize
-                                         : webrtc::RtcpMode::kCompound;
-  if (codec_settings) {
-    bool force_encoder_allocation = false;
-    SetCodec(*codec_settings, force_encoder_allocation);
-  }
-}
-
-WebRtcVideoChannel2::WebRtcVideoSendStream::~WebRtcVideoSendStream() {
-  if (stream_ != NULL) {
-    call_->DestroyVideoSendStream(stream_);
-  }
-  DestroyVideoEncoder(&allocated_encoder_);
-}
-
-bool WebRtcVideoChannel2::WebRtcVideoSendStream::SetVideoSend(
-    bool enable,
-    const VideoOptions* options,
-    rtc::VideoSourceInterface<webrtc::VideoFrame>* source) {
-  TRACE_EVENT0("webrtc", "WebRtcVideoSendStream::SetVideoSend");
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-
-  // Ignore |options| pointer if |enable| is false.
-  bool options_present = enable && options;
-
-  if (options_present) {
-    VideoOptions old_options = parameters_.options;
-    parameters_.options.SetAll(*options);
-    if (parameters_.options.is_screencast.value_or(false) !=
-            old_options.is_screencast.value_or(false) &&
-        parameters_.codec_settings) {
-      // If screen content settings change, we may need to recreate the codec
-      // instance so that the correct type is used.
-
-      bool force_encoder_allocation = true;
-      SetCodec(*parameters_.codec_settings, force_encoder_allocation);
-      // Mark screenshare parameter as being updated, then test for any other
-      // changes that may require codec reconfiguration.
-      old_options.is_screencast = options->is_screencast;
-    }
-    if (parameters_.options != old_options) {
-      ReconfigureEncoder();
-    }
-  }
-
-  if (source_ && stream_) {
-    stream_->SetSource(
-        nullptr, webrtc::VideoSendStream::DegradationPreference::kBalanced);
-  }
-  // Switch to the new source.
-  source_ = source;
-  if (source && stream_) {
-    // Do not adapt resolution for screen content as this will likely
-    // result in blurry and unreadable text.
-    // |this| acts like a VideoSource to make sure SinkWants are handled on the
-    // correct thread.
-    stream_->SetSource(
-        this, enable_cpu_overuse_detection_ &&
-                      !parameters_.options.is_screencast.value_or(false)
-                  ? webrtc::VideoSendStream::DegradationPreference::kBalanced
-                  : webrtc::VideoSendStream::DegradationPreference::
-                        kMaintainResolution);
-  }
-  return true;
-}
-
-const std::vector<uint32_t>&
-WebRtcVideoChannel2::WebRtcVideoSendStream::GetSsrcs() const {
-  return ssrcs_;
-}
-
-WebRtcVideoChannel2::WebRtcVideoSendStream::AllocatedEncoder
-WebRtcVideoChannel2::WebRtcVideoSendStream::CreateVideoEncoder(
-    const VideoCodec& codec,
-    bool force_encoder_allocation) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  // Do not re-create encoders of the same type.
-  if (!force_encoder_allocation && codec == allocated_encoder_.codec &&
-      allocated_encoder_.encoder != nullptr) {
-    return allocated_encoder_;
-  }
-
-  // Try creating external encoder.
-  if (external_encoder_factory_ != nullptr &&
-      FindMatchingCodec(external_encoder_factory_->supported_codecs(), codec)) {
-    webrtc::VideoEncoder* encoder =
-        external_encoder_factory_->CreateVideoEncoder(codec);
-    if (encoder != nullptr)
-      return AllocatedEncoder(encoder, codec, true /* is_external */);
-  }
-
-  // Try creating internal encoder.
-  if (FindMatchingCodec(internal_encoder_factory_->supported_codecs(), codec)) {
-    if (parameters_.encoder_config.content_type ==
-            webrtc::VideoEncoderConfig::ContentType::kScreen &&
-        parameters_.conference_mode && UseSimulcastScreenshare()) {
-      // TODO(sprang): Remove this adapter once libvpx supports simulcast with
-      // same-resolution substreams.
-      WebRtcSimulcastEncoderFactory adapter_factory(
-          internal_encoder_factory_.get());
-      return AllocatedEncoder(adapter_factory.CreateVideoEncoder(codec), codec,
-                              false /* is_external */);
-    }
-    return AllocatedEncoder(
-        internal_encoder_factory_->CreateVideoEncoder(codec), codec,
-        false /* is_external */);
-  }
-
-  // This shouldn't happen, we should not be trying to create something we don't
-  // support.
-  RTC_NOTREACHED();
-  return AllocatedEncoder(NULL, cricket::VideoCodec(), false);
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::DestroyVideoEncoder(
-    AllocatedEncoder* encoder) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  if (encoder->external) {
-    external_encoder_factory_->DestroyVideoEncoder(encoder->external_encoder);
-  }
-  delete encoder->encoder;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::SetCodec(
-    const VideoCodecSettings& codec_settings,
-    bool force_encoder_allocation) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  parameters_.encoder_config = CreateVideoEncoderConfig(codec_settings.codec);
-  RTC_DCHECK_GT(parameters_.encoder_config.number_of_streams, 0);
-
-  AllocatedEncoder new_encoder =
-      CreateVideoEncoder(codec_settings.codec, force_encoder_allocation);
-  parameters_.config.encoder_settings.encoder = new_encoder.encoder;
-  parameters_.config.encoder_settings.full_overuse_time = new_encoder.external;
-  parameters_.config.encoder_settings.payload_name = codec_settings.codec.name;
-  parameters_.config.encoder_settings.payload_type = codec_settings.codec.id;
-  if (new_encoder.external) {
-    webrtc::VideoCodecType type =
-        webrtc::PayloadNameToCodecType(codec_settings.codec.name)
-            .value_or(webrtc::kVideoCodecUnknown);
-    parameters_.config.encoder_settings.internal_source =
-        external_encoder_factory_->EncoderTypeHasInternalSource(type);
-  } else {
-    parameters_.config.encoder_settings.internal_source = false;
-  }
-  parameters_.config.rtp.ulpfec = codec_settings.ulpfec;
-  if (IsFlexfecFieldTrialEnabled()) {
-    parameters_.config.rtp.flexfec.payload_type =
-        codec_settings.flexfec_payload_type;
-  }
-
-  // Set RTX payload type if RTX is enabled.
-  if (!parameters_.config.rtp.rtx.ssrcs.empty()) {
-    if (codec_settings.rtx_payload_type == -1) {
-      LOG(LS_WARNING) << "RTX SSRCs configured but there's no configured RTX "
-                         "payload type. Ignoring.";
-      parameters_.config.rtp.rtx.ssrcs.clear();
-    } else {
-      parameters_.config.rtp.rtx.payload_type = codec_settings.rtx_payload_type;
-    }
-  }
-
-  parameters_.config.rtp.nack.rtp_history_ms =
-      HasNack(codec_settings.codec) ? kNackHistoryMs : 0;
-
-  parameters_.codec_settings =
-      rtc::Optional<WebRtcVideoChannel2::VideoCodecSettings>(codec_settings);
-
-  LOG(LS_INFO) << "RecreateWebRtcStream (send) because of SetCodec.";
-  RecreateWebRtcStream();
-  if (allocated_encoder_.encoder != new_encoder.encoder) {
-    DestroyVideoEncoder(&allocated_encoder_);
-    allocated_encoder_ = new_encoder;
-  }
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::SetSendParameters(
-    const ChangedSendParameters& params) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  // |recreate_stream| means construction-time parameters have changed and the
-  // sending stream needs to be reset with the new config.
-  bool recreate_stream = false;
-  if (params.rtcp_mode) {
-    parameters_.config.rtp.rtcp_mode = *params.rtcp_mode;
-    recreate_stream = true;
-  }
-  if (params.rtp_header_extensions) {
-    parameters_.config.rtp.extensions = *params.rtp_header_extensions;
-    recreate_stream = true;
-  }
-  if (params.max_bandwidth_bps) {
-    parameters_.max_bitrate_bps = *params.max_bandwidth_bps;
-    ReconfigureEncoder();
-  }
-  if (params.conference_mode) {
-    parameters_.conference_mode = *params.conference_mode;
-  }
-
-  // Set codecs and options.
-  if (params.codec) {
-    bool force_encoder_allocation = false;
-    SetCodec(*params.codec, force_encoder_allocation);
-    recreate_stream = false;  // SetCodec has already recreated the stream.
-  } else if (params.conference_mode && parameters_.codec_settings) {
-    bool force_encoder_allocation = false;
-    SetCodec(*parameters_.codec_settings, force_encoder_allocation);
-    recreate_stream = false;  // SetCodec has already recreated the stream.
-  }
-  if (recreate_stream) {
-    LOG(LS_INFO) << "RecreateWebRtcStream (send) because of SetSendParameters";
-    RecreateWebRtcStream();
-  }
-}
-
-bool WebRtcVideoChannel2::WebRtcVideoSendStream::SetRtpParameters(
-    const webrtc::RtpParameters& new_parameters) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  if (!ValidateRtpParameters(new_parameters)) {
-    return false;
-  }
-
-  bool reconfigure_encoder = new_parameters.encodings[0].max_bitrate_bps !=
-                             rtp_parameters_.encodings[0].max_bitrate_bps;
-  rtp_parameters_ = new_parameters;
-  // Codecs are currently handled at the WebRtcVideoChannel2 level.
-  rtp_parameters_.codecs.clear();
-  if (reconfigure_encoder) {
-    ReconfigureEncoder();
-  }
-  // Encoding may have been activated/deactivated.
-  UpdateSendState();
-  return true;
-}
-
-webrtc::RtpParameters
-WebRtcVideoChannel2::WebRtcVideoSendStream::GetRtpParameters() const {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  return rtp_parameters_;
-}
-
-bool WebRtcVideoChannel2::WebRtcVideoSendStream::ValidateRtpParameters(
-    const webrtc::RtpParameters& rtp_parameters) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  if (rtp_parameters.encodings.size() != 1) {
-    LOG(LS_ERROR)
-        << "Attempted to set RtpParameters without exactly one encoding";
-    return false;
-  }
-  if (rtp_parameters.encodings[0].ssrc != rtp_parameters_.encodings[0].ssrc) {
-    LOG(LS_ERROR) << "Attempted to set RtpParameters with modified SSRC";
-    return false;
-  }
-  return true;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::UpdateSendState() {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  // TODO(deadbeef): Need to handle more than one encoding in the future.
-  RTC_DCHECK(rtp_parameters_.encodings.size() == 1u);
-  if (sending_ && rtp_parameters_.encodings[0].active) {
-    RTC_DCHECK(stream_ != nullptr);
-    stream_->Start();
-  } else {
-    if (stream_ != nullptr) {
-      stream_->Stop();
-    }
-  }
-}
-
-webrtc::VideoEncoderConfig
-WebRtcVideoChannel2::WebRtcVideoSendStream::CreateVideoEncoderConfig(
-    const VideoCodec& codec) const {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  webrtc::VideoEncoderConfig encoder_config;
-  bool is_screencast = parameters_.options.is_screencast.value_or(false);
-  if (is_screencast) {
-    encoder_config.min_transmit_bitrate_bps =
-        1000 * parameters_.options.screencast_min_bitrate_kbps.value_or(0);
-    encoder_config.content_type =
-        webrtc::VideoEncoderConfig::ContentType::kScreen;
-  } else {
-    encoder_config.min_transmit_bitrate_bps = 0;
-    encoder_config.content_type =
-        webrtc::VideoEncoderConfig::ContentType::kRealtimeVideo;
-  }
-
-  // By default, the stream count for the codec configuration should match the
-  // number of negotiated ssrcs. But if the codec is blacklisted for simulcast
-  // or a screencast (and not in simulcast screenshare experiment), only
-  // configure a single stream.
-  encoder_config.number_of_streams = parameters_.config.rtp.ssrcs.size();
-  if (IsCodecBlacklistedForSimulcast(codec.name) ||
-      (is_screencast &&
-       (!UseSimulcastScreenshare() || !parameters_.conference_mode))) {
-    encoder_config.number_of_streams = 1;
-  }
-
-  int stream_max_bitrate = parameters_.max_bitrate_bps;
-  if (rtp_parameters_.encodings[0].max_bitrate_bps) {
-    stream_max_bitrate =
-        MinPositive(*(rtp_parameters_.encodings[0].max_bitrate_bps),
-                    parameters_.max_bitrate_bps);
-  }
-
-  int codec_max_bitrate_kbps;
-  if (codec.GetParam(kCodecParamMaxBitrate, &codec_max_bitrate_kbps)) {
-    stream_max_bitrate = codec_max_bitrate_kbps * 1000;
-  }
-  encoder_config.max_bitrate_bps = stream_max_bitrate;
-
-  int max_qp = kDefaultQpMax;
-  codec.GetParam(kCodecParamMaxQuantization, &max_qp);
-  encoder_config.video_stream_factory =
-      new rtc::RefCountedObject<EncoderStreamFactory>(
-          codec.name, max_qp, kDefaultVideoMaxFramerate, is_screencast,
-          parameters_.conference_mode);
-  return encoder_config;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::ReconfigureEncoder() {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  if (!stream_) {
-    // The webrtc::VideoSendStream |stream_| has not yet been created but other
-    // parameters has changed.
-    return;
-  }
-
-  RTC_DCHECK_GT(parameters_.encoder_config.number_of_streams, 0);
-
-  RTC_CHECK(parameters_.codec_settings);
-  VideoCodecSettings codec_settings = *parameters_.codec_settings;
-
-  webrtc::VideoEncoderConfig encoder_config =
-      CreateVideoEncoderConfig(codec_settings.codec);
-
-  encoder_config.encoder_specific_settings = ConfigureVideoEncoderSettings(
-      codec_settings.codec);
-
-  stream_->ReconfigureVideoEncoder(encoder_config.Copy());
-
-  encoder_config.encoder_specific_settings = NULL;
-
-  parameters_.encoder_config = std::move(encoder_config);
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::SetSend(bool send) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  sending_ = send;
-  UpdateSendState();
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::RemoveSink(
-    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  RTC_DCHECK(encoder_sink_ == sink);
-  encoder_sink_ = nullptr;
-  source_->RemoveSink(sink);
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::AddOrUpdateSink(
-    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink,
-    const rtc::VideoSinkWants& wants) {
-  if (worker_thread_ == rtc::Thread::Current()) {
-    // AddOrUpdateSink is called on |worker_thread_| if this is the first
-    // registration of |sink|.
-    RTC_DCHECK_RUN_ON(&thread_checker_);
-    encoder_sink_ = sink;
-    source_->AddOrUpdateSink(encoder_sink_, wants);
-  } else {
-    // Subsequent calls to AddOrUpdateSink will happen on the encoder task
-    // queue.
-    invoker_.AsyncInvoke<void>(
-        RTC_FROM_HERE, worker_thread_, [this, sink, wants] {
-          RTC_DCHECK_RUN_ON(&thread_checker_);
-          // |sink| may be invalidated after this task was posted since
-          // RemoveSink is called on the worker thread.
-          bool encoder_sink_valid = (sink == encoder_sink_);
-          if (source_ && encoder_sink_valid) {
-            source_->AddOrUpdateSink(encoder_sink_, wants);
-          }
-        });
-  }
-}
-
-VideoSenderInfo WebRtcVideoChannel2::WebRtcVideoSendStream::GetVideoSenderInfo(
-    bool log_stats) {
-  VideoSenderInfo info;
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  for (uint32_t ssrc : parameters_.config.rtp.ssrcs)
-    info.add_ssrc(ssrc);
-
-  if (parameters_.codec_settings) {
-    info.codec_name = parameters_.codec_settings->codec.name;
-    info.codec_payload_type = rtc::Optional<int>(
-        parameters_.codec_settings->codec.id);
-  }
-
-  if (stream_ == NULL)
-    return info;
-
-  webrtc::VideoSendStream::Stats stats = stream_->GetStats();
-
-  if (log_stats)
-    LOG(LS_INFO) << stats.ToString(rtc::TimeMillis());
-
-  info.adapt_changes = stats.number_of_cpu_adapt_changes;
-  info.adapt_reason =
-      stats.cpu_limited_resolution ? ADAPTREASON_CPU : ADAPTREASON_NONE;
-
-  // Get bandwidth limitation info from stream_->GetStats().
-  // Input resolution (output from video_adapter) can be further scaled down or
-  // higher video layer(s) can be dropped due to bitrate constraints.
-  // Note, adapt_changes only include changes from the video_adapter.
-  if (stats.bw_limited_resolution)
-    info.adapt_reason |= ADAPTREASON_BANDWIDTH;
-
-  info.encoder_implementation_name = stats.encoder_implementation_name;
-  info.ssrc_groups = ssrc_groups_;
-  info.framerate_input = stats.input_frame_rate;
-  info.framerate_sent = stats.encode_frame_rate;
-  info.avg_encode_ms = stats.avg_encode_time_ms;
-  info.encode_usage_percent = stats.encode_usage_percent;
-  info.frames_encoded = stats.frames_encoded;
-  info.qp_sum = stats.qp_sum;
-
-  info.nominal_bitrate = stats.media_bitrate_bps;
-  info.preferred_bitrate = stats.preferred_media_bitrate_bps;
-
-  info.send_frame_width = 0;
-  info.send_frame_height = 0;
-  for (std::map<uint32_t, webrtc::VideoSendStream::StreamStats>::iterator it =
-           stats.substreams.begin();
-       it != stats.substreams.end(); ++it) {
-    // TODO(pbos): Wire up additional stats, such as padding bytes.
-    webrtc::VideoSendStream::StreamStats stream_stats = it->second;
-    info.bytes_sent += stream_stats.rtp_stats.transmitted.payload_bytes +
-                       stream_stats.rtp_stats.transmitted.header_bytes +
-                       stream_stats.rtp_stats.transmitted.padding_bytes;
-    info.packets_sent += stream_stats.rtp_stats.transmitted.packets;
-    info.packets_lost += stream_stats.rtcp_stats.cumulative_lost;
-    if (stream_stats.width > info.send_frame_width)
-      info.send_frame_width = stream_stats.width;
-    if (stream_stats.height > info.send_frame_height)
-      info.send_frame_height = stream_stats.height;
-    info.firs_rcvd += stream_stats.rtcp_packet_type_counts.fir_packets;
-    info.nacks_rcvd += stream_stats.rtcp_packet_type_counts.nack_packets;
-    info.plis_rcvd += stream_stats.rtcp_packet_type_counts.pli_packets;
-  }
-
-  if (!stats.substreams.empty()) {
-    // TODO(pbos): Report fraction lost per SSRC.
-    webrtc::VideoSendStream::StreamStats first_stream_stats =
-        stats.substreams.begin()->second;
-    info.fraction_lost =
-        static_cast<float>(first_stream_stats.rtcp_stats.fraction_lost) /
-        (1 << 8);
-  }
-
-  return info;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::FillBandwidthEstimationInfo(
-    BandwidthEstimationInfo* bwe_info) {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  if (stream_ == NULL) {
-    return;
-  }
-  webrtc::VideoSendStream::Stats stats = stream_->GetStats();
-  for (std::map<uint32_t, webrtc::VideoSendStream::StreamStats>::iterator it =
-           stats.substreams.begin();
-       it != stats.substreams.end(); ++it) {
-    bwe_info->transmit_bitrate += it->second.total_bitrate_bps;
-    bwe_info->retransmit_bitrate += it->second.retransmit_bitrate_bps;
-  }
-  bwe_info->target_enc_bitrate += stats.target_media_bitrate_bps;
-  bwe_info->actual_enc_bitrate += stats.media_bitrate_bps;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoSendStream::RecreateWebRtcStream() {
-  RTC_DCHECK_RUN_ON(&thread_checker_);
-  if (stream_ != NULL) {
-    call_->DestroyVideoSendStream(stream_);
-  }
-
-  RTC_CHECK(parameters_.codec_settings);
-  RTC_DCHECK_EQ((parameters_.encoder_config.content_type ==
-                 webrtc::VideoEncoderConfig::ContentType::kScreen),
-                parameters_.options.is_screencast.value_or(false))
-      << "encoder content type inconsistent with screencast option";
-  parameters_.encoder_config.encoder_specific_settings =
-      ConfigureVideoEncoderSettings(parameters_.codec_settings->codec);
-
-  webrtc::VideoSendStream::Config config = parameters_.config.Copy();
-  if (!config.rtp.rtx.ssrcs.empty() && config.rtp.rtx.payload_type == -1) {
-    LOG(LS_WARNING) << "RTX SSRCs configured but there's no configured RTX "
-                       "payload type the set codec. Ignoring RTX.";
-    config.rtp.rtx.ssrcs.clear();
-  }
-  stream_ = call_->CreateVideoSendStream(std::move(config),
-                                         parameters_.encoder_config.Copy());
-
-  parameters_.encoder_config.encoder_specific_settings = NULL;
-
-  if (source_) {
-    // Do not adapt resolution for screen content as this will likely result in
-    // blurry and unreadable text.
-    // |this| acts like a VideoSource to make sure SinkWants are handled on the
-    // correct thread.
-    stream_->SetSource(
-        this, enable_cpu_overuse_detection_ &&
-                      !parameters_.options.is_screencast.value_or(false)
-                  ? webrtc::VideoSendStream::DegradationPreference::kBalanced
-                  : webrtc::VideoSendStream::DegradationPreference::
-                        kMaintainResolution);
-  }
-
-  // Call stream_->Start() if necessary conditions are met.
-  UpdateSendState();
-}
-
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::WebRtcVideoReceiveStream(
-    webrtc::Call* call,
-    const StreamParams& sp,
-    webrtc::VideoReceiveStream::Config config,
-    WebRtcVideoDecoderFactory* external_decoder_factory,
-    bool default_stream,
-    const std::vector<VideoCodecSettings>& recv_codecs,
-    const webrtc::FlexfecReceiveStream::Config& flexfec_config)
-    : call_(call),
-      stream_params_(sp),
-      stream_(NULL),
-      default_stream_(default_stream),
-      config_(std::move(config)),
-      flexfec_config_(flexfec_config),
-      flexfec_stream_(nullptr),
-      external_decoder_factory_(external_decoder_factory),
-      sink_(NULL),
-      first_frame_timestamp_(-1),
-      estimated_remote_start_ntp_time_ms_(0) {
-  config_.renderer = this;
-  std::vector<AllocatedDecoder> old_decoders;
-  ConfigureCodecs(recv_codecs, &old_decoders);
-  RecreateWebRtcStream();
-  RTC_DCHECK(old_decoders.empty());
-}
-
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::AllocatedDecoder::
-    AllocatedDecoder(webrtc::VideoDecoder* decoder,
-                     webrtc::VideoCodecType type,
-                     bool external)
-    : decoder(decoder),
-      external_decoder(nullptr),
-      type(type),
-      external(external) {
-  if (external) {
-    external_decoder = decoder;
-    this->decoder =
-        new webrtc::VideoDecoderSoftwareFallbackWrapper(type, external_decoder);
-  }
-}
-
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::~WebRtcVideoReceiveStream() {
-  if (flexfec_stream_) {
-    call_->DestroyFlexfecReceiveStream(flexfec_stream_);
-  }
-  call_->DestroyVideoReceiveStream(stream_);
-  ClearDecoders(&allocated_decoders_);
-}
-
-const std::vector<uint32_t>&
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetSsrcs() const {
-  return stream_params_.ssrcs;
-}
-
-rtc::Optional<uint32_t>
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetFirstPrimarySsrc() const {
-  std::vector<uint32_t> primary_ssrcs;
-  stream_params_.GetPrimarySsrcs(&primary_ssrcs);
-
-  if (primary_ssrcs.empty()) {
-    LOG(LS_WARNING) << "Empty primary ssrcs vector, returning empty optional";
-    return rtc::Optional<uint32_t>();
-  } else {
-    return rtc::Optional<uint32_t>(primary_ssrcs[0]);
-  }
-}
-
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::AllocatedDecoder
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::CreateOrReuseVideoDecoder(
-    std::vector<AllocatedDecoder>* old_decoders,
-    const VideoCodec& codec) {
-  webrtc::VideoCodecType type = webrtc::PayloadNameToCodecType(codec.name)
-                                    .value_or(webrtc::kVideoCodecUnknown);
-
-  for (size_t i = 0; i < old_decoders->size(); ++i) {
-    if ((*old_decoders)[i].type == type) {
-      AllocatedDecoder decoder = (*old_decoders)[i];
-      (*old_decoders)[i] = old_decoders->back();
-      old_decoders->pop_back();
-      return decoder;
-    }
-  }
-
-  if (external_decoder_factory_ != NULL) {
-    webrtc::VideoDecoder* decoder =
-        external_decoder_factory_->CreateVideoDecoderWithParams(
-            type, {stream_params_.id});
-    if (decoder != NULL) {
-      return AllocatedDecoder(decoder, type, true /* is_external */);
-    }
-  }
-
-  InternalDecoderFactory internal_decoder_factory;
-  return AllocatedDecoder(internal_decoder_factory.CreateVideoDecoderWithParams(
-                              type, {stream_params_.id}),
-                          type, false /* is_external */);
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::ConfigureCodecs(
-    const std::vector<VideoCodecSettings>& recv_codecs,
-    std::vector<AllocatedDecoder>* old_decoders) {
-  *old_decoders = allocated_decoders_;
-  allocated_decoders_.clear();
-  config_.decoders.clear();
-  for (size_t i = 0; i < recv_codecs.size(); ++i) {
-    AllocatedDecoder allocated_decoder =
-        CreateOrReuseVideoDecoder(old_decoders, recv_codecs[i].codec);
-    allocated_decoders_.push_back(allocated_decoder);
-
-    webrtc::VideoReceiveStream::Decoder decoder;
-    decoder.decoder = allocated_decoder.decoder;
-    decoder.payload_type = recv_codecs[i].codec.id;
-    decoder.payload_name = recv_codecs[i].codec.name;
-    decoder.codec_params = recv_codecs[i].codec.params;
-    config_.decoders.push_back(decoder);
-  }
-
-  config_.rtp.rtx_payload_types.clear();
-  for (const VideoCodecSettings& recv_codec : recv_codecs) {
-    config_.rtp.rtx_payload_types[recv_codec.codec.id] =
-        recv_codec.rtx_payload_type;
-  }
-
-  config_.rtp.ulpfec = recv_codecs.front().ulpfec;
-  flexfec_config_.payload_type = recv_codecs.front().flexfec_payload_type;
-
-  config_.rtp.nack.rtp_history_ms =
-      HasNack(recv_codecs.begin()->codec) ? kNackHistoryMs : 0;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetLocalSsrc(
-    uint32_t local_ssrc) {
-  // TODO(pbos): Consider turning this sanity check into a RTC_DCHECK. You
-  // should not be able to create a sender with the same SSRC as a receiver, but
-  // right now this can't be done due to unittests depending on receiving what
-  // they are sending from the same MediaChannel.
-  if (local_ssrc == config_.rtp.remote_ssrc) {
-    LOG(LS_INFO) << "Ignoring call to SetLocalSsrc because parameters are "
-                    "unchanged; local_ssrc=" << local_ssrc;
-    return;
-  }
-
-  config_.rtp.local_ssrc = local_ssrc;
-  flexfec_config_.local_ssrc = local_ssrc;
-  LOG(LS_INFO)
-      << "RecreateWebRtcStream (recv) because of SetLocalSsrc; local_ssrc="
-      << local_ssrc;
-  RecreateWebRtcStream();
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetFeedbackParameters(
-    bool nack_enabled,
-    bool remb_enabled,
-    bool transport_cc_enabled,
-    webrtc::RtcpMode rtcp_mode) {
-  int nack_history_ms = nack_enabled ? kNackHistoryMs : 0;
-  if (config_.rtp.nack.rtp_history_ms == nack_history_ms &&
-      config_.rtp.remb == remb_enabled &&
-      config_.rtp.transport_cc == transport_cc_enabled &&
-      config_.rtp.rtcp_mode == rtcp_mode) {
-    LOG(LS_INFO)
-        << "Ignoring call to SetFeedbackParameters because parameters are "
-           "unchanged; nack="
-        << nack_enabled << ", remb=" << remb_enabled
-        << ", transport_cc=" << transport_cc_enabled;
-    return;
-  }
-  config_.rtp.remb = remb_enabled;
-  config_.rtp.nack.rtp_history_ms = nack_history_ms;
-  config_.rtp.transport_cc = transport_cc_enabled;
-  config_.rtp.rtcp_mode = rtcp_mode;
-  // TODO(brandtr): We should be spec-compliant and set |transport_cc| here
-  // based on the rtcp-fb for the FlexFEC codec, not the media codec.
-  flexfec_config_.transport_cc = config_.rtp.transport_cc;
-  flexfec_config_.rtcp_mode = config_.rtp.rtcp_mode;
-  LOG(LS_INFO)
-      << "RecreateWebRtcStream (recv) because of SetFeedbackParameters; nack="
-      << nack_enabled << ", remb=" << remb_enabled
-      << ", transport_cc=" << transport_cc_enabled;
-  RecreateWebRtcStream();
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetRecvParameters(
-    const ChangedRecvParameters& params) {
-  bool needs_recreation = false;
-  std::vector<AllocatedDecoder> old_decoders;
-  if (params.codec_settings) {
-    ConfigureCodecs(*params.codec_settings, &old_decoders);
-    needs_recreation = true;
-  }
-  if (params.rtp_header_extensions) {
-    config_.rtp.extensions = *params.rtp_header_extensions;
-    flexfec_config_.rtp_header_extensions = *params.rtp_header_extensions;
-    needs_recreation = true;
-  }
-  if (needs_recreation) {
-    LOG(LS_INFO) << "RecreateWebRtcStream (recv) because of SetRecvParameters";
-    RecreateWebRtcStream();
-    ClearDecoders(&old_decoders);
-  }
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::RecreateWebRtcStream() {
-  if (stream_) {
-    call_->DestroyVideoReceiveStream(stream_);
-    stream_ = nullptr;
-  }
-  if (flexfec_stream_) {
-    call_->DestroyFlexfecReceiveStream(flexfec_stream_);
-    flexfec_stream_ = nullptr;
-  }
-  if (flexfec_config_.IsCompleteAndEnabled()) {
-    flexfec_stream_ = call_->CreateFlexfecReceiveStream(flexfec_config_);
-    flexfec_stream_->Start();
-  }
-  stream_ = call_->CreateVideoReceiveStream(config_.Copy());
-  stream_->Start();
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::ClearDecoders(
-    std::vector<AllocatedDecoder>* allocated_decoders) {
-  for (size_t i = 0; i < allocated_decoders->size(); ++i) {
-    if ((*allocated_decoders)[i].external) {
-      external_decoder_factory_->DestroyVideoDecoder(
-          (*allocated_decoders)[i].external_decoder);
-    }
-    delete (*allocated_decoders)[i].decoder;
-  }
-  allocated_decoders->clear();
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::OnFrame(
-    const webrtc::VideoFrame& frame) {
-  rtc::CritScope crit(&sink_lock_);
-
-  if (first_frame_timestamp_ < 0)
-    first_frame_timestamp_ = frame.timestamp();
-  int64_t rtp_time_elapsed_since_first_frame =
-      (timestamp_wraparound_handler_.Unwrap(frame.timestamp()) -
-       first_frame_timestamp_);
-  int64_t elapsed_time_ms = rtp_time_elapsed_since_first_frame /
-                            (cricket::kVideoCodecClockrate / 1000);
-  if (frame.ntp_time_ms() > 0)
-    estimated_remote_start_ntp_time_ms_ = frame.ntp_time_ms() - elapsed_time_ms;
-
-  if (sink_ == NULL) {
-    LOG(LS_WARNING) << "VideoReceiveStream not connected to a VideoSink.";
-    return;
-  }
-
-  sink_->OnFrame(frame);
-}
-
-bool WebRtcVideoChannel2::WebRtcVideoReceiveStream::IsDefaultStream() const {
-  return default_stream_;
-}
-
-void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetSink(
-    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
-  rtc::CritScope crit(&sink_lock_);
-  sink_ = sink;
-}
-
-std::string
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetCodecNameFromPayloadType(
-    int payload_type) {
-  for (const webrtc::VideoReceiveStream::Decoder& decoder : config_.decoders) {
-    if (decoder.payload_type == payload_type) {
-      return decoder.payload_name;
-    }
-  }
-  return "";
-}
-
-VideoReceiverInfo
-WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetVideoReceiverInfo(
-    bool log_stats) {
-  VideoReceiverInfo info;
-  info.ssrc_groups = stream_params_.ssrc_groups;
-  info.add_ssrc(config_.rtp.remote_ssrc);
-  webrtc::VideoReceiveStream::Stats stats = stream_->GetStats();
-  info.decoder_implementation_name = stats.decoder_implementation_name;
-  if (stats.current_payload_type != -1) {
-    info.codec_payload_type = rtc::Optional<int>(
-        stats.current_payload_type);
-  }
-  info.bytes_rcvd = stats.rtp_stats.transmitted.payload_bytes +
-                    stats.rtp_stats.transmitted.header_bytes +
-                    stats.rtp_stats.transmitted.padding_bytes;
-  info.packets_rcvd = stats.rtp_stats.transmitted.packets;
-  info.packets_lost = stats.rtcp_stats.cumulative_lost;
-  info.fraction_lost =
-      static_cast<float>(stats.rtcp_stats.fraction_lost) / (1 << 8);
-
-  info.framerate_rcvd = stats.network_frame_rate;
-  info.framerate_decoded = stats.decode_frame_rate;
-  info.framerate_output = stats.render_frame_rate;
-  info.frame_width = stats.width;
-  info.frame_height = stats.height;
-
-  {
-    rtc::CritScope frame_cs(&sink_lock_);
-    info.capture_start_ntp_time_ms = estimated_remote_start_ntp_time_ms_;
-  }
-
-  info.decode_ms = stats.decode_ms;
-  info.max_decode_ms = stats.max_decode_ms;
-  info.current_delay_ms = stats.current_delay_ms;
-  info.target_delay_ms = stats.target_delay_ms;
-  info.jitter_buffer_ms = stats.jitter_buffer_ms;
-  info.min_playout_delay_ms = stats.min_playout_delay_ms;
-  info.render_delay_ms = stats.render_delay_ms;
-  info.frames_received = stats.frame_counts.key_frames +
-                         stats.frame_counts.delta_frames;
-  info.frames_decoded = stats.frames_decoded;
-  info.frames_rendered = stats.frames_rendered;
-  info.qp_sum = stats.qp_sum;
-
-  info.codec_name = GetCodecNameFromPayloadType(stats.current_payload_type);
-
-  info.firs_sent = stats.rtcp_packet_type_counts.fir_packets;
-  info.plis_sent = stats.rtcp_packet_type_counts.pli_packets;
-  info.nacks_sent = stats.rtcp_packet_type_counts.nack_packets;
-
-  if (log_stats)
-    LOG(LS_INFO) << stats.ToString(rtc::TimeMillis());
-
-  return info;
-}
-
-WebRtcVideoChannel2::VideoCodecSettings::VideoCodecSettings()
-    : flexfec_payload_type(-1), rtx_payload_type(-1) {}
-
-bool WebRtcVideoChannel2::VideoCodecSettings::operator==(
-    const WebRtcVideoChannel2::VideoCodecSettings& other) const {
-  return codec == other.codec && ulpfec == other.ulpfec &&
-         flexfec_payload_type == other.flexfec_payload_type &&
-         rtx_payload_type == other.rtx_payload_type;
-}
-
-bool WebRtcVideoChannel2::VideoCodecSettings::operator!=(
-    const WebRtcVideoChannel2::VideoCodecSettings& other) const {
-  return !(*this == other);
-}
-
-std::vector<WebRtcVideoChannel2::VideoCodecSettings>
-WebRtcVideoChannel2::MapCodecs(const std::vector<VideoCodec>& codecs) {
-  RTC_DCHECK(!codecs.empty());
-
-  std::vector<VideoCodecSettings> video_codecs;
-  std::map<int, bool> payload_used;
-  std::map<int, VideoCodec::CodecType> payload_codec_type;
-  // |rtx_mapping| maps video payload type to rtx payload type.
-  std::map<int, int> rtx_mapping;
-
-  webrtc::UlpfecConfig ulpfec_config;
-  int flexfec_payload_type = -1;
-
-  for (size_t i = 0; i < codecs.size(); ++i) {
-    const VideoCodec& in_codec = codecs[i];
-    int payload_type = in_codec.id;
-
-    if (payload_used[payload_type]) {
-      LOG(LS_ERROR) << "Payload type already registered: "
-                    << in_codec.ToString();
-      return std::vector<VideoCodecSettings>();
-    }
-    payload_used[payload_type] = true;
-    payload_codec_type[payload_type] = in_codec.GetCodecType();
-
-    switch (in_codec.GetCodecType()) {
-      case VideoCodec::CODEC_RED: {
-        // RED payload type, should not have duplicates.
-        RTC_DCHECK_EQ(-1, ulpfec_config.red_payload_type);
-        ulpfec_config.red_payload_type = in_codec.id;
-        continue;
-      }
-
-      case VideoCodec::CODEC_ULPFEC: {
-        // ULPFEC payload type, should not have duplicates.
-        RTC_DCHECK_EQ(-1, ulpfec_config.ulpfec_payload_type);
-        ulpfec_config.ulpfec_payload_type = in_codec.id;
-        continue;
-      }
-
-      case VideoCodec::CODEC_FLEXFEC: {
-        // FlexFEC payload type, should not have duplicates.
-        RTC_DCHECK_EQ(-1, flexfec_payload_type);
-        flexfec_payload_type = in_codec.id;
-        continue;
-      }
-
-      case VideoCodec::CODEC_RTX: {
-        int associated_payload_type;
-        if (!in_codec.GetParam(kCodecParamAssociatedPayloadType,
-                               &associated_payload_type) ||
-            !IsValidRtpPayloadType(associated_payload_type)) {
-          LOG(LS_ERROR)
-              << "RTX codec with invalid or no associated payload type: "
-              << in_codec.ToString();
-          return std::vector<VideoCodecSettings>();
-        }
-        rtx_mapping[associated_payload_type] = in_codec.id;
-        continue;
-      }
-
-      case VideoCodec::CODEC_VIDEO:
-        break;
-    }
-
-    video_codecs.push_back(VideoCodecSettings());
-    video_codecs.back().codec = in_codec;
-  }
-
-  // One of these codecs should have been a video codec. Only having FEC
-  // parameters into this code is a logic error.
-  RTC_DCHECK(!video_codecs.empty());
-
-  for (std::map<int, int>::const_iterator it = rtx_mapping.begin();
-       it != rtx_mapping.end();
-       ++it) {
-    if (!payload_used[it->first]) {
-      LOG(LS_ERROR) << "RTX mapped to payload not in codec list.";
-      return std::vector<VideoCodecSettings>();
-    }
-    if (payload_codec_type[it->first] != VideoCodec::CODEC_VIDEO &&
-        payload_codec_type[it->first] != VideoCodec::CODEC_RED) {
-      LOG(LS_ERROR) << "RTX not mapped to regular video codec or RED codec.";
-      return std::vector<VideoCodecSettings>();
-    }
-
-    if (it->first == ulpfec_config.red_payload_type) {
-      ulpfec_config.red_rtx_payload_type = it->second;
-    }
-  }
-
-  for (size_t i = 0; i < video_codecs.size(); ++i) {
-    video_codecs[i].ulpfec = ulpfec_config;
-    video_codecs[i].flexfec_payload_type = flexfec_payload_type;
-    if (rtx_mapping[video_codecs[i].codec.id] != 0 &&
-        rtx_mapping[video_codecs[i].codec.id] !=
-            ulpfec_config.red_payload_type) {
-      video_codecs[i].rtx_payload_type = rtx_mapping[video_codecs[i].codec.id];
-    }
-  }
-
-  return video_codecs;
-}
-
-}  // namespace cricket
+/*
+ *  Copyright (c) 2014 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include "webrtc/media/engine/webrtcvideoengine2.h"
+
+#include <stdio.h>
+#include <algorithm>
+#include <set>
+#include <string>
+#include <utility>
+
+#include "webrtc/api/video/i420_buffer.h"
+#include "webrtc/base/copyonwritebuffer.h"
+#include "webrtc/base/logging.h"
+#include "webrtc/base/stringutils.h"
+#include "webrtc/base/timeutils.h"
+#include "webrtc/base/trace_event.h"
+#include "webrtc/call/call.h"
+#include "webrtc/common_video/h264/profile_level_id.h"
+#include "webrtc/media/engine/constants.h"
+#include "webrtc/media/engine/internalencoderfactory.h"
+#include "webrtc/media/engine/internaldecoderfactory.h"
+#include "webrtc/media/engine/simulcast.h"
+#include "webrtc/media/engine/videoencodersoftwarefallbackwrapper.h"
+#include "webrtc/media/engine/videodecodersoftwarefallbackwrapper.h"
+#include "webrtc/media/engine/webrtcmediaengine.h"
+#include "webrtc/media/engine/webrtcvideoencoderfactory.h"
+#include "webrtc/media/engine/webrtcvoiceengine.h"
+#include "webrtc/modules/video_coding/codecs/vp8/simulcast_encoder_adapter.h"
+#include "webrtc/system_wrappers/include/field_trial.h"
+#include "webrtc/video_decoder.h"
+#include "webrtc/video_encoder.h"
+
+namespace cricket {
+namespace {
+
+// If this field trial is enabled, we will enable sending FlexFEC and disable
+// sending ULPFEC whenever the former has been negotiated. Receiving FlexFEC
+// is enabled whenever FlexFEC has been negotiated.
+bool IsFlexfecFieldTrialEnabled() {
+  return webrtc::field_trial::FindFullName("WebRTC-FlexFEC-03") == "Enabled";
+}
+
+// Wrap cricket::WebRtcVideoEncoderFactory as a webrtc::VideoEncoderFactory.
+class EncoderFactoryAdapter : public webrtc::VideoEncoderFactory {
+ public:
+  // EncoderFactoryAdapter doesn't take ownership of |factory|, which is owned
+  // by e.g. PeerConnectionFactory.
+  explicit EncoderFactoryAdapter(cricket::WebRtcVideoEncoderFactory* factory)
+      : factory_(factory) {}
+  virtual ~EncoderFactoryAdapter() {}
+
+  // Implement webrtc::VideoEncoderFactory.
+  webrtc::VideoEncoder* Create() override {
+    return factory_->CreateVideoEncoder(VideoCodec(kVp8CodecName));
+  }
+
+  void Destroy(webrtc::VideoEncoder* encoder) override {
+    return factory_->DestroyVideoEncoder(encoder);
+  }
+
+ private:
+  cricket::WebRtcVideoEncoderFactory* const factory_;
+};
+
+// An encoder factory that wraps Create requests for simulcastable codec types
+// with a webrtc::SimulcastEncoderAdapter. Non simulcastable codec type
+// requests are just passed through to the contained encoder factory.
+class WebRtcSimulcastEncoderFactory
+    : public cricket::WebRtcVideoEncoderFactory {
+ public:
+  // WebRtcSimulcastEncoderFactory doesn't take ownership of |factory|, which is
+  // owned by e.g. PeerConnectionFactory.
+  explicit WebRtcSimulcastEncoderFactory(
+      cricket::WebRtcVideoEncoderFactory* factory)
+      : factory_(factory) {}
+
+  static bool UseSimulcastEncoderFactory(
+      const std::vector<cricket::VideoCodec>& codecs) {
+    // If any codec is VP8, use the simulcast factory. If asked to create a
+    // non-VP8 codec, we'll just return a contained factory encoder directly.
+    for (const auto& codec : codecs) {
+      if (CodecNamesEq(codec.name.c_str(), kVp8CodecName)) {
+        return true;
+      }
+    }
+    return false;
+  }
+
+  webrtc::VideoEncoder* CreateVideoEncoder(
+      const cricket::VideoCodec& codec) override {
+    RTC_DCHECK(factory_ != NULL);
+    // If it's a codec type we can simulcast, create a wrapped encoder.
+    if (CodecNamesEq(codec.name.c_str(), kVp8CodecName)) {
+      return new webrtc::SimulcastEncoderAdapter(
+          new EncoderFactoryAdapter(factory_));
+    }
+    webrtc::VideoEncoder* encoder = factory_->CreateVideoEncoder(codec);
+    if (encoder) {
+      non_simulcast_encoders_.push_back(encoder);
+    }
+    return encoder;
+  }
+
+  const std::vector<cricket::VideoCodec>& supported_codecs() const override {
+    return factory_->supported_codecs();
+  }
+
+  bool EncoderTypeHasInternalSource(
+      webrtc::VideoCodecType type) const override {
+    return factory_->EncoderTypeHasInternalSource(type);
+  }
+
+  void DestroyVideoEncoder(webrtc::VideoEncoder* encoder) override {
+    // Check first to see if the encoder wasn't wrapped in a
+    // SimulcastEncoderAdapter. In that case, ask the factory to destroy it.
+    if (std::remove(non_simulcast_encoders_.begin(),
+                    non_simulcast_encoders_.end(),
+                    encoder) != non_simulcast_encoders_.end()) {
+      factory_->DestroyVideoEncoder(encoder);
+      return;
+    }
+
+    // Otherwise, SimulcastEncoderAdapter can be deleted directly, and will call
+    // DestroyVideoEncoder on the factory for individual encoder instances.
+    delete encoder;
+  }
+
+ private:
+  // Disable overloaded virtual function warning. TODO(magjed): Remove once
+  // http://crbug/webrtc/6402 is fixed.
+  using cricket::WebRtcVideoEncoderFactory::CreateVideoEncoder;
+
+  cricket::WebRtcVideoEncoderFactory* factory_;
+  // A list of encoders that were created without being wrapped in a
+  // SimulcastEncoderAdapter.
+  std::vector<webrtc::VideoEncoder*> non_simulcast_encoders_;
+};
+
+void AddDefaultFeedbackParams(VideoCodec* codec) {
+  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamCcm, kRtcpFbCcmParamFir));
+  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamNack, kParamValueEmpty));
+  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamNack, kRtcpFbNackParamPli));
+  codec->AddFeedbackParam(FeedbackParam(kRtcpFbParamRemb, kParamValueEmpty));
+  codec->AddFeedbackParam(
+      FeedbackParam(kRtcpFbParamTransportCc, kParamValueEmpty));
+}
+
+static std::string CodecVectorToString(const std::vector<VideoCodec>& codecs) {
+  std::stringstream out;
+  out << '{';
+  for (size_t i = 0; i < codecs.size(); ++i) {
+    out << codecs[i].ToString();
+    if (i != codecs.size() - 1) {
+      out << ", ";
+    }
+  }
+  out << '}';
+  return out.str();
+}
+
+static bool ValidateCodecFormats(const std::vector<VideoCodec>& codecs) {
+  bool has_video = false;
+  for (size_t i = 0; i < codecs.size(); ++i) {
+    if (!codecs[i].ValidateCodecFormat()) {
+      return false;
+    }
+    if (codecs[i].GetCodecType() == VideoCodec::CODEC_VIDEO) {
+      has_video = true;
+    }
+  }
+  if (!has_video) {
+    LOG(LS_ERROR) << "Setting codecs without a video codec is invalid: "
+                  << CodecVectorToString(codecs);
+    return false;
+  }
+  return true;
+}
+
+static bool ValidateStreamParams(const StreamParams& sp) {
+  if (sp.ssrcs.empty()) {
+    LOG(LS_ERROR) << "No SSRCs in stream parameters: " << sp.ToString();
+    return false;
+  }
+
+  std::vector<uint32_t> primary_ssrcs;
+  sp.GetPrimarySsrcs(&primary_ssrcs);
+  std::vector<uint32_t> rtx_ssrcs;
+  sp.GetFidSsrcs(primary_ssrcs, &rtx_ssrcs);
+  for (uint32_t rtx_ssrc : rtx_ssrcs) {
+    bool rtx_ssrc_present = false;
+    for (uint32_t sp_ssrc : sp.ssrcs) {
+      if (sp_ssrc == rtx_ssrc) {
+        rtx_ssrc_present = true;
+        break;
+      }
+    }
+    if (!rtx_ssrc_present) {
+      LOG(LS_ERROR) << "RTX SSRC '" << rtx_ssrc
+                    << "' missing from StreamParams ssrcs: " << sp.ToString();
+      return false;
+    }
+  }
+  if (!rtx_ssrcs.empty() && primary_ssrcs.size() != rtx_ssrcs.size()) {
+    LOG(LS_ERROR)
+        << "RTX SSRCs exist, but don't cover all SSRCs (unsupported): "
+        << sp.ToString();
+    return false;
+  }
+
+  return true;
+}
+
+// Returns true if the given codec is disallowed from doing simulcast.
+bool IsCodecBlacklistedForSimulcast(const std::string& codec_name) {
+  return CodecNamesEq(codec_name, kH264CodecName) ||
+         CodecNamesEq(codec_name, kVp9CodecName);
+}
+
+// The selected thresholds for QVGA and VGA corresponded to a QP around 10.
+// The change in QP declined above the selected bitrates.
+static int GetMaxDefaultVideoBitrateKbps(int width, int height) {
+  if (width * height <= 320 * 240) {
+    return 600;
+  } else if (width * height <= 640 * 480) {
+    return 1700;
+  } else if (width * height <= 960 * 540) {
+    return 2000;
+  } else {
+    return 2500;
+  }
+}
+
+bool GetVp9LayersFromFieldTrialGroup(int* num_spatial_layers,
+                                     int* num_temporal_layers) {
+  std::string group = webrtc::field_trial::FindFullName("WebRTC-SupportVP9SVC");
+  if (group.empty())
+    return false;
+
+  if (sscanf(group.c_str(), "EnabledByFlag_%dSL%dTL", num_spatial_layers,
+             num_temporal_layers) != 2) {
+    return false;
+  }
+  const int kMaxSpatialLayers = 2;
+  if (*num_spatial_layers > kMaxSpatialLayers || *num_spatial_layers < 1)
+    return false;
+
+  const int kMaxTemporalLayers = 3;
+  if (*num_temporal_layers > kMaxTemporalLayers || *num_temporal_layers < 1)
+    return false;
+
+  return true;
+}
+
+int GetDefaultVp9SpatialLayers() {
+  int num_sl;
+  int num_tl;
+  if (GetVp9LayersFromFieldTrialGroup(&num_sl, &num_tl)) {
+    return num_sl;
+  }
+  return 1;
+}
+
+int GetDefaultVp9TemporalLayers() {
+  int num_sl;
+  int num_tl;
+  if (GetVp9LayersFromFieldTrialGroup(&num_sl, &num_tl)) {
+    return num_tl;
+  }
+  return 1;
+}
+
+class EncoderStreamFactory
+    : public webrtc::VideoEncoderConfig::VideoStreamFactoryInterface {
+ public:
+  EncoderStreamFactory(std::string codec_name,
+                       int max_qp,
+                       int max_framerate,
+                       bool is_screencast,
+                       bool conference_mode)
+      : codec_name_(codec_name),
+        max_qp_(max_qp),
+        max_framerate_(max_framerate),
+        is_screencast_(is_screencast),
+        conference_mode_(conference_mode) {}
+
+ private:
+  std::vector<webrtc::VideoStream> CreateEncoderStreams(
+      int width,
+      int height,
+      const webrtc::VideoEncoderConfig& encoder_config) override {
+    if (is_screencast_ &&
+        (!conference_mode_ || !cricket::UseSimulcastScreenshare())) {
+      RTC_DCHECK_EQ(1, encoder_config.number_of_streams);
+    }
+    if (encoder_config.number_of_streams > 1 ||
+        (CodecNamesEq(codec_name_, kVp8CodecName) && is_screencast_ &&
+         conference_mode_)) {
+      return GetSimulcastConfig(encoder_config.number_of_streams, width, height,
+                                encoder_config.max_bitrate_bps, max_qp_,
+                                max_framerate_, is_screencast_);
+    }
+
+    // For unset max bitrates set default bitrate for non-simulcast.
+    int max_bitrate_bps =
+        (encoder_config.max_bitrate_bps > 0)
+            ? encoder_config.max_bitrate_bps
+            : GetMaxDefaultVideoBitrateKbps(width, height) * 1000;
+
+    webrtc::VideoStream stream;
+    stream.width = width;
+    stream.height = height;
+    stream.max_framerate = max_framerate_;
+    stream.min_bitrate_bps = kMinVideoBitrateKbps * 1000;
+    stream.target_bitrate_bps = stream.max_bitrate_bps = max_bitrate_bps;
+    stream.max_qp = max_qp_;
+
+    if (CodecNamesEq(codec_name_, kVp9CodecName) && !is_screencast_) {
+      stream.temporal_layer_thresholds_bps.resize(
+          GetDefaultVp9TemporalLayers() - 1);
+    }
+
+    std::vector<webrtc::VideoStream> streams;
+    streams.push_back(stream);
+    return streams;
+  }
+
+  const std::string codec_name_;
+  const int max_qp_;
+  const int max_framerate_;
+  const bool is_screencast_;
+  const bool conference_mode_;
+};
+
+}  // namespace
+
+// Constants defined in webrtc/media/engine/constants.h
+// TODO(pbos): Move these to a separate constants.cc file.
+const int kMinVideoBitrateKbps = 30;
+
+const int kVideoMtu = 1200;
+const int kVideoRtpBufferSize = 65536;
+
+// This constant is really an on/off, lower-level configurable NACK history
+// duration hasn't been implemented.
+static const int kNackHistoryMs = 1000;
+
+static const int kDefaultQpMax = 56;
+
+static const int kDefaultRtcpReceiverReportSsrc = 1;
+
+// Minimum time interval for logging stats.
+static const int64_t kStatsLogIntervalMs = 10000;
+
+static std::vector<VideoCodec> GetSupportedCodecs(
+    const WebRtcVideoEncoderFactory* external_encoder_factory);
+
+rtc::scoped_refptr<webrtc::VideoEncoderConfig::EncoderSpecificSettings>
+WebRtcVideoChannel2::WebRtcVideoSendStream::ConfigureVideoEncoderSettings(
+    const VideoCodec& codec) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  bool is_screencast = parameters_.options.is_screencast.value_or(false);
+  // No automatic resizing when using simulcast or screencast.
+  bool automatic_resize =
+      !is_screencast && parameters_.config.rtp.ssrcs.size() == 1;
+  bool frame_dropping = !is_screencast;
+  bool denoising;
+  bool codec_default_denoising = false;
+  if (is_screencast) {
+    denoising = false;
+  } else {
+    // Use codec default if video_noise_reduction is unset.
+    codec_default_denoising = !parameters_.options.video_noise_reduction;
+    denoising = parameters_.options.video_noise_reduction.value_or(false);
+  }
+
+  if (CodecNamesEq(codec.name, kH264CodecName)) {
+    webrtc::VideoCodecH264 h264_settings =
+        webrtc::VideoEncoder::GetDefaultH264Settings();
+    h264_settings.frameDroppingOn = frame_dropping;
+    return new rtc::RefCountedObject<
+        webrtc::VideoEncoderConfig::H264EncoderSpecificSettings>(h264_settings);
+  }
+  if (CodecNamesEq(codec.name, kVp8CodecName)) {
+    webrtc::VideoCodecVP8 vp8_settings =
+        webrtc::VideoEncoder::GetDefaultVp8Settings();
+    vp8_settings.automaticResizeOn = automatic_resize;
+    // VP8 denoising is enabled by default.
+    vp8_settings.denoisingOn = codec_default_denoising ? true : denoising;
+    vp8_settings.frameDroppingOn = frame_dropping;
+    return new rtc::RefCountedObject<
+        webrtc::VideoEncoderConfig::Vp8EncoderSpecificSettings>(vp8_settings);
+  }
+  if (CodecNamesEq(codec.name, kVp9CodecName)) {
+    webrtc::VideoCodecVP9 vp9_settings =
+        webrtc::VideoEncoder::GetDefaultVp9Settings();
+    if (is_screencast) {
+      // TODO(asapersson): Set to 2 for now since there is a DCHECK in
+      // VideoSendStream::ReconfigureVideoEncoder.
+      vp9_settings.numberOfSpatialLayers = 2;
+    } else {
+      vp9_settings.numberOfSpatialLayers = GetDefaultVp9SpatialLayers();
+    }
+    // VP9 denoising is disabled by default.
+    vp9_settings.denoisingOn = codec_default_denoising ? false : denoising;
+    vp9_settings.frameDroppingOn = frame_dropping;
+    return new rtc::RefCountedObject<
+        webrtc::VideoEncoderConfig::Vp9EncoderSpecificSettings>(vp9_settings);
+  }
+  return nullptr;
+}
+
+DefaultUnsignalledSsrcHandler::DefaultUnsignalledSsrcHandler()
+    : default_recv_ssrc_(0), default_sink_(NULL) {}
+
+UnsignalledSsrcHandler::Action DefaultUnsignalledSsrcHandler::OnUnsignalledSsrc(
+    WebRtcVideoChannel2* channel,
+    uint32_t ssrc) {
+  if (default_recv_ssrc_ != 0) {  // Already one default stream, so replace it.
+    channel->RemoveRecvStream(default_recv_ssrc_);
+    default_recv_ssrc_ = 0;
+  }
+
+  StreamParams sp;
+  sp.ssrcs.push_back(ssrc);
+  LOG(LS_INFO) << "Creating default receive stream for SSRC=" << ssrc << ".";
+  if (!channel->AddRecvStream(sp, true)) {
+    LOG(LS_WARNING) << "Could not create default receive stream.";
+  }
+
+  channel->SetSink(ssrc, default_sink_);
+  default_recv_ssrc_ = ssrc;
+  return kDeliverPacket;
+}
+
+rtc::VideoSinkInterface<webrtc::VideoFrame>*
+DefaultUnsignalledSsrcHandler::GetDefaultSink() const {
+  return default_sink_;
+}
+
+void DefaultUnsignalledSsrcHandler::SetDefaultSink(
+    VideoMediaChannel* channel,
+    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
+  default_sink_ = sink;
+  if (default_recv_ssrc_ != 0) {
+    channel->SetSink(default_recv_ssrc_, default_sink_);
+  }
+}
+
+WebRtcVideoEngine2::WebRtcVideoEngine2()
+    : initialized_(false),
+      external_decoder_factory_(NULL),
+      external_encoder_factory_(NULL) {
+  LOG(LS_INFO) << "WebRtcVideoEngine2::WebRtcVideoEngine2()";
+}
+
+WebRtcVideoEngine2::~WebRtcVideoEngine2() {
+  LOG(LS_INFO) << "WebRtcVideoEngine2::~WebRtcVideoEngine2";
+}
+
+void WebRtcVideoEngine2::Init() {
+  LOG(LS_INFO) << "WebRtcVideoEngine2::Init";
+  initialized_ = true;
+}
+
+WebRtcVideoChannel2* WebRtcVideoEngine2::CreateChannel(
+    webrtc::Call* call,
+    const MediaConfig& config,
+    const VideoOptions& options) {
+  RTC_DCHECK(initialized_);
+  LOG(LS_INFO) << "CreateChannel. Options: " << options.ToString();
+  return new WebRtcVideoChannel2(call, config, options,
+                                 external_encoder_factory_,
+                                 external_decoder_factory_);
+}
+
+std::vector<VideoCodec> WebRtcVideoEngine2::codecs() const {
+  return GetSupportedCodecs(external_encoder_factory_);
+}
+
+RtpCapabilities WebRtcVideoEngine2::GetCapabilities() const {
+  RtpCapabilities capabilities;
+  capabilities.header_extensions.push_back(
+      webrtc::RtpExtension(webrtc::RtpExtension::kTimestampOffsetUri,
+                           webrtc::RtpExtension::kTimestampOffsetDefaultId));
+  capabilities.header_extensions.push_back(
+      webrtc::RtpExtension(webrtc::RtpExtension::kAbsSendTimeUri,
+                           webrtc::RtpExtension::kAbsSendTimeDefaultId));
+  capabilities.header_extensions.push_back(
+      webrtc::RtpExtension(webrtc::RtpExtension::kVideoRotationUri,
+                           webrtc::RtpExtension::kVideoRotationDefaultId));
+  capabilities.header_extensions.push_back(webrtc::RtpExtension(
+      webrtc::RtpExtension::kTransportSequenceNumberUri,
+      webrtc::RtpExtension::kTransportSequenceNumberDefaultId));
+  capabilities.header_extensions.push_back(
+      webrtc::RtpExtension(webrtc::RtpExtension::kPlayoutDelayUri,
+                           webrtc::RtpExtension::kPlayoutDelayDefaultId));
+  return capabilities;
+}
+
+void WebRtcVideoEngine2::SetExternalDecoderFactory(
+    WebRtcVideoDecoderFactory* decoder_factory) {
+  RTC_DCHECK(!initialized_);
+  external_decoder_factory_ = decoder_factory;
+}
+
+void WebRtcVideoEngine2::SetExternalEncoderFactory(
+    WebRtcVideoEncoderFactory* encoder_factory) {
+  RTC_DCHECK(!initialized_);
+  if (external_encoder_factory_ == encoder_factory)
+    return;
+
+  // No matter what happens we shouldn't hold on to a stale
+  // WebRtcSimulcastEncoderFactory.
+  simulcast_encoder_factory_.reset();
+
+  if (encoder_factory &&
+      WebRtcSimulcastEncoderFactory::UseSimulcastEncoderFactory(
+          encoder_factory->supported_codecs())) {
+    simulcast_encoder_factory_.reset(
+        new WebRtcSimulcastEncoderFactory(encoder_factory));
+    encoder_factory = simulcast_encoder_factory_.get();
+  }
+  external_encoder_factory_ = encoder_factory;
+}
+
+// This is a helper function for AppendVideoCodecs below. It will return the
+// first unused dynamic payload type (in the range [96, 127]), or nothing if no
+// payload type is unused.
+static rtc::Optional<int> NextFreePayloadType(
+    const std::vector<VideoCodec>& codecs) {
+  static const int kFirstDynamicPayloadType = 96;
+  static const int kLastDynamicPayloadType = 127;
+  bool is_payload_used[1 + kLastDynamicPayloadType - kFirstDynamicPayloadType] =
+      {false};
+  for (const VideoCodec& codec : codecs) {
+    if (kFirstDynamicPayloadType <= codec.id &&
+        codec.id <= kLastDynamicPayloadType) {
+      is_payload_used[codec.id - kFirstDynamicPayloadType] = true;
+    }
+  }
+  for (int i = kFirstDynamicPayloadType; i <= kLastDynamicPayloadType; ++i) {
+    if (!is_payload_used[i - kFirstDynamicPayloadType])
+      return rtc::Optional<int>(i);
+  }
+  // No free payload type.
+  return rtc::Optional<int>();
+}
+
+// This is a helper function for GetSupportedCodecs below. It will append new
+// unique codecs from |input_codecs| to |unified_codecs|. It will add default
+// feedback params to the codecs and will also add an associated RTX codec for
+// recognized codecs (VP8, VP9, H264, and RED).
+static void AppendVideoCodecs(const std::vector<VideoCodec>& input_codecs,
+                              std::vector<VideoCodec>* unified_codecs) {
+  for (VideoCodec codec : input_codecs) {
+    const rtc::Optional<int> payload_type =
+        NextFreePayloadType(*unified_codecs);
+    if (!payload_type)
+      return;
+    codec.id = *payload_type;
+    // TODO(magjed): Move the responsibility of setting these parameters to the
+    // encoder factories instead.
+    if (codec.name != kRedCodecName && codec.name != kUlpfecCodecName &&
+        codec.name != kFlexfecCodecName)
+      AddDefaultFeedbackParams(&codec);
+    // Don't add same codec twice.
+    if (FindMatchingCodec(*unified_codecs, codec))
+      continue;
+
+	if (CodecNamesEq(codec.name, kH264CodecName))
+	{
+		auto it = unified_codecs->begin();
+		unified_codecs->insert(it, codec);
+	}
+	else
+	{
+		unified_codecs->push_back(codec);
+	}
+
+
+    // Add associated RTX codec for recognized codecs.
+    // TODO(deadbeef): Should we add RTX codecs for external codecs whose names
+    // we don't recognize?
+    if (CodecNamesEq(codec.name, kVp8CodecName) ||
+        CodecNamesEq(codec.name, kVp9CodecName) ||
+        CodecNamesEq(codec.name, kH264CodecName) ||
+        CodecNamesEq(codec.name, kRedCodecName)) {
+      const rtc::Optional<int> rtx_payload_type =
+          NextFreePayloadType(*unified_codecs);
+      if (!rtx_payload_type)
+        return;
+      unified_codecs->push_back(
+          VideoCodec::CreateRtxCodec(*rtx_payload_type, codec.id));
+    }
+  }
+}
+
+static std::vector<VideoCodec> GetSupportedCodecs(
+    const WebRtcVideoEncoderFactory* external_encoder_factory) {
+  const std::vector<VideoCodec> internal_codecs =
+      InternalEncoderFactory().supported_codecs();
+  LOG(LS_INFO) << "Internally supported codecs: "
+               << CodecVectorToString(internal_codecs);
+
+  std::vector<VideoCodec> unified_codecs;
+  AppendVideoCodecs(internal_codecs, &unified_codecs);
+
+  if (external_encoder_factory != nullptr) {
+    const std::vector<VideoCodec>& external_codecs =
+        external_encoder_factory->supported_codecs();
+    AppendVideoCodecs(external_codecs, &unified_codecs);
+    LOG(LS_INFO) << "Codecs supported by the external encoder factory: "
+                 << CodecVectorToString(external_codecs);
+  }
+
+  return unified_codecs;
+}
+
+WebRtcVideoChannel2::WebRtcVideoChannel2(
+    webrtc::Call* call,
+    const MediaConfig& config,
+    const VideoOptions& options,
+    WebRtcVideoEncoderFactory* external_encoder_factory,
+    WebRtcVideoDecoderFactory* external_decoder_factory)
+    : VideoMediaChannel(config),
+      call_(call),
+      unsignalled_ssrc_handler_(&default_unsignalled_ssrc_handler_),
+      video_config_(config.video),
+      external_encoder_factory_(external_encoder_factory),
+      external_decoder_factory_(external_decoder_factory),
+      default_send_options_(options),
+      last_stats_log_ms_(-1) {
+  RTC_DCHECK(thread_checker_.CalledOnValidThread());
+
+  rtcp_receiver_report_ssrc_ = kDefaultRtcpReceiverReportSsrc;
+  sending_ = false;
+  recv_codecs_ = MapCodecs(GetSupportedCodecs(external_encoder_factory));
+}
+
+WebRtcVideoChannel2::~WebRtcVideoChannel2() {
+  for (auto& kv : send_streams_)
+    delete kv.second;
+  for (auto& kv : receive_streams_)
+    delete kv.second;
+}
+
+rtc::Optional<WebRtcVideoChannel2::VideoCodecSettings>
+WebRtcVideoChannel2::SelectSendVideoCodec(
+    const std::vector<VideoCodecSettings>& remote_mapped_codecs) const {
+  const std::vector<VideoCodec> local_supported_codecs =
+      GetSupportedCodecs(external_encoder_factory_);
+  // Select the first remote codec that is supported locally.
+  for (const VideoCodecSettings& remote_mapped_codec : remote_mapped_codecs) {
+    // For H264, we will limit the encode level to the remote offered level
+    // regardless if level asymmetry is allowed or not. This is strictly not
+    // following the spec in https://tools.ietf.org/html/rfc6184#section-8.2.2
+    // since we should limit the encode level to the lower of local and remote
+    // level when level asymmetry is not allowed.
+    if (FindMatchingCodec(local_supported_codecs, remote_mapped_codec.codec))
+      return rtc::Optional<VideoCodecSettings>(remote_mapped_codec);
+  }
+  // No remote codec was supported.
+  return rtc::Optional<VideoCodecSettings>();
+}
+
+bool WebRtcVideoChannel2::ReceiveCodecsHaveChanged(
+    std::vector<VideoCodecSettings> before,
+    std::vector<VideoCodecSettings> after) {
+  if (before.size() != after.size()) {
+    return true;
+  }
+  // The receive codec order doesn't matter, so we sort the codecs before
+  // comparing. This is necessary because currently the
+  // only way to change the send codec is to munge SDP, which causes
+  // the receive codec list to change order, which causes the streams
+  // to be recreates which causes a "blink" of black video.  In order
+  // to support munging the SDP in this way without recreating receive
+  // streams, we ignore the order of the received codecs so that
+  // changing the order doesn't cause this "blink".
+  auto comparison =
+      [](const VideoCodecSettings& codec1, const VideoCodecSettings& codec2) {
+        return codec1.codec.id > codec2.codec.id;
+      };
+  std::sort(before.begin(), before.end(), comparison);
+  std::sort(after.begin(), after.end(), comparison);
+  return before != after;
+}
+
+bool WebRtcVideoChannel2::GetChangedSendParameters(
+    const VideoSendParameters& params,
+    ChangedSendParameters* changed_params) const {
+  if (!ValidateCodecFormats(params.codecs) ||
+      !ValidateRtpExtensions(params.extensions)) {
+    return false;
+  }
+
+  // Select one of the remote codecs that will be used as send codec.
+  const rtc::Optional<VideoCodecSettings> selected_send_codec =
+      SelectSendVideoCodec(MapCodecs(params.codecs));
+
+  if (!selected_send_codec) {
+    LOG(LS_ERROR) << "No video codecs supported.";
+    return false;
+  }
+
+  if (!send_codec_ || *selected_send_codec != *send_codec_)
+    changed_params->codec = selected_send_codec;
+
+  // Handle RTP header extensions.
+  std::vector<webrtc::RtpExtension> filtered_extensions = FilterRtpExtensions(
+      params.extensions, webrtc::RtpExtension::IsSupportedForVideo, true);
+  if (!send_rtp_extensions_ || (*send_rtp_extensions_ != filtered_extensions)) {
+    changed_params->rtp_header_extensions =
+        rtc::Optional<std::vector<webrtc::RtpExtension>>(filtered_extensions);
+  }
+
+  // Handle max bitrate.
+  if (params.max_bandwidth_bps != send_params_.max_bandwidth_bps &&
+      params.max_bandwidth_bps >= 0) {
+    // 0 uncaps max bitrate (-1).
+    changed_params->max_bandwidth_bps = rtc::Optional<int>(
+        params.max_bandwidth_bps == 0 ? -1 : params.max_bandwidth_bps);
+  }
+
+  // Handle conference mode.
+  if (params.conference_mode != send_params_.conference_mode) {
+    changed_params->conference_mode =
+        rtc::Optional<bool>(params.conference_mode);
+  }
+
+  // Handle RTCP mode.
+  if (params.rtcp.reduced_size != send_params_.rtcp.reduced_size) {
+    changed_params->rtcp_mode = rtc::Optional<webrtc::RtcpMode>(
+        params.rtcp.reduced_size ? webrtc::RtcpMode::kReducedSize
+                                 : webrtc::RtcpMode::kCompound);
+  }
+
+  return true;
+}
+
+rtc::DiffServCodePoint WebRtcVideoChannel2::PreferredDscp() const {
+  return rtc::DSCP_AF41;
+}
+
+bool WebRtcVideoChannel2::SetSendParameters(const VideoSendParameters& params) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetSendParameters");
+  LOG(LS_INFO) << "SetSendParameters: " << params.ToString();
+  ChangedSendParameters changed_params;
+  if (!GetChangedSendParameters(params, &changed_params)) {
+    return false;
+  }
+
+  if (changed_params.codec) {
+    const VideoCodecSettings& codec_settings = *changed_params.codec;
+    send_codec_ = rtc::Optional<VideoCodecSettings>(codec_settings);
+    LOG(LS_INFO) << "Using codec: " << codec_settings.codec.ToString();
+  }
+
+  if (changed_params.rtp_header_extensions) {
+    send_rtp_extensions_ = changed_params.rtp_header_extensions;
+  }
+
+  if (changed_params.codec || changed_params.max_bandwidth_bps) {
+    if (send_codec_) {
+      // TODO(holmer): Changing the codec parameters shouldn't necessarily mean
+      // that we change the min/max of bandwidth estimation. Reevaluate this.
+      bitrate_config_ = GetBitrateConfigForCodec(send_codec_->codec);
+      if (!changed_params.codec) {
+        // If the codec isn't changing, set the start bitrate to -1 which means
+        // "unchanged" so that BWE isn't affected.
+        bitrate_config_.start_bitrate_bps = -1;
+      }
+    }
+    if (params.max_bandwidth_bps >= 0) {
+      // Note that max_bandwidth_bps intentionally takes priority over the
+      // bitrate config for the codec. This allows FEC to be applied above the
+      // codec target bitrate.
+      // TODO(pbos): Figure out whether b=AS means max bitrate for this
+      // WebRtcVideoChannel2 (in which case we're good), or per sender (SSRC),
+      // in which case this should not set a Call::BitrateConfig but rather
+      // reconfigure all senders.
+      bitrate_config_.max_bitrate_bps =
+          params.max_bandwidth_bps == 0 ? -1 : params.max_bandwidth_bps;
+    }
+    call_->SetBitrateConfig(bitrate_config_);
+  }
+
+  {
+    rtc::CritScope stream_lock(&stream_crit_);
+    for (auto& kv : send_streams_) {
+      kv.second->SetSendParameters(changed_params);
+    }
+    if (changed_params.codec || changed_params.rtcp_mode) {
+      // Update receive feedback parameters from new codec or RTCP mode.
+      LOG(LS_INFO)
+          << "SetFeedbackOptions on all the receive streams because the send "
+             "codec or RTCP mode has changed.";
+      for (auto& kv : receive_streams_) {
+        RTC_DCHECK(kv.second != nullptr);
+        kv.second->SetFeedbackParameters(
+            HasNack(send_codec_->codec), HasRemb(send_codec_->codec),
+            HasTransportCc(send_codec_->codec),
+            params.rtcp.reduced_size ? webrtc::RtcpMode::kReducedSize
+                                     : webrtc::RtcpMode::kCompound);
+      }
+    }
+  }
+  send_params_ = params;
+  return true;
+}
+
+webrtc::RtpParameters WebRtcVideoChannel2::GetRtpSendParameters(
+    uint32_t ssrc) const {
+  rtc::CritScope stream_lock(&stream_crit_);
+  auto it = send_streams_.find(ssrc);
+  if (it == send_streams_.end()) {
+    LOG(LS_WARNING) << "Attempting to get RTP send parameters for stream "
+                    << "with ssrc " << ssrc << " which doesn't exist.";
+    return webrtc::RtpParameters();
+  }
+
+  webrtc::RtpParameters rtp_params = it->second->GetRtpParameters();
+  // Need to add the common list of codecs to the send stream-specific
+  // RTP parameters.
+  for (const VideoCodec& codec : send_params_.codecs) {
+    rtp_params.codecs.push_back(codec.ToCodecParameters());
+  }
+  return rtp_params;
+}
+
+bool WebRtcVideoChannel2::SetRtpSendParameters(
+    uint32_t ssrc,
+    const webrtc::RtpParameters& parameters) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetRtpSendParameters");
+  rtc::CritScope stream_lock(&stream_crit_);
+  auto it = send_streams_.find(ssrc);
+  if (it == send_streams_.end()) {
+    LOG(LS_ERROR) << "Attempting to set RTP send parameters for stream "
+                  << "with ssrc " << ssrc << " which doesn't exist.";
+    return false;
+  }
+
+  // TODO(deadbeef): Handle setting parameters with a list of codecs in a
+  // different order (which should change the send codec).
+  webrtc::RtpParameters current_parameters = GetRtpSendParameters(ssrc);
+  if (current_parameters.codecs != parameters.codecs) {
+    LOG(LS_ERROR) << "Using SetParameters to change the set of codecs "
+                  << "is not currently supported.";
+    return false;
+  }
+
+  return it->second->SetRtpParameters(parameters);
+}
+
+webrtc::RtpParameters WebRtcVideoChannel2::GetRtpReceiveParameters(
+    uint32_t ssrc) const {
+  rtc::CritScope stream_lock(&stream_crit_);
+  auto it = receive_streams_.find(ssrc);
+  if (it == receive_streams_.end()) {
+    LOG(LS_WARNING) << "Attempting to get RTP receive parameters for stream "
+                    << "with ssrc " << ssrc << " which doesn't exist.";
+    return webrtc::RtpParameters();
+  }
+
+  // TODO(deadbeef): Return stream-specific parameters.
+  webrtc::RtpParameters rtp_params = CreateRtpParametersWithOneEncoding();
+  for (const VideoCodec& codec : recv_params_.codecs) {
+    rtp_params.codecs.push_back(codec.ToCodecParameters());
+  }
+  rtp_params.encodings[0].ssrc = it->second->GetFirstPrimarySsrc();
+  return rtp_params;
+}
+
+bool WebRtcVideoChannel2::SetRtpReceiveParameters(
+    uint32_t ssrc,
+    const webrtc::RtpParameters& parameters) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetRtpReceiveParameters");
+  rtc::CritScope stream_lock(&stream_crit_);
+  auto it = receive_streams_.find(ssrc);
+  if (it == receive_streams_.end()) {
+    LOG(LS_ERROR) << "Attempting to set RTP receive parameters for stream "
+                  << "with ssrc " << ssrc << " which doesn't exist.";
+    return false;
+  }
+
+  webrtc::RtpParameters current_parameters = GetRtpReceiveParameters(ssrc);
+  if (current_parameters != parameters) {
+    LOG(LS_ERROR) << "Changing the RTP receive parameters is currently "
+                  << "unsupported.";
+    return false;
+  }
+  return true;
+}
+
+bool WebRtcVideoChannel2::GetChangedRecvParameters(
+    const VideoRecvParameters& params,
+    ChangedRecvParameters* changed_params) const {
+  if (!ValidateCodecFormats(params.codecs) ||
+      !ValidateRtpExtensions(params.extensions)) {
+    return false;
+  }
+
+  // Handle receive codecs.
+  const std::vector<VideoCodecSettings> mapped_codecs =
+      MapCodecs(params.codecs);
+  if (mapped_codecs.empty()) {
+    LOG(LS_ERROR) << "SetRecvParameters called without any video codecs.";
+    return false;
+  }
+
+  // Verify that every mapped codec is supported locally.
+  const std::vector<VideoCodec> local_supported_codecs =
+      GetSupportedCodecs(external_encoder_factory_);
+  for (const VideoCodecSettings& mapped_codec : mapped_codecs) {
+    if (!FindMatchingCodec(local_supported_codecs, mapped_codec.codec)) {
+      LOG(LS_ERROR) << "SetRecvParameters called with unsupported video codec: "
+                    << mapped_codec.codec.ToString();
+      return false;
+    }
+  }
+
+  if (ReceiveCodecsHaveChanged(recv_codecs_, mapped_codecs)) {
+    changed_params->codec_settings =
+        rtc::Optional<std::vector<VideoCodecSettings>>(mapped_codecs);
+  }
+
+  // Handle RTP header extensions.
+  std::vector<webrtc::RtpExtension> filtered_extensions = FilterRtpExtensions(
+      params.extensions, webrtc::RtpExtension::IsSupportedForVideo, false);
+  if (filtered_extensions != recv_rtp_extensions_) {
+    changed_params->rtp_header_extensions =
+        rtc::Optional<std::vector<webrtc::RtpExtension>>(filtered_extensions);
+  }
+
+  return true;
+}
+
+bool WebRtcVideoChannel2::SetRecvParameters(const VideoRecvParameters& params) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetRecvParameters");
+  LOG(LS_INFO) << "SetRecvParameters: " << params.ToString();
+  ChangedRecvParameters changed_params;
+  if (!GetChangedRecvParameters(params, &changed_params)) {
+    return false;
+  }
+  if (changed_params.rtp_header_extensions) {
+    recv_rtp_extensions_ = *changed_params.rtp_header_extensions;
+  }
+  if (changed_params.codec_settings) {
+    LOG(LS_INFO) << "Changing recv codecs from "
+                 << CodecSettingsVectorToString(recv_codecs_) << " to "
+                 << CodecSettingsVectorToString(*changed_params.codec_settings);
+    recv_codecs_ = *changed_params.codec_settings;
+  }
+
+  {
+    rtc::CritScope stream_lock(&stream_crit_);
+    for (auto& kv : receive_streams_) {
+      kv.second->SetRecvParameters(changed_params);
+    }
+  }
+  recv_params_ = params;
+  return true;
+}
+
+std::string WebRtcVideoChannel2::CodecSettingsVectorToString(
+    const std::vector<VideoCodecSettings>& codecs) {
+  std::stringstream out;
+  out << '{';
+  for (size_t i = 0; i < codecs.size(); ++i) {
+    out << codecs[i].codec.ToString();
+    if (i != codecs.size() - 1) {
+      out << ", ";
+    }
+  }
+  out << '}';
+  return out.str();
+}
+
+bool WebRtcVideoChannel2::GetSendCodec(VideoCodec* codec) {
+  if (!send_codec_) {
+    LOG(LS_VERBOSE) << "GetSendCodec: No send codec set.";
+    return false;
+  }
+  *codec = send_codec_->codec;
+  return true;
+}
+
+bool WebRtcVideoChannel2::SetSend(bool send) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::SetSend");
+  LOG(LS_VERBOSE) << "SetSend: " << (send ? "true" : "false");
+  if (send && !send_codec_) {
+    LOG(LS_ERROR) << "SetSend(true) called before setting codec.";
+    return false;
+  }
+  {
+    rtc::CritScope stream_lock(&stream_crit_);
+    for (const auto& kv : send_streams_) {
+      kv.second->SetSend(send);
+    }
+  }
+  sending_ = send;
+  return true;
+}
+
+// TODO(nisse): The enable argument was used for mute logic which has
+// been moved to VideoBroadcaster. So remove the argument from this
+// method.
+bool WebRtcVideoChannel2::SetVideoSend(
+    uint32_t ssrc,
+    bool enable,
+    const VideoOptions* options,
+    rtc::VideoSourceInterface<webrtc::VideoFrame>* source) {
+  TRACE_EVENT0("webrtc", "SetVideoSend");
+  RTC_DCHECK(ssrc != 0);
+  LOG(LS_INFO) << "SetVideoSend (ssrc= " << ssrc << ", enable = " << enable
+               << ", options: " << (options ? options->ToString() : "nullptr")
+               << ", source = " << (source ? "(source)" : "nullptr") << ")";
+
+  rtc::CritScope stream_lock(&stream_crit_);
+  const auto& kv = send_streams_.find(ssrc);
+  if (kv == send_streams_.end()) {
+    // Allow unknown ssrc only if source is null.
+    RTC_CHECK(source == nullptr);
+    LOG(LS_ERROR) << "No sending stream on ssrc " << ssrc;
+    return false;
+  }
+
+  return kv->second->SetVideoSend(enable, options, source);
+}
+
+bool WebRtcVideoChannel2::ValidateSendSsrcAvailability(
+    const StreamParams& sp) const {
+  for (uint32_t ssrc : sp.ssrcs) {
+    if (send_ssrcs_.find(ssrc) != send_ssrcs_.end()) {
+      LOG(LS_ERROR) << "Send stream with SSRC '" << ssrc << "' already exists.";
+      return false;
+    }
+  }
+  return true;
+}
+
+bool WebRtcVideoChannel2::ValidateReceiveSsrcAvailability(
+    const StreamParams& sp) const {
+  for (uint32_t ssrc : sp.ssrcs) {
+    if (receive_ssrcs_.find(ssrc) != receive_ssrcs_.end()) {
+      LOG(LS_ERROR) << "Receive stream with SSRC '" << ssrc
+                    << "' already exists.";
+      return false;
+    }
+  }
+  return true;
+}
+
+bool WebRtcVideoChannel2::AddSendStream(const StreamParams& sp) {
+  LOG(LS_INFO) << "AddSendStream: " << sp.ToString();
+  if (!ValidateStreamParams(sp))
+    return false;
+
+  rtc::CritScope stream_lock(&stream_crit_);
+
+  if (!ValidateSendSsrcAvailability(sp))
+    return false;
+
+  for (uint32_t used_ssrc : sp.ssrcs)
+    send_ssrcs_.insert(used_ssrc);
+
+  webrtc::VideoSendStream::Config config(this);
+  config.suspend_below_min_bitrate = video_config_.suspend_below_min_bitrate;
+  config.periodic_alr_bandwidth_probing =
+      video_config_.periodic_alr_bandwidth_probing;
+  WebRtcVideoSendStream* stream = new WebRtcVideoSendStream(
+      call_, sp, std::move(config), default_send_options_,
+      external_encoder_factory_, video_config_.enable_cpu_overuse_detection,
+      bitrate_config_.max_bitrate_bps, send_codec_, send_rtp_extensions_,
+      send_params_);
+
+  uint32_t ssrc = sp.first_ssrc();
+  RTC_DCHECK(ssrc != 0);
+  send_streams_[ssrc] = stream;
+
+  if (rtcp_receiver_report_ssrc_ == kDefaultRtcpReceiverReportSsrc) {
+    rtcp_receiver_report_ssrc_ = ssrc;
+    LOG(LS_INFO) << "SetLocalSsrc on all the receive streams because we added "
+                    "a send stream.";
+    for (auto& kv : receive_streams_)
+      kv.second->SetLocalSsrc(ssrc);
+  }
+  if (sending_) {
+    stream->SetSend(true);
+  }
+
+  return true;
+}
+
+bool WebRtcVideoChannel2::RemoveSendStream(uint32_t ssrc) {
+  LOG(LS_INFO) << "RemoveSendStream: " << ssrc;
+
+  WebRtcVideoSendStream* removed_stream;
+  {
+    rtc::CritScope stream_lock(&stream_crit_);
+    std::map<uint32_t, WebRtcVideoSendStream*>::iterator it =
+        send_streams_.find(ssrc);
+    if (it == send_streams_.end()) {
+      return false;
+    }
+
+    for (uint32_t old_ssrc : it->second->GetSsrcs())
+      send_ssrcs_.erase(old_ssrc);
+
+    removed_stream = it->second;
+    send_streams_.erase(it);
+
+    // Switch receiver report SSRCs, the one in use is no longer valid.
+    if (rtcp_receiver_report_ssrc_ == ssrc) {
+      rtcp_receiver_report_ssrc_ = send_streams_.empty()
+                                       ? kDefaultRtcpReceiverReportSsrc
+                                       : send_streams_.begin()->first;
+      LOG(LS_INFO) << "SetLocalSsrc on all the receive streams because the "
+                      "previous local SSRC was removed.";
+
+      for (auto& kv : receive_streams_) {
+        kv.second->SetLocalSsrc(rtcp_receiver_report_ssrc_);
+      }
+    }
+  }
+
+  delete removed_stream;
+
+  return true;
+}
+
+void WebRtcVideoChannel2::DeleteReceiveStream(
+    WebRtcVideoChannel2::WebRtcVideoReceiveStream* stream) {
+  for (uint32_t old_ssrc : stream->GetSsrcs())
+    receive_ssrcs_.erase(old_ssrc);
+  delete stream;
+}
+
+bool WebRtcVideoChannel2::AddRecvStream(const StreamParams& sp) {
+  return AddRecvStream(sp, false);
+}
+
+bool WebRtcVideoChannel2::AddRecvStream(const StreamParams& sp,
+                                        bool default_stream) {
+  RTC_DCHECK(thread_checker_.CalledOnValidThread());
+
+  LOG(LS_INFO) << "AddRecvStream" << (default_stream ? " (default stream)" : "")
+               << ": " << sp.ToString();
+  if (!ValidateStreamParams(sp))
+    return false;
+
+  uint32_t ssrc = sp.first_ssrc();
+  RTC_DCHECK(ssrc != 0);  // TODO(pbos): Is this ever valid?
+
+  rtc::CritScope stream_lock(&stream_crit_);
+  // Remove running stream if this was a default stream.
+  const auto& prev_stream = receive_streams_.find(ssrc);
+  if (prev_stream != receive_streams_.end()) {
+    if (default_stream || !prev_stream->second->IsDefaultStream()) {
+      LOG(LS_ERROR) << "Receive stream for SSRC '" << ssrc
+                    << "' already exists.";
+      return false;
+    }
+    DeleteReceiveStream(prev_stream->second);
+    receive_streams_.erase(prev_stream);
+  }
+
+  if (!ValidateReceiveSsrcAvailability(sp))
+    return false;
+
+  for (uint32_t used_ssrc : sp.ssrcs)
+    receive_ssrcs_.insert(used_ssrc);
+
+  webrtc::VideoReceiveStream::Config config(this);
+  webrtc::FlexfecReceiveStream::Config flexfec_config(this);
+  ConfigureReceiverRtp(&config, &flexfec_config, sp);
+
+  config.disable_prerenderer_smoothing =
+      video_config_.disable_prerenderer_smoothing;
+  config.sync_group = sp.sync_label;
+
+  receive_streams_[ssrc] = new WebRtcVideoReceiveStream(
+      call_, sp, std::move(config), external_decoder_factory_, default_stream,
+      recv_codecs_, flexfec_config);
+
+  return true;
+}
+
+void WebRtcVideoChannel2::ConfigureReceiverRtp(
+    webrtc::VideoReceiveStream::Config* config,
+    webrtc::FlexfecReceiveStream::Config* flexfec_config,
+    const StreamParams& sp) const {
+  uint32_t ssrc = sp.first_ssrc();
+
+  config->rtp.remote_ssrc = ssrc;
+  config->rtp.local_ssrc = rtcp_receiver_report_ssrc_;
+
+  // TODO(pbos): This protection is against setting the same local ssrc as
+  // remote which is not permitted by the lower-level API. RTCP requires a
+  // corresponding sender SSRC. Figure out what to do when we don't have
+  // (receive-only) or know a good local SSRC.
+  if (config->rtp.remote_ssrc == config->rtp.local_ssrc) {
+    if (config->rtp.local_ssrc != kDefaultRtcpReceiverReportSsrc) {
+      config->rtp.local_ssrc = kDefaultRtcpReceiverReportSsrc;
+    } else {
+      config->rtp.local_ssrc = kDefaultRtcpReceiverReportSsrc + 1;
+    }
+  }
+
+  // Whether or not the receive stream sends reduced size RTCP is determined
+  // by the send params.
+  // TODO(deadbeef): Once we change "send_params" to "sender_params" and
+  // "recv_params" to "receiver_params", we should get this out of
+  // receiver_params_.
+  config->rtp.rtcp_mode = send_params_.rtcp.reduced_size
+                              ? webrtc::RtcpMode::kReducedSize
+                              : webrtc::RtcpMode::kCompound;
+
+  config->rtp.remb = send_codec_ ? HasRemb(send_codec_->codec) : false;
+  config->rtp.transport_cc =
+      send_codec_ ? HasTransportCc(send_codec_->codec) : false;
+
+  sp.GetFidSsrc(ssrc, &config->rtp.rtx_ssrc);
+
+  config->rtp.extensions = recv_rtp_extensions_;
+
+  // TODO(brandtr): Generalize when we add support for multistream protection.
+  if (sp.GetFecFrSsrc(ssrc, &flexfec_config->remote_ssrc)) {
+    flexfec_config->protected_media_ssrcs = {ssrc};
+    flexfec_config->local_ssrc = config->rtp.local_ssrc;
+    flexfec_config->rtcp_mode = config->rtp.rtcp_mode;
+    // TODO(brandtr): We should be spec-compliant and set |transport_cc| here
+    // based on the rtcp-fb for the FlexFEC codec, not the media codec.
+    flexfec_config->transport_cc = config->rtp.transport_cc;
+    flexfec_config->rtp_header_extensions = config->rtp.extensions;
+  }
+}
+
+bool WebRtcVideoChannel2::RemoveRecvStream(uint32_t ssrc) {
+  LOG(LS_INFO) << "RemoveRecvStream: " << ssrc;
+  if (ssrc == 0) {
+    LOG(LS_ERROR) << "RemoveRecvStream with 0 ssrc is not supported.";
+    return false;
+  }
+
+  rtc::CritScope stream_lock(&stream_crit_);
+  std::map<uint32_t, WebRtcVideoReceiveStream*>::iterator stream =
+      receive_streams_.find(ssrc);
+  if (stream == receive_streams_.end()) {
+    LOG(LS_ERROR) << "Stream not found for ssrc: " << ssrc;
+    return false;
+  }
+  DeleteReceiveStream(stream->second);
+  receive_streams_.erase(stream);
+
+  return true;
+}
+
+bool WebRtcVideoChannel2::SetSink(
+    uint32_t ssrc,
+    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
+  LOG(LS_INFO) << "SetSink: ssrc:" << ssrc << " "
+               << (sink ? "(ptr)" : "nullptr");
+  if (ssrc == 0) {
+    default_unsignalled_ssrc_handler_.SetDefaultSink(this, sink);
+    return true;
+  }
+
+  rtc::CritScope stream_lock(&stream_crit_);
+  std::map<uint32_t, WebRtcVideoReceiveStream*>::iterator it =
+      receive_streams_.find(ssrc);
+  if (it == receive_streams_.end()) {
+    return false;
+  }
+
+  it->second->SetSink(sink);
+  return true;
+}
+
+bool WebRtcVideoChannel2::GetStats(VideoMediaInfo* info) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoChannel2::GetStats");
+
+  // Log stats periodically.
+  bool log_stats = false;
+  int64_t now_ms = rtc::TimeMillis();
+  if (last_stats_log_ms_ == -1 ||
+      now_ms - last_stats_log_ms_ > kStatsLogIntervalMs) {
+    last_stats_log_ms_ = now_ms;
+    log_stats = true;
+  }
+
+  info->Clear();
+  FillSenderStats(info, log_stats);
+  FillReceiverStats(info, log_stats);
+  FillSendAndReceiveCodecStats(info);
+  webrtc::Call::Stats stats = call_->GetStats();
+  FillBandwidthEstimationStats(stats, info);
+  if (stats.rtt_ms != -1) {
+    for (size_t i = 0; i < info->senders.size(); ++i) {
+      info->senders[i].rtt_ms = stats.rtt_ms;
+    }
+  }
+
+  if (log_stats)
+    LOG(LS_INFO) << stats.ToString(now_ms);
+
+  return true;
+}
+
+void WebRtcVideoChannel2::FillSenderStats(VideoMediaInfo* video_media_info,
+                                          bool log_stats) {
+  rtc::CritScope stream_lock(&stream_crit_);
+  for (std::map<uint32_t, WebRtcVideoSendStream*>::iterator it =
+           send_streams_.begin();
+       it != send_streams_.end(); ++it) {
+    video_media_info->senders.push_back(
+        it->second->GetVideoSenderInfo(log_stats));
+  }
+}
+
+void WebRtcVideoChannel2::FillReceiverStats(VideoMediaInfo* video_media_info,
+                                            bool log_stats) {
+  rtc::CritScope stream_lock(&stream_crit_);
+  for (std::map<uint32_t, WebRtcVideoReceiveStream*>::iterator it =
+           receive_streams_.begin();
+       it != receive_streams_.end(); ++it) {
+    video_media_info->receivers.push_back(
+        it->second->GetVideoReceiverInfo(log_stats));
+  }
+}
+
+void WebRtcVideoChannel2::FillBandwidthEstimationStats(
+    const webrtc::Call::Stats& stats,
+    VideoMediaInfo* video_media_info) {
+  BandwidthEstimationInfo bwe_info;
+  bwe_info.available_send_bandwidth = stats.send_bandwidth_bps;
+  bwe_info.available_recv_bandwidth = stats.recv_bandwidth_bps;
+  bwe_info.bucket_delay = stats.pacer_delay_ms;
+
+  // Get send stream bitrate stats.
+  rtc::CritScope stream_lock(&stream_crit_);
+  for (std::map<uint32_t, WebRtcVideoSendStream*>::iterator stream =
+           send_streams_.begin();
+       stream != send_streams_.end(); ++stream) {
+    stream->second->FillBandwidthEstimationInfo(&bwe_info);
+  }
+  video_media_info->bw_estimations.push_back(bwe_info);
+}
+
+void WebRtcVideoChannel2::FillSendAndReceiveCodecStats(
+    VideoMediaInfo* video_media_info) {
+  for (const VideoCodec& codec : send_params_.codecs) {
+    webrtc::RtpCodecParameters codec_params = codec.ToCodecParameters();
+    video_media_info->send_codecs.insert(
+        std::make_pair(codec_params.payload_type, std::move(codec_params)));
+  }
+  for (const VideoCodec& codec : recv_params_.codecs) {
+    webrtc::RtpCodecParameters codec_params = codec.ToCodecParameters();
+    video_media_info->receive_codecs.insert(
+        std::make_pair(codec_params.payload_type, std::move(codec_params)));
+  }
+}
+
+void WebRtcVideoChannel2::OnPacketReceived(
+    rtc::CopyOnWriteBuffer* packet,
+    const rtc::PacketTime& packet_time) {
+  const webrtc::PacketTime webrtc_packet_time(packet_time.timestamp,
+                                              packet_time.not_before);
+  const webrtc::PacketReceiver::DeliveryStatus delivery_result =
+      call_->Receiver()->DeliverPacket(
+          webrtc::MediaType::VIDEO,
+          packet->cdata(), packet->size(),
+          webrtc_packet_time);
+  switch (delivery_result) {
+    case webrtc::PacketReceiver::DELIVERY_OK:
+      return;
+    case webrtc::PacketReceiver::DELIVERY_PACKET_ERROR:
+      return;
+    case webrtc::PacketReceiver::DELIVERY_UNKNOWN_SSRC:
+      break;
+  }
+
+  uint32_t ssrc = 0;
+  if (!GetRtpSsrc(packet->cdata(), packet->size(), &ssrc)) {
+    return;
+  }
+
+  int payload_type = 0;
+  if (!GetRtpPayloadType(packet->cdata(), packet->size(), &payload_type)) {
+    return;
+  }
+
+  // See if this payload_type is registered as one that usually gets its own
+  // SSRC (RTX) or at least is safe to drop either way (FEC). If it is, and
+  // it wasn't handled above by DeliverPacket, that means we don't know what
+  // stream it associates with, and we shouldn't ever create an implicit channel
+  // for these.
+  for (auto& codec : recv_codecs_) {
+    if (payload_type == codec.rtx_payload_type ||
+        payload_type == codec.ulpfec.red_rtx_payload_type ||
+        payload_type == codec.ulpfec.ulpfec_payload_type ||
+        payload_type == codec.flexfec_payload_type) {
+      return;
+    }
+  }
+
+  switch (unsignalled_ssrc_handler_->OnUnsignalledSsrc(this, ssrc)) {
+    case UnsignalledSsrcHandler::kDropPacket:
+      return;
+    case UnsignalledSsrcHandler::kDeliverPacket:
+      break;
+  }
+
+  if (call_->Receiver()->DeliverPacket(
+          webrtc::MediaType::VIDEO,
+          packet->cdata(), packet->size(),
+          webrtc_packet_time) != webrtc::PacketReceiver::DELIVERY_OK) {
+    LOG(LS_WARNING) << "Failed to deliver RTP packet on re-delivery.";
+    return;
+  }
+}
+
+void WebRtcVideoChannel2::OnRtcpReceived(
+    rtc::CopyOnWriteBuffer* packet,
+    const rtc::PacketTime& packet_time) {
+  const webrtc::PacketTime webrtc_packet_time(packet_time.timestamp,
+                                              packet_time.not_before);
+  // TODO(pbos): Check webrtc::PacketReceiver::DELIVERY_OK once we deliver
+  // for both audio and video on the same path. Since BundleFilter doesn't
+  // filter RTCP anymore incoming RTCP packets could've been going to audio (so
+  // logging failures spam the log).
+  call_->Receiver()->DeliverPacket(
+      webrtc::MediaType::VIDEO,
+      packet->cdata(), packet->size(),
+      webrtc_packet_time);
+}
+
+void WebRtcVideoChannel2::OnReadyToSend(bool ready) {
+  LOG(LS_VERBOSE) << "OnReadyToSend: " << (ready ? "Ready." : "Not ready.");
+  call_->SignalChannelNetworkState(
+      webrtc::MediaType::VIDEO,
+      ready ? webrtc::kNetworkUp : webrtc::kNetworkDown);
+}
+
+void WebRtcVideoChannel2::OnNetworkRouteChanged(
+    const std::string& transport_name,
+    const rtc::NetworkRoute& network_route) {
+  call_->OnNetworkRouteChanged(transport_name, network_route);
+}
+
+void WebRtcVideoChannel2::OnTransportOverheadChanged(
+    int transport_overhead_per_packet) {
+  call_->OnTransportOverheadChanged(webrtc::MediaType::VIDEO,
+                                    transport_overhead_per_packet);
+}
+
+void WebRtcVideoChannel2::SetInterface(NetworkInterface* iface) {
+  MediaChannel::SetInterface(iface);
+  // Set the RTP recv/send buffer to a bigger size
+  MediaChannel::SetOption(NetworkInterface::ST_RTP,
+                          rtc::Socket::OPT_RCVBUF,
+                          kVideoRtpBufferSize);
+
+  // Speculative change to increase the outbound socket buffer size.
+  // In b/15152257, we are seeing a significant number of packets discarded
+  // due to lack of socket buffer space, although it's not yet clear what the
+  // ideal value should be.
+  MediaChannel::SetOption(NetworkInterface::ST_RTP,
+                          rtc::Socket::OPT_SNDBUF,
+                          kVideoRtpBufferSize);
+}
+
+bool WebRtcVideoChannel2::SendRtp(const uint8_t* data,
+                                  size_t len,
+                                  const webrtc::PacketOptions& options) {
+  rtc::CopyOnWriteBuffer packet(data, len, kMaxRtpPacketLen);
+  rtc::PacketOptions rtc_options;
+  rtc_options.packet_id = options.packet_id;
+  return MediaChannel::SendPacket(&packet, rtc_options);
+}
+
+bool WebRtcVideoChannel2::SendRtcp(const uint8_t* data, size_t len) {
+  rtc::CopyOnWriteBuffer packet(data, len, kMaxRtpPacketLen);
+  return MediaChannel::SendRtcp(&packet, rtc::PacketOptions());
+}
+
+WebRtcVideoChannel2::WebRtcVideoSendStream::VideoSendStreamParameters::
+    VideoSendStreamParameters(
+        webrtc::VideoSendStream::Config config,
+        const VideoOptions& options,
+        int max_bitrate_bps,
+        const rtc::Optional<VideoCodecSettings>& codec_settings)
+    : config(std::move(config)),
+      options(options),
+      max_bitrate_bps(max_bitrate_bps),
+      conference_mode(false),
+      codec_settings(codec_settings) {}
+
+WebRtcVideoChannel2::WebRtcVideoSendStream::AllocatedEncoder::AllocatedEncoder(
+    webrtc::VideoEncoder* encoder,
+    const cricket::VideoCodec& codec,
+    bool external)
+    : encoder(encoder),
+      external_encoder(nullptr),
+      codec(codec),
+      external(external) {
+  if (external) {
+    external_encoder = encoder;
+    this->encoder =
+        new webrtc::VideoEncoderSoftwareFallbackWrapper(codec, encoder);
+  }
+}
+
+WebRtcVideoChannel2::WebRtcVideoSendStream::WebRtcVideoSendStream(
+    webrtc::Call* call,
+    const StreamParams& sp,
+    webrtc::VideoSendStream::Config config,
+    const VideoOptions& options,
+    WebRtcVideoEncoderFactory* external_encoder_factory,
+    bool enable_cpu_overuse_detection,
+    int max_bitrate_bps,
+    const rtc::Optional<VideoCodecSettings>& codec_settings,
+    const rtc::Optional<std::vector<webrtc::RtpExtension>>& rtp_extensions,
+    // TODO(deadbeef): Don't duplicate information between send_params,
+    // rtp_extensions, options, etc.
+    const VideoSendParameters& send_params)
+    : worker_thread_(rtc::Thread::Current()),
+      ssrcs_(sp.ssrcs),
+      ssrc_groups_(sp.ssrc_groups),
+      call_(call),
+      enable_cpu_overuse_detection_(enable_cpu_overuse_detection),
+      source_(nullptr),
+      external_encoder_factory_(external_encoder_factory),
+      internal_encoder_factory_(new InternalEncoderFactory()),
+      stream_(nullptr),
+      encoder_sink_(nullptr),
+      parameters_(std::move(config), options, max_bitrate_bps, codec_settings),
+      rtp_parameters_(CreateRtpParametersWithOneEncoding()),
+      allocated_encoder_(nullptr, cricket::VideoCodec(), false),
+      sending_(false) {
+  parameters_.config.rtp.max_packet_size = kVideoMtu;
+  parameters_.conference_mode = send_params.conference_mode;
+
+  sp.GetPrimarySsrcs(&parameters_.config.rtp.ssrcs);
+
+  // ValidateStreamParams should prevent this from happening.
+  RTC_CHECK(!parameters_.config.rtp.ssrcs.empty());
+  rtp_parameters_.encodings[0].ssrc =
+      rtc::Optional<uint32_t>(parameters_.config.rtp.ssrcs[0]);
+
+  // RTX.
+  sp.GetFidSsrcs(parameters_.config.rtp.ssrcs,
+                 &parameters_.config.rtp.rtx.ssrcs);
+
+  // FlexFEC SSRCs.
+  // TODO(brandtr): This code needs to be generalized when we add support for
+  // multistream protection.
+  if (IsFlexfecFieldTrialEnabled()) {
+    uint32_t flexfec_ssrc;
+    bool flexfec_enabled = false;
+    for (uint32_t primary_ssrc : parameters_.config.rtp.ssrcs) {
+      if (sp.GetFecFrSsrc(primary_ssrc, &flexfec_ssrc)) {
+        if (flexfec_enabled) {
+          LOG(LS_INFO) << "Multiple FlexFEC streams proposed by remote, but "
+                          "our implementation only supports a single FlexFEC "
+                          "stream. Will not enable FlexFEC for proposed "
+                          "stream with SSRC: "
+                       << flexfec_ssrc << ".";
+          continue;
+        }
+
+        flexfec_enabled = true;
+        parameters_.config.rtp.flexfec.ssrc = flexfec_ssrc;
+        parameters_.config.rtp.flexfec.protected_media_ssrcs = {primary_ssrc};
+      }
+    }
+  }
+
+  parameters_.config.rtp.c_name = sp.cname;
+  if (rtp_extensions) {
+    parameters_.config.rtp.extensions = *rtp_extensions;
+  }
+  parameters_.config.rtp.rtcp_mode = send_params.rtcp.reduced_size
+                                         ? webrtc::RtcpMode::kReducedSize
+                                         : webrtc::RtcpMode::kCompound;
+  if (codec_settings) {
+    bool force_encoder_allocation = false;
+    SetCodec(*codec_settings, force_encoder_allocation);
+  }
+}
+
+WebRtcVideoChannel2::WebRtcVideoSendStream::~WebRtcVideoSendStream() {
+  if (stream_ != NULL) {
+    call_->DestroyVideoSendStream(stream_);
+  }
+  DestroyVideoEncoder(&allocated_encoder_);
+}
+
+bool WebRtcVideoChannel2::WebRtcVideoSendStream::SetVideoSend(
+    bool enable,
+    const VideoOptions* options,
+    rtc::VideoSourceInterface<webrtc::VideoFrame>* source) {
+  TRACE_EVENT0("webrtc", "WebRtcVideoSendStream::SetVideoSend");
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+
+  // Ignore |options| pointer if |enable| is false.
+  bool options_present = enable && options;
+
+  if (options_present) {
+    VideoOptions old_options = parameters_.options;
+    parameters_.options.SetAll(*options);
+    if (parameters_.options.is_screencast.value_or(false) !=
+            old_options.is_screencast.value_or(false) &&
+        parameters_.codec_settings) {
+      // If screen content settings change, we may need to recreate the codec
+      // instance so that the correct type is used.
+
+      bool force_encoder_allocation = true;
+      SetCodec(*parameters_.codec_settings, force_encoder_allocation);
+      // Mark screenshare parameter as being updated, then test for any other
+      // changes that may require codec reconfiguration.
+      old_options.is_screencast = options->is_screencast;
+    }
+    if (parameters_.options != old_options) {
+      ReconfigureEncoder();
+    }
+  }
+
+  if (source_ && stream_) {
+    stream_->SetSource(
+        nullptr, webrtc::VideoSendStream::DegradationPreference::kBalanced);
+  }
+  // Switch to the new source.
+  source_ = source;
+  if (source && stream_) {
+    // Do not adapt resolution for screen content as this will likely
+    // result in blurry and unreadable text.
+    // |this| acts like a VideoSource to make sure SinkWants are handled on the
+    // correct thread.
+    stream_->SetSource(
+        this, enable_cpu_overuse_detection_ &&
+                      !parameters_.options.is_screencast.value_or(false)
+                  ? webrtc::VideoSendStream::DegradationPreference::kBalanced
+                  : webrtc::VideoSendStream::DegradationPreference::
+                        kMaintainResolution);
+  }
+  return true;
+}
+
+const std::vector<uint32_t>&
+WebRtcVideoChannel2::WebRtcVideoSendStream::GetSsrcs() const {
+  return ssrcs_;
+}
+
+WebRtcVideoChannel2::WebRtcVideoSendStream::AllocatedEncoder
+WebRtcVideoChannel2::WebRtcVideoSendStream::CreateVideoEncoder(
+    const VideoCodec& codec,
+    bool force_encoder_allocation) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  // Do not re-create encoders of the same type.
+  if (!force_encoder_allocation && codec == allocated_encoder_.codec &&
+      allocated_encoder_.encoder != nullptr) {
+    return allocated_encoder_;
+  }
+
+  // Try creating external encoder.
+  if (external_encoder_factory_ != nullptr &&
+      FindMatchingCodec(external_encoder_factory_->supported_codecs(), codec)) {
+    webrtc::VideoEncoder* encoder =
+        external_encoder_factory_->CreateVideoEncoder(codec);
+    if (encoder != nullptr)
+      return AllocatedEncoder(encoder, codec, true /* is_external */);
+  }
+
+  // Try creating internal encoder.
+  if (FindMatchingCodec(internal_encoder_factory_->supported_codecs(), codec)) {
+    if (parameters_.encoder_config.content_type ==
+            webrtc::VideoEncoderConfig::ContentType::kScreen &&
+        parameters_.conference_mode && UseSimulcastScreenshare()) {
+      // TODO(sprang): Remove this adapter once libvpx supports simulcast with
+      // same-resolution substreams.
+      WebRtcSimulcastEncoderFactory adapter_factory(
+          internal_encoder_factory_.get());
+      return AllocatedEncoder(adapter_factory.CreateVideoEncoder(codec), codec,
+                              false /* is_external */);
+    }
+    return AllocatedEncoder(
+        internal_encoder_factory_->CreateVideoEncoder(codec), codec,
+        false /* is_external */);
+  }
+
+  // This shouldn't happen, we should not be trying to create something we don't
+  // support.
+  RTC_NOTREACHED();
+  return AllocatedEncoder(NULL, cricket::VideoCodec(), false);
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::DestroyVideoEncoder(
+    AllocatedEncoder* encoder) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  if (encoder->external) {
+    external_encoder_factory_->DestroyVideoEncoder(encoder->external_encoder);
+  }
+  delete encoder->encoder;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::SetCodec(
+    const VideoCodecSettings& codec_settings,
+    bool force_encoder_allocation) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  parameters_.encoder_config = CreateVideoEncoderConfig(codec_settings.codec);
+  RTC_DCHECK_GT(parameters_.encoder_config.number_of_streams, 0);
+
+  AllocatedEncoder new_encoder =
+      CreateVideoEncoder(codec_settings.codec, force_encoder_allocation);
+  parameters_.config.encoder_settings.encoder = new_encoder.encoder;
+  parameters_.config.encoder_settings.full_overuse_time = new_encoder.external;
+  parameters_.config.encoder_settings.payload_name = codec_settings.codec.name;
+  parameters_.config.encoder_settings.payload_type = codec_settings.codec.id;
+  if (new_encoder.external) {
+    webrtc::VideoCodecType type =
+        webrtc::PayloadNameToCodecType(codec_settings.codec.name)
+            .value_or(webrtc::kVideoCodecUnknown);
+    parameters_.config.encoder_settings.internal_source =
+        external_encoder_factory_->EncoderTypeHasInternalSource(type);
+  } else {
+    parameters_.config.encoder_settings.internal_source = false;
+  }
+  parameters_.config.rtp.ulpfec = codec_settings.ulpfec;
+  if (IsFlexfecFieldTrialEnabled()) {
+    parameters_.config.rtp.flexfec.payload_type =
+        codec_settings.flexfec_payload_type;
+  }
+
+  // Set RTX payload type if RTX is enabled.
+  if (!parameters_.config.rtp.rtx.ssrcs.empty()) {
+    if (codec_settings.rtx_payload_type == -1) {
+      LOG(LS_WARNING) << "RTX SSRCs configured but there's no configured RTX "
+                         "payload type. Ignoring.";
+      parameters_.config.rtp.rtx.ssrcs.clear();
+    } else {
+      parameters_.config.rtp.rtx.payload_type = codec_settings.rtx_payload_type;
+    }
+  }
+
+  parameters_.config.rtp.nack.rtp_history_ms =
+      HasNack(codec_settings.codec) ? kNackHistoryMs : 0;
+
+  parameters_.codec_settings =
+      rtc::Optional<WebRtcVideoChannel2::VideoCodecSettings>(codec_settings);
+
+  LOG(LS_INFO) << "RecreateWebRtcStream (send) because of SetCodec.";
+  RecreateWebRtcStream();
+  if (allocated_encoder_.encoder != new_encoder.encoder) {
+    DestroyVideoEncoder(&allocated_encoder_);
+    allocated_encoder_ = new_encoder;
+  }
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::SetSendParameters(
+    const ChangedSendParameters& params) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  // |recreate_stream| means construction-time parameters have changed and the
+  // sending stream needs to be reset with the new config.
+  bool recreate_stream = false;
+  if (params.rtcp_mode) {
+    parameters_.config.rtp.rtcp_mode = *params.rtcp_mode;
+    recreate_stream = true;
+  }
+  if (params.rtp_header_extensions) {
+    parameters_.config.rtp.extensions = *params.rtp_header_extensions;
+    recreate_stream = true;
+  }
+  if (params.max_bandwidth_bps) {
+    parameters_.max_bitrate_bps = *params.max_bandwidth_bps;
+    ReconfigureEncoder();
+  }
+  if (params.conference_mode) {
+    parameters_.conference_mode = *params.conference_mode;
+  }
+
+  // Set codecs and options.
+  if (params.codec) {
+    bool force_encoder_allocation = false;
+    SetCodec(*params.codec, force_encoder_allocation);
+    recreate_stream = false;  // SetCodec has already recreated the stream.
+  } else if (params.conference_mode && parameters_.codec_settings) {
+    bool force_encoder_allocation = false;
+    SetCodec(*parameters_.codec_settings, force_encoder_allocation);
+    recreate_stream = false;  // SetCodec has already recreated the stream.
+  }
+  if (recreate_stream) {
+    LOG(LS_INFO) << "RecreateWebRtcStream (send) because of SetSendParameters";
+    RecreateWebRtcStream();
+  }
+}
+
+bool WebRtcVideoChannel2::WebRtcVideoSendStream::SetRtpParameters(
+    const webrtc::RtpParameters& new_parameters) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  if (!ValidateRtpParameters(new_parameters)) {
+    return false;
+  }
+
+  bool reconfigure_encoder = new_parameters.encodings[0].max_bitrate_bps !=
+                             rtp_parameters_.encodings[0].max_bitrate_bps;
+  rtp_parameters_ = new_parameters;
+  // Codecs are currently handled at the WebRtcVideoChannel2 level.
+  rtp_parameters_.codecs.clear();
+  if (reconfigure_encoder) {
+    ReconfigureEncoder();
+  }
+  // Encoding may have been activated/deactivated.
+  UpdateSendState();
+  return true;
+}
+
+webrtc::RtpParameters
+WebRtcVideoChannel2::WebRtcVideoSendStream::GetRtpParameters() const {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  return rtp_parameters_;
+}
+
+bool WebRtcVideoChannel2::WebRtcVideoSendStream::ValidateRtpParameters(
+    const webrtc::RtpParameters& rtp_parameters) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  if (rtp_parameters.encodings.size() != 1) {
+    LOG(LS_ERROR)
+        << "Attempted to set RtpParameters without exactly one encoding";
+    return false;
+  }
+  if (rtp_parameters.encodings[0].ssrc != rtp_parameters_.encodings[0].ssrc) {
+    LOG(LS_ERROR) << "Attempted to set RtpParameters with modified SSRC";
+    return false;
+  }
+  return true;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::UpdateSendState() {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  // TODO(deadbeef): Need to handle more than one encoding in the future.
+  RTC_DCHECK(rtp_parameters_.encodings.size() == 1u);
+  if (sending_ && rtp_parameters_.encodings[0].active) {
+    RTC_DCHECK(stream_ != nullptr);
+    stream_->Start();
+  } else {
+    if (stream_ != nullptr) {
+      stream_->Stop();
+    }
+  }
+}
+
+webrtc::VideoEncoderConfig
+WebRtcVideoChannel2::WebRtcVideoSendStream::CreateVideoEncoderConfig(
+    const VideoCodec& codec) const {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  webrtc::VideoEncoderConfig encoder_config;
+  bool is_screencast = parameters_.options.is_screencast.value_or(false);
+  if (is_screencast) {
+    encoder_config.min_transmit_bitrate_bps =
+        1000 * parameters_.options.screencast_min_bitrate_kbps.value_or(0);
+    encoder_config.content_type =
+        webrtc::VideoEncoderConfig::ContentType::kScreen;
+  } else {
+    encoder_config.min_transmit_bitrate_bps = 0;
+    encoder_config.content_type =
+        webrtc::VideoEncoderConfig::ContentType::kRealtimeVideo;
+  }
+
+  // By default, the stream count for the codec configuration should match the
+  // number of negotiated ssrcs. But if the codec is blacklisted for simulcast
+  // or a screencast (and not in simulcast screenshare experiment), only
+  // configure a single stream.
+  encoder_config.number_of_streams = parameters_.config.rtp.ssrcs.size();
+  if (IsCodecBlacklistedForSimulcast(codec.name) ||
+      (is_screencast &&
+       (!UseSimulcastScreenshare() || !parameters_.conference_mode))) {
+    encoder_config.number_of_streams = 1;
+  }
+
+  int stream_max_bitrate = parameters_.max_bitrate_bps;
+  if (rtp_parameters_.encodings[0].max_bitrate_bps) {
+    stream_max_bitrate =
+        MinPositive(*(rtp_parameters_.encodings[0].max_bitrate_bps),
+                    parameters_.max_bitrate_bps);
+  }
+
+  int codec_max_bitrate_kbps;
+  if (codec.GetParam(kCodecParamMaxBitrate, &codec_max_bitrate_kbps)) {
+    stream_max_bitrate = codec_max_bitrate_kbps * 1000;
+  }
+  encoder_config.max_bitrate_bps = stream_max_bitrate;
+
+  int max_qp = kDefaultQpMax;
+  codec.GetParam(kCodecParamMaxQuantization, &max_qp);
+  encoder_config.video_stream_factory =
+      new rtc::RefCountedObject<EncoderStreamFactory>(
+          codec.name, max_qp, kDefaultVideoMaxFramerate, is_screencast,
+          parameters_.conference_mode);
+  return encoder_config;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::ReconfigureEncoder() {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  if (!stream_) {
+    // The webrtc::VideoSendStream |stream_| has not yet been created but other
+    // parameters has changed.
+    return;
+  }
+
+  RTC_DCHECK_GT(parameters_.encoder_config.number_of_streams, 0);
+
+  RTC_CHECK(parameters_.codec_settings);
+  VideoCodecSettings codec_settings = *parameters_.codec_settings;
+
+  webrtc::VideoEncoderConfig encoder_config =
+      CreateVideoEncoderConfig(codec_settings.codec);
+
+  encoder_config.encoder_specific_settings = ConfigureVideoEncoderSettings(
+      codec_settings.codec);
+
+  stream_->ReconfigureVideoEncoder(encoder_config.Copy());
+
+  encoder_config.encoder_specific_settings = NULL;
+
+  parameters_.encoder_config = std::move(encoder_config);
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::SetSend(bool send) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  sending_ = send;
+  UpdateSendState();
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::RemoveSink(
+    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  RTC_DCHECK(encoder_sink_ == sink);
+  encoder_sink_ = nullptr;
+  source_->RemoveSink(sink);
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::AddOrUpdateSink(
+    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink,
+    const rtc::VideoSinkWants& wants) {
+  if (worker_thread_ == rtc::Thread::Current()) {
+    // AddOrUpdateSink is called on |worker_thread_| if this is the first
+    // registration of |sink|.
+    RTC_DCHECK_RUN_ON(&thread_checker_);
+    encoder_sink_ = sink;
+    source_->AddOrUpdateSink(encoder_sink_, wants);
+  } else {
+    // Subsequent calls to AddOrUpdateSink will happen on the encoder task
+    // queue.
+    invoker_.AsyncInvoke<void>(
+        RTC_FROM_HERE, worker_thread_, [this, sink, wants] {
+          RTC_DCHECK_RUN_ON(&thread_checker_);
+          // |sink| may be invalidated after this task was posted since
+          // RemoveSink is called on the worker thread.
+          bool encoder_sink_valid = (sink == encoder_sink_);
+          if (source_ && encoder_sink_valid) {
+            source_->AddOrUpdateSink(encoder_sink_, wants);
+          }
+        });
+  }
+}
+
+VideoSenderInfo WebRtcVideoChannel2::WebRtcVideoSendStream::GetVideoSenderInfo(
+    bool log_stats) {
+  VideoSenderInfo info;
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  for (uint32_t ssrc : parameters_.config.rtp.ssrcs)
+    info.add_ssrc(ssrc);
+
+  if (parameters_.codec_settings) {
+    info.codec_name = parameters_.codec_settings->codec.name;
+    info.codec_payload_type = rtc::Optional<int>(
+        parameters_.codec_settings->codec.id);
+  }
+
+  if (stream_ == NULL)
+    return info;
+
+  webrtc::VideoSendStream::Stats stats = stream_->GetStats();
+
+  if (log_stats)
+    LOG(LS_INFO) << stats.ToString(rtc::TimeMillis());
+
+  info.adapt_changes = stats.number_of_cpu_adapt_changes;
+  info.adapt_reason =
+      stats.cpu_limited_resolution ? ADAPTREASON_CPU : ADAPTREASON_NONE;
+
+  // Get bandwidth limitation info from stream_->GetStats().
+  // Input resolution (output from video_adapter) can be further scaled down or
+  // higher video layer(s) can be dropped due to bitrate constraints.
+  // Note, adapt_changes only include changes from the video_adapter.
+  if (stats.bw_limited_resolution)
+    info.adapt_reason |= ADAPTREASON_BANDWIDTH;
+
+  info.encoder_implementation_name = stats.encoder_implementation_name;
+  info.ssrc_groups = ssrc_groups_;
+  info.framerate_input = stats.input_frame_rate;
+  info.framerate_sent = stats.encode_frame_rate;
+  info.avg_encode_ms = stats.avg_encode_time_ms;
+  info.encode_usage_percent = stats.encode_usage_percent;
+  info.frames_encoded = stats.frames_encoded;
+  info.qp_sum = stats.qp_sum;
+
+  info.nominal_bitrate = stats.media_bitrate_bps;
+  info.preferred_bitrate = stats.preferred_media_bitrate_bps;
+
+  info.send_frame_width = 0;
+  info.send_frame_height = 0;
+  for (std::map<uint32_t, webrtc::VideoSendStream::StreamStats>::iterator it =
+           stats.substreams.begin();
+       it != stats.substreams.end(); ++it) {
+    // TODO(pbos): Wire up additional stats, such as padding bytes.
+    webrtc::VideoSendStream::StreamStats stream_stats = it->second;
+    info.bytes_sent += stream_stats.rtp_stats.transmitted.payload_bytes +
+                       stream_stats.rtp_stats.transmitted.header_bytes +
+                       stream_stats.rtp_stats.transmitted.padding_bytes;
+    info.packets_sent += stream_stats.rtp_stats.transmitted.packets;
+    info.packets_lost += stream_stats.rtcp_stats.cumulative_lost;
+    if (stream_stats.width > info.send_frame_width)
+      info.send_frame_width = stream_stats.width;
+    if (stream_stats.height > info.send_frame_height)
+      info.send_frame_height = stream_stats.height;
+    info.firs_rcvd += stream_stats.rtcp_packet_type_counts.fir_packets;
+    info.nacks_rcvd += stream_stats.rtcp_packet_type_counts.nack_packets;
+    info.plis_rcvd += stream_stats.rtcp_packet_type_counts.pli_packets;
+  }
+
+  if (!stats.substreams.empty()) {
+    // TODO(pbos): Report fraction lost per SSRC.
+    webrtc::VideoSendStream::StreamStats first_stream_stats =
+        stats.substreams.begin()->second;
+    info.fraction_lost =
+        static_cast<float>(first_stream_stats.rtcp_stats.fraction_lost) /
+        (1 << 8);
+  }
+
+  return info;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::FillBandwidthEstimationInfo(
+    BandwidthEstimationInfo* bwe_info) {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  if (stream_ == NULL) {
+    return;
+  }
+  webrtc::VideoSendStream::Stats stats = stream_->GetStats();
+  for (std::map<uint32_t, webrtc::VideoSendStream::StreamStats>::iterator it =
+           stats.substreams.begin();
+       it != stats.substreams.end(); ++it) {
+    bwe_info->transmit_bitrate += it->second.total_bitrate_bps;
+    bwe_info->retransmit_bitrate += it->second.retransmit_bitrate_bps;
+  }
+  bwe_info->target_enc_bitrate += stats.target_media_bitrate_bps;
+  bwe_info->actual_enc_bitrate += stats.media_bitrate_bps;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoSendStream::RecreateWebRtcStream() {
+  RTC_DCHECK_RUN_ON(&thread_checker_);
+  if (stream_ != NULL) {
+    call_->DestroyVideoSendStream(stream_);
+  }
+
+  RTC_CHECK(parameters_.codec_settings);
+  RTC_DCHECK_EQ((parameters_.encoder_config.content_type ==
+                 webrtc::VideoEncoderConfig::ContentType::kScreen),
+                parameters_.options.is_screencast.value_or(false))
+      << "encoder content type inconsistent with screencast option";
+  parameters_.encoder_config.encoder_specific_settings =
+      ConfigureVideoEncoderSettings(parameters_.codec_settings->codec);
+
+  webrtc::VideoSendStream::Config config = parameters_.config.Copy();
+  if (!config.rtp.rtx.ssrcs.empty() && config.rtp.rtx.payload_type == -1) {
+    LOG(LS_WARNING) << "RTX SSRCs configured but there's no configured RTX "
+                       "payload type the set codec. Ignoring RTX.";
+    config.rtp.rtx.ssrcs.clear();
+  }
+  stream_ = call_->CreateVideoSendStream(std::move(config),
+                                         parameters_.encoder_config.Copy());
+
+  parameters_.encoder_config.encoder_specific_settings = NULL;
+
+  if (source_) {
+    // Do not adapt resolution for screen content as this will likely result in
+    // blurry and unreadable text.
+    // |this| acts like a VideoSource to make sure SinkWants are handled on the
+    // correct thread.
+    stream_->SetSource(
+        this, enable_cpu_overuse_detection_ &&
+                      !parameters_.options.is_screencast.value_or(false)
+                  ? webrtc::VideoSendStream::DegradationPreference::kBalanced
+                  : webrtc::VideoSendStream::DegradationPreference::
+                        kMaintainResolution);
+  }
+
+  // Call stream_->Start() if necessary conditions are met.
+  UpdateSendState();
+}
+
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::WebRtcVideoReceiveStream(
+    webrtc::Call* call,
+    const StreamParams& sp,
+    webrtc::VideoReceiveStream::Config config,
+    WebRtcVideoDecoderFactory* external_decoder_factory,
+    bool default_stream,
+    const std::vector<VideoCodecSettings>& recv_codecs,
+    const webrtc::FlexfecReceiveStream::Config& flexfec_config)
+    : call_(call),
+      stream_params_(sp),
+      stream_(NULL),
+      default_stream_(default_stream),
+      config_(std::move(config)),
+      flexfec_config_(flexfec_config),
+      flexfec_stream_(nullptr),
+      external_decoder_factory_(external_decoder_factory),
+      sink_(NULL),
+      first_frame_timestamp_(-1),
+      estimated_remote_start_ntp_time_ms_(0) {
+  config_.renderer = this;
+  std::vector<AllocatedDecoder> old_decoders;
+  ConfigureCodecs(recv_codecs, &old_decoders);
+  RecreateWebRtcStream();
+  RTC_DCHECK(old_decoders.empty());
+}
+
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::AllocatedDecoder::
+    AllocatedDecoder(webrtc::VideoDecoder* decoder,
+                     webrtc::VideoCodecType type,
+                     bool external)
+    : decoder(decoder),
+      external_decoder(nullptr),
+      type(type),
+      external(external) {
+  if (external) {
+    external_decoder = decoder;
+    this->decoder =
+        new webrtc::VideoDecoderSoftwareFallbackWrapper(type, external_decoder);
+  }
+}
+
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::~WebRtcVideoReceiveStream() {
+  if (flexfec_stream_) {
+    call_->DestroyFlexfecReceiveStream(flexfec_stream_);
+  }
+  call_->DestroyVideoReceiveStream(stream_);
+  ClearDecoders(&allocated_decoders_);
+}
+
+const std::vector<uint32_t>&
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetSsrcs() const {
+  return stream_params_.ssrcs;
+}
+
+rtc::Optional<uint32_t>
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetFirstPrimarySsrc() const {
+  std::vector<uint32_t> primary_ssrcs;
+  stream_params_.GetPrimarySsrcs(&primary_ssrcs);
+
+  if (primary_ssrcs.empty()) {
+    LOG(LS_WARNING) << "Empty primary ssrcs vector, returning empty optional";
+    return rtc::Optional<uint32_t>();
+  } else {
+    return rtc::Optional<uint32_t>(primary_ssrcs[0]);
+  }
+}
+
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::AllocatedDecoder
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::CreateOrReuseVideoDecoder(
+    std::vector<AllocatedDecoder>* old_decoders,
+    const VideoCodec& codec) {
+  webrtc::VideoCodecType type = webrtc::PayloadNameToCodecType(codec.name)
+                                    .value_or(webrtc::kVideoCodecUnknown);
+
+  for (size_t i = 0; i < old_decoders->size(); ++i) {
+    if ((*old_decoders)[i].type == type) {
+      AllocatedDecoder decoder = (*old_decoders)[i];
+      (*old_decoders)[i] = old_decoders->back();
+      old_decoders->pop_back();
+      return decoder;
+    }
+  }
+
+  if (external_decoder_factory_ != NULL) {
+    webrtc::VideoDecoder* decoder =
+        external_decoder_factory_->CreateVideoDecoderWithParams(
+            type, {stream_params_.id});
+    if (decoder != NULL) {
+      return AllocatedDecoder(decoder, type, true /* is_external */);
+    }
+  }
+
+  InternalDecoderFactory internal_decoder_factory;
+  return AllocatedDecoder(internal_decoder_factory.CreateVideoDecoderWithParams(
+                              type, {stream_params_.id}),
+                          type, false /* is_external */);
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::ConfigureCodecs(
+    const std::vector<VideoCodecSettings>& recv_codecs,
+    std::vector<AllocatedDecoder>* old_decoders) {
+  *old_decoders = allocated_decoders_;
+  allocated_decoders_.clear();
+  config_.decoders.clear();
+  for (size_t i = 0; i < recv_codecs.size(); ++i) {
+    AllocatedDecoder allocated_decoder =
+        CreateOrReuseVideoDecoder(old_decoders, recv_codecs[i].codec);
+    allocated_decoders_.push_back(allocated_decoder);
+
+    webrtc::VideoReceiveStream::Decoder decoder;
+    decoder.decoder = allocated_decoder.decoder;
+    decoder.payload_type = recv_codecs[i].codec.id;
+    decoder.payload_name = recv_codecs[i].codec.name;
+    decoder.codec_params = recv_codecs[i].codec.params;
+    config_.decoders.push_back(decoder);
+  }
+
+  config_.rtp.rtx_payload_types.clear();
+  for (const VideoCodecSettings& recv_codec : recv_codecs) {
+    config_.rtp.rtx_payload_types[recv_codec.codec.id] =
+        recv_codec.rtx_payload_type;
+  }
+
+  config_.rtp.ulpfec = recv_codecs.front().ulpfec;
+  flexfec_config_.payload_type = recv_codecs.front().flexfec_payload_type;
+
+  config_.rtp.nack.rtp_history_ms =
+      HasNack(recv_codecs.begin()->codec) ? kNackHistoryMs : 0;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetLocalSsrc(
+    uint32_t local_ssrc) {
+  // TODO(pbos): Consider turning this sanity check into a RTC_DCHECK. You
+  // should not be able to create a sender with the same SSRC as a receiver, but
+  // right now this can't be done due to unittests depending on receiving what
+  // they are sending from the same MediaChannel.
+  if (local_ssrc == config_.rtp.remote_ssrc) {
+    LOG(LS_INFO) << "Ignoring call to SetLocalSsrc because parameters are "
+                    "unchanged; local_ssrc=" << local_ssrc;
+    return;
+  }
+
+  config_.rtp.local_ssrc = local_ssrc;
+  flexfec_config_.local_ssrc = local_ssrc;
+  LOG(LS_INFO)
+      << "RecreateWebRtcStream (recv) because of SetLocalSsrc; local_ssrc="
+      << local_ssrc;
+  RecreateWebRtcStream();
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetFeedbackParameters(
+    bool nack_enabled,
+    bool remb_enabled,
+    bool transport_cc_enabled,
+    webrtc::RtcpMode rtcp_mode) {
+  int nack_history_ms = nack_enabled ? kNackHistoryMs : 0;
+  if (config_.rtp.nack.rtp_history_ms == nack_history_ms &&
+      config_.rtp.remb == remb_enabled &&
+      config_.rtp.transport_cc == transport_cc_enabled &&
+      config_.rtp.rtcp_mode == rtcp_mode) {
+    LOG(LS_INFO)
+        << "Ignoring call to SetFeedbackParameters because parameters are "
+           "unchanged; nack="
+        << nack_enabled << ", remb=" << remb_enabled
+        << ", transport_cc=" << transport_cc_enabled;
+    return;
+  }
+  config_.rtp.remb = remb_enabled;
+  config_.rtp.nack.rtp_history_ms = nack_history_ms;
+  config_.rtp.transport_cc = transport_cc_enabled;
+  config_.rtp.rtcp_mode = rtcp_mode;
+  // TODO(brandtr): We should be spec-compliant and set |transport_cc| here
+  // based on the rtcp-fb for the FlexFEC codec, not the media codec.
+  flexfec_config_.transport_cc = config_.rtp.transport_cc;
+  flexfec_config_.rtcp_mode = config_.rtp.rtcp_mode;
+  LOG(LS_INFO)
+      << "RecreateWebRtcStream (recv) because of SetFeedbackParameters; nack="
+      << nack_enabled << ", remb=" << remb_enabled
+      << ", transport_cc=" << transport_cc_enabled;
+  RecreateWebRtcStream();
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetRecvParameters(
+    const ChangedRecvParameters& params) {
+  bool needs_recreation = false;
+  std::vector<AllocatedDecoder> old_decoders;
+  if (params.codec_settings) {
+    ConfigureCodecs(*params.codec_settings, &old_decoders);
+    needs_recreation = true;
+  }
+  if (params.rtp_header_extensions) {
+    config_.rtp.extensions = *params.rtp_header_extensions;
+    flexfec_config_.rtp_header_extensions = *params.rtp_header_extensions;
+    needs_recreation = true;
+  }
+  if (needs_recreation) {
+    LOG(LS_INFO) << "RecreateWebRtcStream (recv) because of SetRecvParameters";
+    RecreateWebRtcStream();
+    ClearDecoders(&old_decoders);
+  }
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::RecreateWebRtcStream() {
+  if (stream_) {
+    call_->DestroyVideoReceiveStream(stream_);
+    stream_ = nullptr;
+  }
+  if (flexfec_stream_) {
+    call_->DestroyFlexfecReceiveStream(flexfec_stream_);
+    flexfec_stream_ = nullptr;
+  }
+  if (flexfec_config_.IsCompleteAndEnabled()) {
+    flexfec_stream_ = call_->CreateFlexfecReceiveStream(flexfec_config_);
+    flexfec_stream_->Start();
+  }
+  stream_ = call_->CreateVideoReceiveStream(config_.Copy());
+  stream_->Start();
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::ClearDecoders(
+    std::vector<AllocatedDecoder>* allocated_decoders) {
+  for (size_t i = 0; i < allocated_decoders->size(); ++i) {
+    if ((*allocated_decoders)[i].external) {
+      external_decoder_factory_->DestroyVideoDecoder(
+          (*allocated_decoders)[i].external_decoder);
+    }
+    delete (*allocated_decoders)[i].decoder;
+  }
+  allocated_decoders->clear();
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::OnFrame(
+    const webrtc::VideoFrame& frame) {
+  rtc::CritScope crit(&sink_lock_);
+
+  if (first_frame_timestamp_ < 0)
+    first_frame_timestamp_ = frame.timestamp();
+  int64_t rtp_time_elapsed_since_first_frame =
+      (timestamp_wraparound_handler_.Unwrap(frame.timestamp()) -
+       first_frame_timestamp_);
+  int64_t elapsed_time_ms = rtp_time_elapsed_since_first_frame /
+                            (cricket::kVideoCodecClockrate / 1000);
+  if (frame.ntp_time_ms() > 0)
+    estimated_remote_start_ntp_time_ms_ = frame.ntp_time_ms() - elapsed_time_ms;
+
+  if (sink_ == NULL) {
+    LOG(LS_WARNING) << "VideoReceiveStream not connected to a VideoSink.";
+    return;
+  }
+
+  sink_->OnFrame(frame);
+}
+
+bool WebRtcVideoChannel2::WebRtcVideoReceiveStream::IsDefaultStream() const {
+  return default_stream_;
+}
+
+void WebRtcVideoChannel2::WebRtcVideoReceiveStream::SetSink(
+    rtc::VideoSinkInterface<webrtc::VideoFrame>* sink) {
+  rtc::CritScope crit(&sink_lock_);
+  sink_ = sink;
+}
+
+std::string
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetCodecNameFromPayloadType(
+    int payload_type) {
+  for (const webrtc::VideoReceiveStream::Decoder& decoder : config_.decoders) {
+    if (decoder.payload_type == payload_type) {
+      return decoder.payload_name;
+    }
+  }
+  return "";
+}
+
+VideoReceiverInfo
+WebRtcVideoChannel2::WebRtcVideoReceiveStream::GetVideoReceiverInfo(
+    bool log_stats) {
+  VideoReceiverInfo info;
+  info.ssrc_groups = stream_params_.ssrc_groups;
+  info.add_ssrc(config_.rtp.remote_ssrc);
+  webrtc::VideoReceiveStream::Stats stats = stream_->GetStats();
+  info.decoder_implementation_name = stats.decoder_implementation_name;
+  if (stats.current_payload_type != -1) {
+    info.codec_payload_type = rtc::Optional<int>(
+        stats.current_payload_type);
+  }
+  info.bytes_rcvd = stats.rtp_stats.transmitted.payload_bytes +
+                    stats.rtp_stats.transmitted.header_bytes +
+                    stats.rtp_stats.transmitted.padding_bytes;
+  info.packets_rcvd = stats.rtp_stats.transmitted.packets;
+  info.packets_lost = stats.rtcp_stats.cumulative_lost;
+  info.fraction_lost =
+      static_cast<float>(stats.rtcp_stats.fraction_lost) / (1 << 8);
+
+  info.framerate_rcvd = stats.network_frame_rate;
+  info.framerate_decoded = stats.decode_frame_rate;
+  info.framerate_output = stats.render_frame_rate;
+  info.frame_width = stats.width;
+  info.frame_height = stats.height;
+
+  {
+    rtc::CritScope frame_cs(&sink_lock_);
+    info.capture_start_ntp_time_ms = estimated_remote_start_ntp_time_ms_;
+  }
+
+  info.decode_ms = stats.decode_ms;
+  info.max_decode_ms = stats.max_decode_ms;
+  info.current_delay_ms = stats.current_delay_ms;
+  info.target_delay_ms = stats.target_delay_ms;
+  info.jitter_buffer_ms = stats.jitter_buffer_ms;
+  info.min_playout_delay_ms = stats.min_playout_delay_ms;
+  info.render_delay_ms = stats.render_delay_ms;
+  info.frames_received = stats.frame_counts.key_frames +
+                         stats.frame_counts.delta_frames;
+  info.frames_decoded = stats.frames_decoded;
+  info.frames_rendered = stats.frames_rendered;
+  info.qp_sum = stats.qp_sum;
+
+  info.codec_name = GetCodecNameFromPayloadType(stats.current_payload_type);
+
+  info.firs_sent = stats.rtcp_packet_type_counts.fir_packets;
+  info.plis_sent = stats.rtcp_packet_type_counts.pli_packets;
+  info.nacks_sent = stats.rtcp_packet_type_counts.nack_packets;
+
+  if (log_stats)
+    LOG(LS_INFO) << stats.ToString(rtc::TimeMillis());
+
+  return info;
+}
+
+WebRtcVideoChannel2::VideoCodecSettings::VideoCodecSettings()
+    : flexfec_payload_type(-1), rtx_payload_type(-1) {}
+
+bool WebRtcVideoChannel2::VideoCodecSettings::operator==(
+    const WebRtcVideoChannel2::VideoCodecSettings& other) const {
+  return codec == other.codec && ulpfec == other.ulpfec &&
+         flexfec_payload_type == other.flexfec_payload_type &&
+         rtx_payload_type == other.rtx_payload_type;
+}
+
+bool WebRtcVideoChannel2::VideoCodecSettings::operator!=(
+    const WebRtcVideoChannel2::VideoCodecSettings& other) const {
+  return !(*this == other);
+}
+
+std::vector<WebRtcVideoChannel2::VideoCodecSettings>
+WebRtcVideoChannel2::MapCodecs(const std::vector<VideoCodec>& codecs) {
+  RTC_DCHECK(!codecs.empty());
+
+  std::vector<VideoCodecSettings> video_codecs;
+  std::map<int, bool> payload_used;
+  std::map<int, VideoCodec::CodecType> payload_codec_type;
+  // |rtx_mapping| maps video payload type to rtx payload type.
+  std::map<int, int> rtx_mapping;
+
+  webrtc::UlpfecConfig ulpfec_config;
+  int flexfec_payload_type = -1;
+
+  for (size_t i = 0; i < codecs.size(); ++i) {
+    const VideoCodec& in_codec = codecs[i];
+    int payload_type = in_codec.id;
+
+    if (payload_used[payload_type]) {
+      LOG(LS_ERROR) << "Payload type already registered: "
+                    << in_codec.ToString();
+      return std::vector<VideoCodecSettings>();
+    }
+    payload_used[payload_type] = true;
+    payload_codec_type[payload_type] = in_codec.GetCodecType();
+
+    switch (in_codec.GetCodecType()) {
+      case VideoCodec::CODEC_RED: {
+        // RED payload type, should not have duplicates.
+        RTC_DCHECK_EQ(-1, ulpfec_config.red_payload_type);
+        ulpfec_config.red_payload_type = in_codec.id;
+        continue;
+      }
+
+      case VideoCodec::CODEC_ULPFEC: {
+        // ULPFEC payload type, should not have duplicates.
+        RTC_DCHECK_EQ(-1, ulpfec_config.ulpfec_payload_type);
+        ulpfec_config.ulpfec_payload_type = in_codec.id;
+        continue;
+      }
+
+      case VideoCodec::CODEC_FLEXFEC: {
+        // FlexFEC payload type, should not have duplicates.
+        RTC_DCHECK_EQ(-1, flexfec_payload_type);
+        flexfec_payload_type = in_codec.id;
+        continue;
+      }
+
+      case VideoCodec::CODEC_RTX: {
+        int associated_payload_type;
+        if (!in_codec.GetParam(kCodecParamAssociatedPayloadType,
+                               &associated_payload_type) ||
+            !IsValidRtpPayloadType(associated_payload_type)) {
+          LOG(LS_ERROR)
+              << "RTX codec with invalid or no associated payload type: "
+              << in_codec.ToString();
+          return std::vector<VideoCodecSettings>();
+        }
+        rtx_mapping[associated_payload_type] = in_codec.id;
+        continue;
+      }
+
+      case VideoCodec::CODEC_VIDEO:
+        break;
+    }
+
+    video_codecs.push_back(VideoCodecSettings());
+    video_codecs.back().codec = in_codec;
+  }
+
+  // One of these codecs should have been a video codec. Only having FEC
+  // parameters into this code is a logic error.
+  RTC_DCHECK(!video_codecs.empty());
+
+  for (std::map<int, int>::const_iterator it = rtx_mapping.begin();
+       it != rtx_mapping.end();
+       ++it) {
+    if (!payload_used[it->first]) {
+      LOG(LS_ERROR) << "RTX mapped to payload not in codec list.";
+      return std::vector<VideoCodecSettings>();
+    }
+    if (payload_codec_type[it->first] != VideoCodec::CODEC_VIDEO &&
+        payload_codec_type[it->first] != VideoCodec::CODEC_RED) {
+      LOG(LS_ERROR) << "RTX not mapped to regular video codec or RED codec.";
+      return std::vector<VideoCodecSettings>();
+    }
+
+    if (it->first == ulpfec_config.red_payload_type) {
+      ulpfec_config.red_rtx_payload_type = it->second;
+    }
+  }
+
+  for (size_t i = 0; i < video_codecs.size(); ++i) {
+    video_codecs[i].ulpfec = ulpfec_config;
+    video_codecs[i].flexfec_payload_type = flexfec_payload_type;
+    if (rtx_mapping[video_codecs[i].codec.id] != 0 &&
+        rtx_mapping[video_codecs[i].codec.id] !=
+            ulpfec_config.red_payload_type) {
+      video_codecs[i].rtx_payload_type = rtx_mapping[video_codecs[i].codec.id];
+    }
+  }
+
+  return video_codecs;
+}
+
+}  // namespace cricket
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
index 84bfafb..055cc1f 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
+++ b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
@@ -1,503 +1,590 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- *
- */
-
-#include "webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h"
-
-#include <limits>
-#include <string>
-
-#include "third_party/openh264/src/codec/api/svc/codec_api.h"
-#include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
-#include "third_party/openh264/src/codec/api/svc/codec_def.h"
-#include "third_party/openh264/src/codec/api/svc/codec_ver.h"
-
-#include "webrtc/base/checks.h"
-#include "webrtc/base/logging.h"
-#include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
-#include "webrtc/media/base/mediaconstants.h"
-#include "webrtc/system_wrappers/include/metrics.h"
-
-namespace webrtc {
-
-namespace {
-
-const bool kOpenH264EncoderDetailedLogging = false;
-
-// Used by histograms. Values of entries should not be changed.
-enum H264EncoderImplEvent {
-  kH264EncoderEventInit = 0,
-  kH264EncoderEventError = 1,
-  kH264EncoderEventMax = 16,
-};
-
-int NumberOfThreads(int width, int height, int number_of_cores) {
-  // TODO(hbos): In Chromium, multiple threads do not work with sandbox on Mac,
-  // see crbug.com/583348. Until further investigated, only use one thread.
-//  if (width * height >= 1920 * 1080 && number_of_cores > 8) {
-//    return 8;  // 8 threads for 1080p on high perf machines.
-//  } else if (width * height > 1280 * 960 && number_of_cores >= 6) {
-//    return 3;  // 3 threads for 1080p.
-//  } else if (width * height > 640 * 480 && number_of_cores >= 3) {
-//    return 2;  // 2 threads for qHD/HD.
-//  } else {
-//    return 1;  // 1 thread for VGA or less.
-//  }
-// TODO(sprang): Also check sSliceArgument.uiSliceNum om GetEncoderPrams(),
-//               before enabling multithreading here.
-  return 1;
-}
-
-FrameType ConvertToVideoFrameType(EVideoFrameType type) {
-  switch (type) {
-    case videoFrameTypeIDR:
-      return kVideoFrameKey;
-    case videoFrameTypeSkip:
-    case videoFrameTypeI:
-    case videoFrameTypeP:
-    case videoFrameTypeIPMixed:
-      return kVideoFrameDelta;
-    case videoFrameTypeInvalid:
-      break;
-  }
-  RTC_NOTREACHED() << "Unexpected/invalid frame type: " << type;
-  return kEmptyFrame;
-}
-
-}  // namespace
-
-// Helper method used by H264EncoderImpl::Encode.
-// Copies the encoded bytes from |info| to |encoded_image| and updates the
-// fragmentation information of |frag_header|. The |encoded_image->_buffer| may
-// be deleted and reallocated if a bigger buffer is required.
-//
-// After OpenH264 encoding, the encoded bytes are stored in |info| spread out
-// over a number of layers and "NAL units". Each NAL unit is a fragment starting
-// with the four-byte start code {0,0,0,1}. All of this data (including the
-// start codes) is copied to the |encoded_image->_buffer| and the |frag_header|
-// is updated to point to each fragment, with offsets and lengths set as to
-// exclude the start codes.
-static void RtpFragmentize(EncodedImage* encoded_image,
-                           std::unique_ptr<uint8_t[]>* encoded_image_buffer,
-                           const VideoFrameBuffer& frame_buffer,
-                           SFrameBSInfo* info,
-                           RTPFragmentationHeader* frag_header) {
-  // Calculate minimum buffer size required to hold encoded data.
-  size_t required_size = 0;
-  size_t fragments_count = 0;
-  for (int layer = 0; layer < info->iLayerNum; ++layer) {
-    const SLayerBSInfo& layerInfo = info->sLayerInfo[layer];
-    for (int nal = 0; nal < layerInfo.iNalCount; ++nal, ++fragments_count) {
-      RTC_CHECK_GE(layerInfo.pNalLengthInByte[nal], 0);
-      // Ensure |required_size| will not overflow.
-      RTC_CHECK_LE(layerInfo.pNalLengthInByte[nal],
-                   std::numeric_limits<size_t>::max() - required_size);
-      required_size += layerInfo.pNalLengthInByte[nal];
-    }
-  }
-  if (encoded_image->_size < required_size) {
-    // Increase buffer size. Allocate enough to hold an unencoded image, this
-    // should be more than enough to hold any encoded data of future frames of
-    // the same size (avoiding possible future reallocation due to variations in
-    // required size).
-    encoded_image->_size =
-        CalcBufferSize(kI420, frame_buffer.width(), frame_buffer.height());
-    if (encoded_image->_size < required_size) {
-      // Encoded data > unencoded data. Allocate required bytes.
-      LOG(LS_WARNING) << "Encoding produced more bytes than the original image "
-                      << "data! Original bytes: " << encoded_image->_size
-                      << ", encoded bytes: " << required_size << ".";
-      encoded_image->_size = required_size;
-    }
-    encoded_image->_buffer = new uint8_t[encoded_image->_size];
-    encoded_image_buffer->reset(encoded_image->_buffer);
-  }
-
-  // Iterate layers and NAL units, note each NAL unit as a fragment and copy
-  // the data to |encoded_image->_buffer|.
-  const uint8_t start_code[4] = {0, 0, 0, 1};
-  frag_header->VerifyAndAllocateFragmentationHeader(fragments_count);
-  size_t frag = 0;
-  encoded_image->_length = 0;
-  for (int layer = 0; layer < info->iLayerNum; ++layer) {
-    const SLayerBSInfo& layerInfo = info->sLayerInfo[layer];
-    // Iterate NAL units making up this layer, noting fragments.
-    size_t layer_len = 0;
-    for (int nal = 0; nal < layerInfo.iNalCount; ++nal, ++frag) {
-      // Because the sum of all layer lengths, |required_size|, fits in a
-      // |size_t|, we know that any indices in-between will not overflow.
-      RTC_DCHECK_GE(layerInfo.pNalLengthInByte[nal], 4);
-      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+0], start_code[0]);
-      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+1], start_code[1]);
-      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+2], start_code[2]);
-      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+3], start_code[3]);
-      frag_header->fragmentationOffset[frag] =
-          encoded_image->_length + layer_len + sizeof(start_code);
-      frag_header->fragmentationLength[frag] =
-          layerInfo.pNalLengthInByte[nal] - sizeof(start_code);
-      layer_len += layerInfo.pNalLengthInByte[nal];
-    }
-    // Copy the entire layer's data (including start codes).
-    memcpy(encoded_image->_buffer + encoded_image->_length,
-           layerInfo.pBsBuf,
-           layer_len);
-    encoded_image->_length += layer_len;
-  }
-}
-
-H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
-    : openh264_encoder_(nullptr),
-      width_(0),
-      height_(0),
-      max_frame_rate_(0.0f),
-      target_bps_(0),
-      max_bps_(0),
-      mode_(kRealtimeVideo),
-      frame_dropping_on_(false),
-      key_frame_interval_(0),
-      packetization_mode_(H264PacketizationMode::SingleNalUnit),
-      max_payload_size_(0),
-      number_of_cores_(0),
-      encoded_image_callback_(nullptr),
-      has_reported_init_(false),
-      has_reported_error_(false) {
-  RTC_CHECK(cricket::CodecNamesEq(codec.name, cricket::kH264CodecName));
-  std::string packetization_mode_string;
-  if (codec.GetParam(cricket::kH264FmtpPacketizationMode,
-                     &packetization_mode_string) &&
-      packetization_mode_string == "1") {
-    packetization_mode_ = H264PacketizationMode::NonInterleaved;
-  }
-}
-
-H264EncoderImpl::~H264EncoderImpl() {
-  Release();
-}
-
-int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
-                                    int32_t number_of_cores,
-                                    size_t max_payload_size) {
-  ReportInit();
-  if (!codec_settings ||
-      codec_settings->codecType != kVideoCodecH264) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-  }
-  if (codec_settings->maxFramerate == 0) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-  }
-  if (codec_settings->width < 1 || codec_settings->height < 1) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-  }
-
-  int32_t release_ret = Release();
-  if (release_ret != WEBRTC_VIDEO_CODEC_OK) {
-    ReportError();
-    return release_ret;
-  }
-  RTC_DCHECK(!openh264_encoder_);
-
-  // Create encoder.
-  if (WelsCreateSVCEncoder(&openh264_encoder_) != 0) {
-    // Failed to create encoder.
-    LOG(LS_ERROR) << "Failed to create OpenH264 encoder";
-    RTC_DCHECK(!openh264_encoder_);
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERROR;
-  }
-  RTC_DCHECK(openh264_encoder_);
-  if (kOpenH264EncoderDetailedLogging) {
-    int trace_level = WELS_LOG_DETAIL;
-    openh264_encoder_->SetOption(ENCODER_OPTION_TRACE_LEVEL,
-                                 &trace_level);
-  }
-  // else WELS_LOG_DEFAULT is used by default.
-
-  number_of_cores_ = number_of_cores;
-  // Set internal settings from codec_settings
-  width_ = codec_settings->width;
-  height_ = codec_settings->height;
-  max_frame_rate_ = static_cast<float>(codec_settings->maxFramerate);
-  mode_ = codec_settings->mode;
-  frame_dropping_on_ = codec_settings->H264().frameDroppingOn;
-  key_frame_interval_ = codec_settings->H264().keyFrameInterval;
-  max_payload_size_ = max_payload_size;
-
-  // Codec_settings uses kbits/second; encoder uses bits/second.
-  max_bps_ = codec_settings->maxBitrate * 1000;
-  if (codec_settings->targetBitrate == 0)
-    target_bps_ = codec_settings->startBitrate * 1000;
-  else
-    target_bps_ = codec_settings->targetBitrate * 1000;
-
-  SEncParamExt encoder_params = CreateEncoderParams();
-
-  // Initialize.
-  if (openh264_encoder_->InitializeExt(&encoder_params) != 0) {
-    LOG(LS_ERROR) << "Failed to initialize OpenH264 encoder";
-    Release();
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERROR;
-  }
-  // TODO(pbos): Base init params on these values before submitting.
-  int video_format = EVideoFormatType::videoFormatI420;
-  openh264_encoder_->SetOption(ENCODER_OPTION_DATAFORMAT,
-                               &video_format);
-
-  // Initialize encoded image. Default buffer size: size of unencoded data.
-  encoded_image_._size =
-      CalcBufferSize(kI420, codec_settings->width, codec_settings->height);
-  encoded_image_._buffer = new uint8_t[encoded_image_._size];
-  encoded_image_buffer_.reset(encoded_image_._buffer);
-  encoded_image_._completeFrame = true;
-  encoded_image_._encodedWidth = 0;
-  encoded_image_._encodedHeight = 0;
-  encoded_image_._length = 0;
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-int32_t H264EncoderImpl::Release() {
-  if (openh264_encoder_) {
-    RTC_CHECK_EQ(0, openh264_encoder_->Uninitialize());
-    WelsDestroySVCEncoder(openh264_encoder_);
-    openh264_encoder_ = nullptr;
-  }
-  encoded_image_._buffer = nullptr;
-  encoded_image_buffer_.reset();
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-int32_t H264EncoderImpl::RegisterEncodeCompleteCallback(
-    EncodedImageCallback* callback) {
-  encoded_image_callback_ = callback;
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-int32_t H264EncoderImpl::SetRateAllocation(
-    const BitrateAllocation& bitrate_allocation,
-    uint32_t framerate) {
-  if (bitrate_allocation.get_sum_bps() <= 0 || framerate <= 0)
-    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
-
-  target_bps_ = bitrate_allocation.get_sum_bps();
-  max_frame_rate_ = static_cast<float>(framerate);
-
-  SBitrateInfo target_bitrate;
-  memset(&target_bitrate, 0, sizeof(SBitrateInfo));
-  target_bitrate.iLayer = SPATIAL_LAYER_ALL,
-  target_bitrate.iBitrate = target_bps_;
-  openh264_encoder_->SetOption(ENCODER_OPTION_BITRATE,
-                               &target_bitrate);
-  openh264_encoder_->SetOption(ENCODER_OPTION_FRAME_RATE, &max_frame_rate_);
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
-                                const CodecSpecificInfo* codec_specific_info,
-                                const std::vector<FrameType>* frame_types) {
-  if (!IsInitialized()) {
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
-  }
-  if (!encoded_image_callback_) {
-    LOG(LS_WARNING) << "InitEncode() has been called, but a callback function "
-                    << "has not been set with RegisterEncodeCompleteCallback()";
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
-  }
-
-  bool force_key_frame = false;
-  if (frame_types != nullptr) {
-    // We only support a single stream.
-    RTC_DCHECK_EQ(frame_types->size(), 1);
-    // Skip frame?
-    if ((*frame_types)[0] == kEmptyFrame) {
-      return WEBRTC_VIDEO_CODEC_OK;
-    }
-    // Force key frame?
-    force_key_frame = (*frame_types)[0] == kVideoFrameKey;
-  }
-  if (force_key_frame) {
-    // API doc says ForceIntraFrame(false) does nothing, but calling this
-    // function forces a key frame regardless of the |bIDR| argument's value.
-    // (If every frame is a key frame we get lag/delays.)
-    openh264_encoder_->ForceIntraFrame(true);
-  }
-  rtc::scoped_refptr<const VideoFrameBuffer> frame_buffer =
-      input_frame.video_frame_buffer();
-  // EncodeFrame input.
-  SSourcePicture picture;
-  memset(&picture, 0, sizeof(SSourcePicture));
-  picture.iPicWidth = frame_buffer->width();
-  picture.iPicHeight = frame_buffer->height();
-  picture.iColorFormat = EVideoFormatType::videoFormatI420;
-  picture.uiTimeStamp = input_frame.ntp_time_ms();
-  picture.iStride[0] = frame_buffer->StrideY();
-  picture.iStride[1] = frame_buffer->StrideU();
-  picture.iStride[2] = frame_buffer->StrideV();
-  picture.pData[0] = const_cast<uint8_t*>(frame_buffer->DataY());
-  picture.pData[1] = const_cast<uint8_t*>(frame_buffer->DataU());
-  picture.pData[2] = const_cast<uint8_t*>(frame_buffer->DataV());
-
-  // EncodeFrame output.
-  SFrameBSInfo info;
-  memset(&info, 0, sizeof(SFrameBSInfo));
-
-  // Encode!
-  int enc_ret = openh264_encoder_->EncodeFrame(&picture, &info);
-  if (enc_ret != 0) {
-    LOG(LS_ERROR) << "OpenH264 frame encoding failed, EncodeFrame returned "
-                  << enc_ret << ".";
-    ReportError();
-    return WEBRTC_VIDEO_CODEC_ERROR;
-  }
-
-  encoded_image_._encodedWidth = frame_buffer->width();
-  encoded_image_._encodedHeight = frame_buffer->height();
-  encoded_image_._timeStamp = input_frame.timestamp();
-  encoded_image_.ntp_time_ms_ = input_frame.ntp_time_ms();
-  encoded_image_.capture_time_ms_ = input_frame.render_time_ms();
-  encoded_image_.rotation_ = input_frame.rotation();
-  encoded_image_._frameType = ConvertToVideoFrameType(info.eFrameType);
-
-  // Split encoded image up into fragments. This also updates |encoded_image_|.
-  RTPFragmentationHeader frag_header;
-  RtpFragmentize(&encoded_image_, &encoded_image_buffer_, *frame_buffer, &info,
-                 &frag_header);
-
-  // Encoder can skip frames to save bandwidth in which case
-  // |encoded_image_._length| == 0.
-  if (encoded_image_._length > 0) {
-    // Parse QP.
-    h264_bitstream_parser_.ParseBitstream(encoded_image_._buffer,
-                                          encoded_image_._length);
-    h264_bitstream_parser_.GetLastSliceQp(&encoded_image_.qp_);
-
-    // Deliver encoded image.
-    CodecSpecificInfo codec_specific;
-    codec_specific.codecType = kVideoCodecH264;
-    codec_specific.codecSpecific.H264.packetization_mode = packetization_mode_;
-    encoded_image_callback_->OnEncodedImage(encoded_image_, &codec_specific,
-                                            &frag_header);
-  }
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-const char* H264EncoderImpl::ImplementationName() const {
-  return "OpenH264";
-}
-
-bool H264EncoderImpl::IsInitialized() const {
-  return openh264_encoder_ != nullptr;
-}
-
-// Initialization parameters.
-// There are two ways to initialize. There is SEncParamBase (cleared with
-// memset(&p, 0, sizeof(SEncParamBase)) used in Initialize, and SEncParamExt
-// which is a superset of SEncParamBase (cleared with GetDefaultParams) used
-// in InitializeExt.
-SEncParamExt H264EncoderImpl::CreateEncoderParams() const {
-  RTC_DCHECK(openh264_encoder_);
-  SEncParamExt encoder_params;
-  openh264_encoder_->GetDefaultParams(&encoder_params);
-  if (mode_ == kRealtimeVideo) {
-    encoder_params.iUsageType = CAMERA_VIDEO_REAL_TIME;
-  } else if (mode_ == kScreensharing) {
-    encoder_params.iUsageType = SCREEN_CONTENT_REAL_TIME;
-  } else {
-    RTC_NOTREACHED();
-  }
-  encoder_params.iPicWidth = width_;
-  encoder_params.iPicHeight = height_;
-  encoder_params.iTargetBitrate = target_bps_;
-  encoder_params.iMaxBitrate = max_bps_;
-  // Rate Control mode
-  encoder_params.iRCMode = RC_BITRATE_MODE;
-  encoder_params.fMaxFrameRate = max_frame_rate_;
-
-  // The following parameters are extension parameters (they're in SEncParamExt,
-  // not in SEncParamBase).
-  encoder_params.bEnableFrameSkip = frame_dropping_on_;
-  // |uiIntraPeriod|    - multiple of GOP size
-  // |keyFrameInterval| - number of frames
-  encoder_params.uiIntraPeriod = key_frame_interval_;
-  encoder_params.uiMaxNalSize = 0;
-  // Threading model: use auto.
-  //  0: auto (dynamic imp. internal encoder)
-  //  1: single thread (default value)
-  // >1: number of threads
-  encoder_params.iMultipleThreadIdc = NumberOfThreads(
-      encoder_params.iPicWidth, encoder_params.iPicHeight, number_of_cores_);
-  // The base spatial layer 0 is the only one we use.
-  encoder_params.sSpatialLayers[0].iVideoWidth = encoder_params.iPicWidth;
-  encoder_params.sSpatialLayers[0].iVideoHeight = encoder_params.iPicHeight;
-  encoder_params.sSpatialLayers[0].fFrameRate = encoder_params.fMaxFrameRate;
-  encoder_params.sSpatialLayers[0].iSpatialBitrate =
-      encoder_params.iTargetBitrate;
-  encoder_params.sSpatialLayers[0].iMaxSpatialBitrate =
-      encoder_params.iMaxBitrate;
-  LOG(INFO) << "OpenH264 version is " << OPENH264_MAJOR << "."
-            << OPENH264_MINOR;
-  switch (packetization_mode_) {
-    case H264PacketizationMode::SingleNalUnit:
-      // Limit the size of the packets produced.
-      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceNum = 1;
-      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceMode =
-          SM_SIZELIMITED_SLICE;
-      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceSizeConstraint =
-          static_cast<unsigned int>(max_payload_size_);
-      break;
-    case H264PacketizationMode::NonInterleaved:
-      // When uiSliceMode = SM_FIXEDSLCNUM_SLICE, uiSliceNum = 0 means auto
-      // design it with cpu core number.
-      // TODO(sprang): Set to 0 when we understand why the rate controller borks
-      //               when uiSliceNum > 1.
-      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceNum = 1;
-      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceMode =
-          SM_FIXEDSLCNUM_SLICE;
-      break;
-  }
-  return encoder_params;
-}
-
-void H264EncoderImpl::ReportInit() {
-  if (has_reported_init_)
-    return;
-  RTC_HISTOGRAM_ENUMERATION("WebRTC.Video.H264EncoderImpl.Event",
-                            kH264EncoderEventInit,
-                            kH264EncoderEventMax);
-  has_reported_init_ = true;
-}
-
-void H264EncoderImpl::ReportError() {
-  if (has_reported_error_)
-    return;
-  RTC_HISTOGRAM_ENUMERATION("WebRTC.Video.H264EncoderImpl.Event",
-                            kH264EncoderEventError,
-                            kH264EncoderEventMax);
-  has_reported_error_ = true;
-}
-
-int32_t H264EncoderImpl::SetChannelParameters(
-    uint32_t packet_loss, int64_t rtt) {
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-int32_t H264EncoderImpl::SetPeriodicKeyFrames(bool enable) {
-  return WEBRTC_VIDEO_CODEC_OK;
-}
-
-VideoEncoder::ScalingSettings H264EncoderImpl::GetScalingSettings() const {
-  return VideoEncoder::ScalingSettings(true);
-}
-
-}  // namespace webrtc
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ */
+
+#include "webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h"
+#include "webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.h"
+#include "webrtc/common_video/h264/h264_common.h"
+
+#include <limits>
+#include <string>
+
+#include "third_party/openh264/src/codec/api/svc/codec_api.h"
+#include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
+#include "third_party/openh264/src/codec/api/svc/codec_def.h"
+#include "third_party/openh264/src/codec/api/svc/codec_ver.h"
+
+#if USEX264
+//#define __STDC_CONSTANT_MACROS
+//x264 and ffmpeg headers
+extern "C"
+ {
+	#include "third_party/x264/x264.h"
+	#include "third_party/ffmpeg/libavcodec/avcodec.h"
+	#include "third_party/ffmpeg/libavformat/avformat.h"
+	#include "third_party/ffmpeg/libswscale/swscale.h"
+}
+#endif
+
+#include "webrtc/base/checks.h"
+#include "webrtc/base/logging.h"
+#include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
+#include "webrtc/media/base/mediaconstants.h"
+#include "webrtc/system_wrappers/include/metrics.h"
+
+#include <memory>
+#include <utility>
+#include <vector>
+#include <iostream>
+#include <fstream>
+#include "webrtc/base/thread.h"
+#include "webrtc/base/bind.h"
+#include "webrtc/base/asyncinvoker.h"
+
+namespace webrtc {
+
+namespace {
+
+// Used by histograms. Values of entries should not be changed.
+enum H264EncoderImplEvent {
+  kH264EncoderEventInit = 0,
+  kH264EncoderEventError = 1,
+  kH264EncoderEventMax = 16,
+};
+
+const bool kOpenH264EncoderDetailedLogging = false;
+
+int NumberOfThreads(int width, int height, int number_of_cores) {
+  // TODO(hbos): In Chromium, multiple threads do not work with sandbox on Mac,
+  // see crbug.com/583348. Until further investigated, only use one thread.
+//  if (width * height >= 1920 * 1080 && number_of_cores > 8) {
+//    return 8;  // 8 threads for 1080p on high perf machines.
+//  } else if (width * height > 1280 * 960 && number_of_cores >= 6) {
+//    return 3;  // 3 threads for 1080p.
+//  } else if (width * height > 640 * 480 && number_of_cores >= 3) {
+//    return 2;  // 2 threads for qHD/HD.
+//  } else {
+//    return 1;  // 1 thread for VGA or less.
+//  }
+// TODO(sprang): Also check sSliceArgument.uiSliceNum om GetEncoderPrams(),
+//               before enabling multithreading here.
+  return 1;
+}
+
+FrameType ConvertToVideoFrameType(EVideoFrameType type) {
+  switch (type) {
+    case videoFrameTypeIDR:
+      return kVideoFrameKey;
+    case videoFrameTypeSkip:
+    case videoFrameTypeI:
+    case videoFrameTypeP:
+    case videoFrameTypeIPMixed:
+      return kVideoFrameDelta;
+    case videoFrameTypeInvalid:
+      break;
+  }
+  RTC_NOTREACHED() << "Unexpected/invalid frame type: " << type;
+  return kEmptyFrame;
+}
+}  // namespace
+
+// Helper method used by H264EncoderImpl::Encode.
+// Copies the encoded bytes from |info| to |encoded_image| and updates the
+// fragmentation information of |frag_header|. The |encoded_image->_buffer| may
+// be deleted and reallocated if a bigger buffer is required.
+//
+// After OpenH264 encoding, the encoded bytes are stored in |info| spread out
+// over a number of layers and "NAL units". Each NAL unit is a fragment starting
+// with the four-byte start code {0,0,0,1}. All of this data (including the
+// start codes) is copied to the |encoded_image->_buffer| and the |frag_header|
+// is updated to point to each fragment, with offsets and lengths set as to
+// exclude the start codes.
+static void RtpFragmentize(EncodedImage* encoded_image,
+                           std::unique_ptr<uint8_t[]>* encoded_image_buffer,
+                           const VideoFrameBuffer& frame_buffer,
+                           SFrameBSInfo* info,
+                           RTPFragmentationHeader* frag_header) {
+  // Calculate minimum buffer size required to hold encoded data.
+  size_t required_size = 0;
+  size_t fragments_count = 0;
+  for (int layer = 0; layer < info->iLayerNum; ++layer) {
+    const SLayerBSInfo& layerInfo = info->sLayerInfo[layer];
+    for (int nal = 0; nal < layerInfo.iNalCount; ++nal, ++fragments_count) {
+      RTC_CHECK_GE(layerInfo.pNalLengthInByte[nal], 0);
+      // Ensure |required_size| will not overflow.
+      RTC_CHECK_LE(layerInfo.pNalLengthInByte[nal],
+                   std::numeric_limits<size_t>::max() - required_size);
+      required_size += layerInfo.pNalLengthInByte[nal];
+    }
+  }
+  if (encoded_image->_size < required_size) {
+    // Increase buffer size. Allocate enough to hold an unencoded image, this
+    // should be more than enough to hold any encoded data of future frames of
+    // the same size (avoiding possible future reallocation due to variations in
+    // required size).
+    encoded_image->_size =
+        CalcBufferSize(kI420, frame_buffer.width(), frame_buffer.height());
+    if (encoded_image->_size < required_size) {
+      // Encoded data > unencoded data. Allocate required bytes.
+      LOG(LS_WARNING) << "Encoding produced more bytes than the original image "
+                      << "data! Original bytes: " << encoded_image->_size
+                      << ", encoded bytes: " << required_size << ".";
+      encoded_image->_size = required_size;
+    }
+    encoded_image->_buffer = new uint8_t[encoded_image->_size];
+    encoded_image_buffer->reset(encoded_image->_buffer);
+  }
+
+  // Iterate layers and NAL units, note each NAL unit as a fragment and copy
+  // the data to |encoded_image->_buffer|.
+  const uint8_t start_code[4] = {0, 0, 0, 1};
+  frag_header->VerifyAndAllocateFragmentationHeader(fragments_count);
+  size_t frag = 0;
+  encoded_image->_length = 0;
+  for (int layer = 0; layer < info->iLayerNum; ++layer) {
+    const SLayerBSInfo& layerInfo = info->sLayerInfo[layer];
+    // Iterate NAL units making up this layer, noting fragments.
+    size_t layer_len = 0;
+    for (int nal = 0; nal < layerInfo.iNalCount; ++nal, ++frag) {
+      // Because the sum of all layer lengths, |required_size|, fits in a
+      // |size_t|, we know that any indices in-between will not overflow.
+      RTC_DCHECK_GE(layerInfo.pNalLengthInByte[nal], 4);
+      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+0], start_code[0]);
+      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+1], start_code[1]);
+      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+2], start_code[2]);
+      RTC_DCHECK_EQ(layerInfo.pBsBuf[layer_len+3], start_code[3]);
+      frag_header->fragmentationOffset[frag] =
+          encoded_image->_length + layer_len + sizeof(start_code);
+      frag_header->fragmentationLength[frag] =
+          layerInfo.pNalLengthInByte[nal] - sizeof(start_code);
+      layer_len += layerInfo.pNalLengthInByte[nal];
+    }
+    // Copy the entire layer's data (including start codes).
+    memcpy(encoded_image->_buffer + encoded_image->_length,
+           layerInfo.pBsBuf,
+           layer_len);
+    encoded_image->_length += layer_len;
+  }
+}
+
+H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
+    : 
+	 encoder_(nullptr),
+	number_of_cores_(0),
+      width_(0),
+      height_(0),
+      max_frame_rate_(0.0f),
+      target_bps_(0),
+      max_bps_(0),
+      mode_(kRealtimeVideo),
+      frame_dropping_on_(false),
+      key_frame_interval_(0),
+      packetization_mode_(H264PacketizationMode::SingleNalUnit),
+      max_payload_size_(0),
+      encoded_image_callback_(nullptr),
+      has_reported_init_(false),
+      has_reported_error_(false) {
+  RTC_CHECK(cricket::CodecNamesEq(codec.name, cricket::kH264CodecName));
+  std::string packetization_mode_string;
+  if (codec.GetParam(cricket::kH264FmtpPacketizationMode,
+                     &packetization_mode_string) &&
+      packetization_mode_string == "1") {
+    packetization_mode_ = H264PacketizationMode::NonInterleaved;
+  }
+}
+
+H264EncoderImpl::~H264EncoderImpl() {
+  Release();
+}
+
+int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
+                                    int32_t number_of_cores,
+                                    size_t max_payload_size) {
+  ReportInit();
+  if (!codec_settings ||
+      codec_settings->codecType != kVideoCodecH264) {
+    ReportError();
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (codec_settings->maxFramerate == 0) {
+    ReportError();
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+  if (codec_settings->width < 1 || codec_settings->height < 1) {
+    ReportError();
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+  }
+
+  int32_t release_ret = Release();
+  if (release_ret != WEBRTC_VIDEO_CODEC_OK) {
+    ReportError();
+    return release_ret;
+  }
+	RTC_DCHECK(!encoder_);
+
+	//codec_settings
+  // Create encoder.
+  if (WelsCreateSVCEncoder(&encoder_) != 0) {
+    // Failed to create encoder.
+    LOG(LS_ERROR) << "Failed to create OpenH264 encoder";
+	RTC_DCHECK(!encoder_);
+    ReportError();
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  RTC_DCHECK(encoder_);
+  if (kOpenH264EncoderDetailedLogging) {
+    int trace_level = WELS_LOG_DETAIL;
+	encoder_->SetOption(ENCODER_OPTION_TRACE_LEVEL,
+                                 &trace_level);
+  }
+  // else WELS_LOG_DEFAULT is used by default.
+
+  number_of_cores_ = number_of_cores;
+  // Set internal settings from codec_settings
+  width_ = codec_settings->width;
+  height_ = codec_settings->height;
+  max_frame_rate_ = static_cast<float>(codec_settings->maxFramerate);
+  mode_ = codec_settings->mode;
+  frame_dropping_on_ = codec_settings->H264().frameDroppingOn;
+  key_frame_interval_ = codec_settings->H264().keyFrameInterval;
+  max_payload_size_ = max_payload_size;
+
+  // Codec_settings uses kbits/second; encoder uses bits/second.
+  max_bps_ = codec_settings->maxBitrate * 1000;
+  if (codec_settings->targetBitrate == 0)
+    target_bps_ = codec_settings->startBitrate * 1000;
+  else
+    target_bps_ = codec_settings->targetBitrate * 1000;
+
+  SEncParamExt encoder_params = CreateEncoderParams();
+
+  // Initialize.
+  if (encoder_->InitializeExt(&encoder_params) != 0) {
+    LOG(LS_ERROR) << "Failed to initialize OpenH264 encoder";
+    Release();
+    ReportError();
+    return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  // TODO(pbos): Base init params on these values before submitting.
+  int video_format = EVideoFormatType::videoFormatI420;
+  encoder_->SetOption(ENCODER_OPTION_DATAFORMAT,
+                               &video_format);
+
+  // Initialize encoded image. Default buffer size: size of unencoded data.
+  encoded_image_._size =
+      CalcBufferSize(kI420, codec_settings->width, codec_settings->height);
+  encoded_image_._buffer = new uint8_t[encoded_image_._size];
+  encoded_image_buffer_.reset(encoded_image_._buffer);
+  encoded_image_._completeFrame = true;
+  encoded_image_._encodedWidth = 0;
+  encoded_image_._encodedHeight = 0;
+  encoded_image_._length = 0;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int32_t H264EncoderImpl::Release() {
+	if (encoder_) {
+		RTC_CHECK_EQ(0, encoder_->Uninitialize());
+		WelsDestroySVCEncoder(encoder_);
+		encoder_ = nullptr;
+	}
+
+  encoded_image_._buffer = nullptr;
+  encoded_image_buffer_.reset();
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int32_t H264EncoderImpl::RegisterEncodeCompleteCallback(
+    EncodedImageCallback* callback) {
+  encoded_image_callback_ = callback;
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int32_t H264EncoderImpl::SetRateAllocation(
+    const BitrateAllocation& bitrate_allocation,
+    uint32_t framerate) {
+  if (bitrate_allocation.get_sum_bps() <= 0 || framerate <= 0)
+    return WEBRTC_VIDEO_CODEC_ERR_PARAMETER;
+
+  target_bps_ = bitrate_allocation.get_sum_bps();
+  max_frame_rate_ = static_cast<float>(framerate);
+
+  SBitrateInfo target_bitrate;
+  memset(&target_bitrate, 0, sizeof(SBitrateInfo));
+  target_bitrate.iLayer = SPATIAL_LAYER_ALL,
+  target_bitrate.iBitrate = target_bps_;
+  encoder_->SetOption(ENCODER_OPTION_BITRATE,
+                               &target_bitrate);
+  encoder_->SetOption(ENCODER_OPTION_FRAME_RATE, &max_frame_rate_);
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
+	const CodecSpecificInfo* codec_specific_info,
+	const std::vector<FrameType>* frame_types) {
+
+	rtc::scoped_refptr<const VideoFrameBuffer> frame_buffer = input_frame.video_frame_buffer();
+	// Flag if the buffer is already encoded.
+	int encoded_buffer_size = frame_buffer->encoded_length();
+	SFrameBSInfo info;
+
+	if (encoded_buffer_size == 0)
+	{
+		if (!IsInitialized()) {
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+		}
+	}
+
+	if (!encoded_image_callback_) {
+		LOG(LS_WARNING) << "InitEncode() has been called, but a callback function "
+			<< "has not been set with RegisterEncodeCompleteCallback()";
+		ReportError();
+		return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
+	}
+
+	bool force_key_frame = false;
+	if (frame_types != nullptr) {
+		// We only support a single stream.
+		RTC_DCHECK_EQ(frame_types->size(), 1);
+		// Skip frame?
+		if ((*frame_types)[0] == kEmptyFrame) {
+			return WEBRTC_VIDEO_CODEC_OK;
+		}
+		// Force key frame?
+		force_key_frame = (*frame_types)[0] == kVideoFrameKey;
+	}
+	if (force_key_frame) {
+		// API doc says ForceIntraFrame(false) does nothing, but calling this
+		// function forces a key frame regardless of the |bIDR| argument's value.
+		// (If every frame is a key frame we get lag/delays.)
+		if (encoded_buffer_size == 0)
+		{
+			encoder_->ForceIntraFrame(true);
+		}
+	}
+
+	if (encoded_buffer_size == 0)
+	{
+		// EncodeFrame input.
+		SSourcePicture picture;
+		memset(&picture, 0, sizeof(SSourcePicture));
+		picture.iPicWidth = frame_buffer->width();
+		picture.iPicHeight = frame_buffer->height();
+		picture.iColorFormat = EVideoFormatType::videoFormatI420;
+		picture.uiTimeStamp = input_frame.ntp_time_ms();
+		picture.iStride[0] = frame_buffer->StrideY();
+		picture.iStride[1] = frame_buffer->StrideU();
+		picture.iStride[2] = frame_buffer->StrideV();
+		picture.pData[0] = const_cast<uint8_t*>(frame_buffer->DataY());
+		picture.pData[1] = const_cast<uint8_t*>(frame_buffer->DataU());
+		picture.pData[2] = const_cast<uint8_t*>(frame_buffer->DataV());
+
+		// EncodeFrame output.
+		memset(&info, 0, sizeof(SFrameBSInfo));
+
+		// Encode!
+		int enc_ret = encoder_->EncodeFrame(&picture, &info);
+		if (enc_ret != 0) {
+			LOG(LS_ERROR) << "OpenH264 frame encoding failed, EncodeFrame returned "
+				<< enc_ret << ".";
+			ReportError();
+			return WEBRTC_VIDEO_CODEC_ERROR;
+		}
+
+		encoded_image_._frameType = ConvertToVideoFrameType(info.eFrameType);
+	}
+
+	encoded_image_._encodedWidth = frame_buffer->width();
+	encoded_image_._encodedHeight = frame_buffer->height();
+	encoded_image_._timeStamp = input_frame.timestamp();
+	encoded_image_.ntp_time_ms_ = input_frame.ntp_time_ms();
+	encoded_image_.capture_time_ms_ = input_frame.render_time_ms();
+	encoded_image_.rotation_ = input_frame.rotation();
+
+	// Split encoded image up into fragments. This also updates |encoded_image_|.
+	RTPFragmentationHeader frag_header;
+	if (encoded_buffer_size == 0)
+	{
+		RtpFragmentize(&encoded_image_, &encoded_image_buffer_, *frame_buffer, &info,
+			&frag_header);
+	}
+	else
+	{
+		uint8_t * p_nal = const_cast<uint8_t*>(frame_buffer->DataY());
+		size_t i_nal;
+
+		std::vector<H264::NaluIndex> NALUidx;
+
+		if ((p_nal[4] & 0x0F) != 0x07) {
+			NALUidx = H264::FindNaluIndices(p_nal, encoded_buffer_size);
+			if (NALUidx.size() < 1)
+				return WEBRTC_VIDEO_CODEC_OK;
+
+			i_nal = 1;
+			NALUidx[0].payload_size = encoded_buffer_size - NALUidx[0].payload_start_offset;
+		}
+		else {
+			NALUidx = H264::FindNaluIndices(p_nal, 200);
+			i_nal = NALUidx.size();
+			if (i_nal > 2)
+				NALUidx[i_nal - 1].payload_size = encoded_buffer_size - NALUidx[i_nal - 1].payload_start_offset;
+		}
+
+		frag_header.VerifyAndAllocateFragmentationHeader(i_nal);
+		encoded_image_._length = 0;
+
+		uint32_t totalNaluIndex = 0;
+		for (size_t nal_index = 0; nal_index < i_nal; nal_index++)
+		{
+			size_t currentNaluSize = 0;
+			currentNaluSize = NALUidx[nal_index].payload_size; //i_frame_size
+			memcpy(encoded_image_._buffer + encoded_image_._length, &p_nal[NALUidx[nal_index].payload_start_offset], currentNaluSize);
+			encoded_image_._length += currentNaluSize;
+
+			frag_header.fragmentationOffset[totalNaluIndex] = encoded_image_._length - currentNaluSize;
+			frag_header.fragmentationLength[totalNaluIndex] = currentNaluSize;
+			frag_header.fragmentationPlType[totalNaluIndex] = H264::ParseNaluType(p_nal[NALUidx[nal_index].start_offset]);
+			frag_header.fragmentationTimeDiff[totalNaluIndex] = 0;
+			totalNaluIndex++;
+		}
+	}
+
+	// Encoder can skip frames to save bandwidth in which case
+	// |encoded_image_._length| == 0.
+	if (encoded_image_._length > 0) {
+
+		if (encoded_buffer_size == 0)
+		{
+			// Parse QP.
+			h264_bitstream_parser_.ParseBitstream(encoded_image_._buffer,
+				encoded_image_._length);
+			h264_bitstream_parser_.GetLastSliceQp(&encoded_image_.qp_);
+		}
+
+		// Deliver encoded image.
+		CodecSpecificInfo codec_specific;
+		codec_specific.codecType = kVideoCodecH264;
+		codec_specific.codecSpecific.H264.packetization_mode = packetization_mode_;
+		encoded_image_callback_->OnEncodedImage(encoded_image_, &codec_specific,
+			&frag_header);
+	}
+	return WEBRTC_VIDEO_CODEC_OK;
+}
+
+const char* H264EncoderImpl::ImplementationName() const {
+  return "OpenH264";
+}
+
+bool H264EncoderImpl::IsInitialized() const {
+	return encoder_ != nullptr;
+}
+
+// Initialization parameters.
+// There are two ways to initialize. There is SEncParamBase (cleared with
+// memset(&p, 0, sizeof(SEncParamBase)) used in Initialize, and SEncParamExt
+// which is a superset of SEncParamBase (cleared with GetDefaultParams) used
+// in InitializeExt.
+SEncParamExt H264EncoderImpl::CreateEncoderParams() const {
+  RTC_DCHECK(encoder_);
+  SEncParamExt encoder_params;
+  encoder_->GetDefaultParams(&encoder_params);
+  if (mode_ == kRealtimeVideo) {
+    encoder_params.iUsageType = CAMERA_VIDEO_REAL_TIME;
+  } else if (mode_ == kScreensharing) {
+    encoder_params.iUsageType = SCREEN_CONTENT_REAL_TIME;
+  } else {
+    RTC_NOTREACHED();
+  }
+  encoder_params.iPicWidth = width_;
+  encoder_params.iPicHeight = height_;
+  encoder_params.iTargetBitrate = target_bps_;
+  encoder_params.iMaxBitrate = max_bps_;
+  // Rate Control mode
+  encoder_params.iRCMode = RC_BITRATE_MODE;
+  encoder_params.fMaxFrameRate = max_frame_rate_;
+
+  // The following parameters are extension parameters (they're in SEncParamExt,
+  // not in SEncParamBase).
+  encoder_params.bEnableFrameSkip = frame_dropping_on_;
+  // |uiIntraPeriod|    - multiple of GOP size
+  // |keyFrameInterval| - number of frames
+  encoder_params.uiIntraPeriod = key_frame_interval_;
+  encoder_params.uiMaxNalSize = 0;
+  // Threading model: use auto.
+  //  0: auto (dynamic imp. internal encoder)
+  //  1: single thread (default value)
+  // >1: number of threads
+  encoder_params.iMultipleThreadIdc = NumberOfThreads(
+      encoder_params.iPicWidth, encoder_params.iPicHeight, number_of_cores_);
+  // The base spatial layer 0 is the only one we use.
+  encoder_params.sSpatialLayers[0].iVideoWidth = encoder_params.iPicWidth;
+  encoder_params.sSpatialLayers[0].iVideoHeight = encoder_params.iPicHeight;
+  encoder_params.sSpatialLayers[0].fFrameRate = encoder_params.fMaxFrameRate;
+  encoder_params.sSpatialLayers[0].iSpatialBitrate =
+      encoder_params.iTargetBitrate;
+  encoder_params.sSpatialLayers[0].iMaxSpatialBitrate =
+      encoder_params.iMaxBitrate;
+  LOG(INFO) << "OpenH264 version is " << OPENH264_MAJOR << "."
+            << OPENH264_MINOR;
+  switch (packetization_mode_) {
+    case H264PacketizationMode::SingleNalUnit:
+      // Limit the size of the packets produced.
+      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceNum = 1;
+      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceMode =
+          SM_SIZELIMITED_SLICE;
+      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceSizeConstraint =
+          static_cast<unsigned int>(max_payload_size_);
+      break;
+    case H264PacketizationMode::NonInterleaved:
+      // When uiSliceMode = SM_FIXEDSLCNUM_SLICE, uiSliceNum = 0 means auto
+      // design it with cpu core number.
+      // TODO(sprang): Set to 0 when we understand why the rate controller borks
+      //               when uiSliceNum > 1.
+      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceNum = 1;
+      encoder_params.sSpatialLayers[0].sSliceArgument.uiSliceMode =
+          SM_FIXEDSLCNUM_SLICE;
+      break;
+  }
+  return encoder_params;
+}
+
+void H264EncoderImpl::ReportInit() {
+  if (has_reported_init_)
+    return;
+  RTC_HISTOGRAM_ENUMERATION("WebRTC.Video.H264EncoderImpl.Event",
+                            kH264EncoderEventInit,
+                            kH264EncoderEventMax);
+  has_reported_init_ = true;
+}
+
+void H264EncoderImpl::ReportError() {
+  if (has_reported_error_)
+    return;
+  RTC_HISTOGRAM_ENUMERATION("WebRTC.Video.H264EncoderImpl.Event",
+                            kH264EncoderEventError,
+                            kH264EncoderEventMax);
+  has_reported_error_ = true;
+}
+
+int32_t H264EncoderImpl::SetChannelParameters(
+    uint32_t packet_loss, int64_t rtt) {
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+int32_t H264EncoderImpl::SetPeriodicKeyFrames(bool enable) {
+  return WEBRTC_VIDEO_CODEC_OK;
+}
+
+VideoEncoder::ScalingSettings H264EncoderImpl::GetScalingSettings() const {
+  return VideoEncoder::ScalingSettings(true);
+}
+
+}  // namespace webrtc
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
index a455259..f3bc5e6 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
+++ b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
@@ -1,104 +1,128 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- *
- */
-
-#ifndef WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_H264_ENCODER_IMPL_H_
-#define WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_H264_ENCODER_IMPL_H_
-
-#include <memory>
-#include <vector>
-
-#include "webrtc/common_video/h264/h264_bitstream_parser.h"
-#include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
-#include "webrtc/modules/video_coding/utility/quality_scaler.h"
-
-#include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
-
-class ISVCEncoder;
-
-namespace webrtc {
-
-class H264EncoderImpl : public H264Encoder {
- public:
-  explicit H264EncoderImpl(const cricket::VideoCodec& codec);
-  ~H264EncoderImpl() override;
-
-  // |max_payload_size| is ignored.
-  // The following members of |codec_settings| are used. The rest are ignored.
-  // - codecType (must be kVideoCodecH264)
-  // - targetBitrate
-  // - maxFramerate
-  // - width
-  // - height
-  int32_t InitEncode(const VideoCodec* codec_settings,
-                     int32_t number_of_cores,
-                     size_t max_payload_size) override;
-  int32_t Release() override;
-
-  int32_t RegisterEncodeCompleteCallback(
-      EncodedImageCallback* callback) override;
-  int32_t SetRateAllocation(const BitrateAllocation& bitrate_allocation,
-                            uint32_t framerate) override;
-
-  // The result of encoding - an EncodedImage and RTPFragmentationHeader - are
-  // passed to the encode complete callback.
-  int32_t Encode(const VideoFrame& frame,
-                 const CodecSpecificInfo* codec_specific_info,
-                 const std::vector<FrameType>* frame_types) override;
-
-  const char* ImplementationName() const override;
-
-  VideoEncoder::ScalingSettings GetScalingSettings() const override;
-
-  // Unsupported / Do nothing.
-  int32_t SetChannelParameters(uint32_t packet_loss, int64_t rtt) override;
-  int32_t SetPeriodicKeyFrames(bool enable) override;
-
-  // Exposed for testing.
-  H264PacketizationMode PacketizationModeForTesting() const {
-    return packetization_mode_;
-  }
-
- private:
-  bool IsInitialized() const;
-  SEncParamExt CreateEncoderParams() const;
-
-  webrtc::H264BitstreamParser h264_bitstream_parser_;
-  // Reports statistics with histograms.
-  void ReportInit();
-  void ReportError();
-
-  ISVCEncoder* openh264_encoder_;
-  // Settings that are used by this encoder.
-  int width_;
-  int height_;
-  float max_frame_rate_;
-  uint32_t target_bps_;
-  uint32_t max_bps_;
-  VideoCodecMode mode_;
-  // H.264 specifc parameters
-  bool frame_dropping_on_;
-  int key_frame_interval_;
-  H264PacketizationMode packetization_mode_;
-
-  size_t max_payload_size_;
-  int32_t number_of_cores_;
-
-  EncodedImage encoded_image_;
-  std::unique_ptr<uint8_t[]> encoded_image_buffer_;
-  EncodedImageCallback* encoded_image_callback_;
-
-  bool has_reported_init_;
-  bool has_reported_error_;
-};
-
-}  // namespace webrtc
-
-#endif  // WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_H264_ENCODER_IMPL_H_
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ *
+ */
+
+#ifndef WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_H264_ENCODER_IMPL_H_
+#define WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_H264_ENCODER_IMPL_H_
+
+#include <memory>
+#include <vector>
+
+#include "webrtc/common_video/h264/h264_bitstream_parser.h"
+#include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
+#include "webrtc/modules/video_coding/utility/quality_scaler.h"
+
+//#define USEOPENH264 1
+//#define USEX264 1
+
+// #include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
+
+#include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
+class ISVCEncoder;
+#if USEX264
+//#define __STDC_CONSTANT_MACROS
+//x264 and ffmpeg headers
+extern "C"
+ {
+	+#include "third_party/x264/x264.h"
+		+ #include "third_party/ffmpeg/libavcodec/avcodec.h"
+		+ #include "third_party/ffmpeg/libavformat/avformat.h"
+		+ #include "third_party/ffmpeg/libswscale/swscale.h"
+		+ }
+#endif
+
+namespace webrtc {
+
+class H264EncoderImpl : public H264Encoder {
+ public:
+  explicit H264EncoderImpl(const cricket::VideoCodec& codec);
+  ~H264EncoderImpl() override;
+
+  // |max_payload_size| is ignored.
+  // The following members of |codec_settings| are used. The rest are ignored.
+  // - codecType (must be kVideoCodecH264)
+  // - targetBitrate
+  // - maxFramerate
+  // - width
+  // - height
+  int32_t InitEncode(const VideoCodec* codec_settings,
+                     int32_t number_of_cores,
+                     size_t max_payload_size) override;
+  int32_t Release() override;
+
+  int32_t RegisterEncodeCompleteCallback(
+      EncodedImageCallback* callback) override;
+  int32_t SetRateAllocation(const BitrateAllocation& bitrate_allocation,
+                            uint32_t framerate) override;
+
+  // The result of encoding - an EncodedImage and RTPFragmentationHeader - are
+  // passed to the encode complete callback.
+  int32_t Encode(const VideoFrame& frame,
+                 const CodecSpecificInfo* codec_specific_info,
+                 const std::vector<FrameType>* frame_types) override;
+
+  const char* ImplementationName() const override;
+
+  VideoEncoder::ScalingSettings GetScalingSettings() const override;
+
+  // Unsupported / Do nothing.
+  int32_t SetChannelParameters(uint32_t packet_loss, int64_t rtt) override;
+  int32_t SetPeriodicKeyFrames(bool enable) override;
+
+  // Exposed for testing.
+  H264PacketizationMode PacketizationModeForTesting() const {
+    return packetization_mode_;
+  }
+
+ private:
+  bool IsInitialized() const;
+  SEncParamExt CreateEncoderParams() const;
+
+  webrtc::H264BitstreamParser h264_bitstream_parser_;
+  // Reports statistics with histograms.
+  void ReportInit();
+  void ReportError();
+
+
+  ISVCEncoder* encoder_;
+#if USEX264
+  //x264
+  x264_picture_t pic;
+  x264_picture_t pic_out;
+  x264_t *encoder_;
+  int i_frame = 0;
+  x264_nal_t *nal;
+#endif
+  // Settings that are used by this encoder.
+  int width_;
+  int height_;
+  float max_frame_rate_;
+  uint32_t target_bps_;
+  uint32_t max_bps_;
+  VideoCodecMode mode_;
+  // H.264 specifc parameters
+  bool frame_dropping_on_;
+  int key_frame_interval_;
+  H264PacketizationMode packetization_mode_;
+
+  size_t max_payload_size_;
+  int32_t number_of_cores_;
+
+  EncodedImage encoded_image_;
+  std::unique_ptr<uint8_t[]> encoded_image_buffer_;
+  EncodedImageCallback* encoded_image_callback_;
+
+  bool has_reported_init_;
+  bool has_reported_error_;
+};
+
+}  // namespace webrtc
+
+#endif  // WEBRTC_MODULES_VIDEO_CODING_CODECS_H264_H264_ENCODER_IMPL_H_
diff --git a/webrtc/modules/video_coding/video_sender.cc b/webrtc/modules/video_coding/video_sender.cc
index 0b54d13..d87b9cb 100644
--- a/webrtc/modules/video_coding/video_sender.cc
+++ b/webrtc/modules/video_coding/video_sender.cc
@@ -1,402 +1,404 @@
-/*
- *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-
-
-#include <algorithm>  // std::max
-
-#include "webrtc/base/checks.h"
-#include "webrtc/base/logging.h"
-#include "webrtc/common_types.h"
-#include "webrtc/common_video/include/video_bitrate_allocator.h"
-#include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
-#include "webrtc/modules/video_coding/codecs/vp8/temporal_layers.h"
-#include "webrtc/modules/video_coding/include/video_codec_interface.h"
-#include "webrtc/modules/video_coding/encoded_frame.h"
-#include "webrtc/modules/video_coding/utility/default_video_bitrate_allocator.h"
-#include "webrtc/modules/video_coding/utility/quality_scaler.h"
-#include "webrtc/modules/video_coding/video_coding_impl.h"
-#include "webrtc/system_wrappers/include/clock.h"
-
-namespace webrtc {
-namespace vcm {
-
-VideoSender::VideoSender(Clock* clock,
-                         EncodedImageCallback* post_encode_callback,
-                         VCMSendStatisticsCallback* send_stats_callback)
-    : clock_(clock),
-      _encoder(nullptr),
-      _mediaOpt(clock_),
-      _encodedFrameCallback(post_encode_callback, &_mediaOpt),
-      post_encode_callback_(post_encode_callback),
-      send_stats_callback_(send_stats_callback),
-      _codecDataBase(&_encodedFrameCallback),
-      frame_dropper_enabled_(true),
-      _sendStatsTimer(VCMProcessTimer::kDefaultProcessIntervalMs, clock_),
-      current_codec_(),
-      encoder_params_({BitrateAllocation(), 0, 0, 0}),
-      encoder_has_internal_source_(false),
-      next_frame_types_(1, kVideoFrameDelta) {
-  _mediaOpt.Reset();
-  // Allow VideoSender to be created on one thread but used on another, post
-  // construction. This is currently how this class is being used by at least
-  // one external project (diffractor).
-  sequenced_checker_.Detach();
-}
-
-VideoSender::~VideoSender() {}
-
-void VideoSender::Process() {
-  if (_sendStatsTimer.TimeUntilProcess() == 0) {
-    // |_sendStatsTimer.Processed()| must be called. Otherwise
-    // VideoSender::Process() will be called in an infinite loop.
-    _sendStatsTimer.Processed();
-    if (send_stats_callback_) {
-      uint32_t bitRate = _mediaOpt.SentBitRate();
-      uint32_t frameRate = _mediaOpt.SentFrameRate();
-      send_stats_callback_->SendStatistics(bitRate, frameRate);
-    }
-  }
-}
-
-int64_t VideoSender::TimeUntilNextProcess() {
-  return _sendStatsTimer.TimeUntilProcess();
-}
-
-// Register the send codec to be used.
-int32_t VideoSender::RegisterSendCodec(const VideoCodec* sendCodec,
-                                       uint32_t numberOfCores,
-                                       uint32_t maxPayloadSize) {
-  RTC_DCHECK(sequenced_checker_.CalledSequentially());
-  rtc::CritScope lock(&encoder_crit_);
-  if (sendCodec == nullptr) {
-    return VCM_PARAMETER_ERROR;
-  }
-
-  bool ret =
-      _codecDataBase.SetSendCodec(sendCodec, numberOfCores, maxPayloadSize);
-
-  // Update encoder regardless of result to make sure that we're not holding on
-  // to a deleted instance.
-  _encoder = _codecDataBase.GetEncoder();
-  // Cache the current codec here so they can be fetched from this thread
-  // without requiring the _sendCritSect lock.
-  current_codec_ = *sendCodec;
-
-  if (!ret) {
-    LOG(LS_ERROR) << "Failed to initialize set encoder with payload name '"
-                  << sendCodec->plName << "'.";
-    return VCM_CODEC_ERROR;
-  }
-
-  // SetSendCodec succeeded, _encoder should be set.
-  RTC_DCHECK(_encoder);
-
-  int numLayers;
-  if (sendCodec->codecType == kVideoCodecVP8) {
-    numLayers = sendCodec->VP8().numberOfTemporalLayers;
-  } else if (sendCodec->codecType == kVideoCodecVP9) {
-    numLayers = sendCodec->VP9().numberOfTemporalLayers;
-  } else {
-    numLayers = 1;
-  }
-
-  // If we have screensharing and we have layers, we disable frame dropper.
-  bool disable_frame_dropper =
-      numLayers > 1 && sendCodec->mode == kScreensharing;
-  if (disable_frame_dropper) {
-    _mediaOpt.EnableFrameDropper(false);
-  } else if (frame_dropper_enabled_) {
-    _mediaOpt.EnableFrameDropper(true);
-  }
-
-  {
-    rtc::CritScope cs(&params_crit_);
-    next_frame_types_.clear();
-    next_frame_types_.resize(VCM_MAX(sendCodec->numberOfSimulcastStreams, 1),
-                             kVideoFrameKey);
-    // Cache InternalSource() to have this available from IntraFrameRequest()
-    // without having to acquire encoder_crit_ (avoid blocking on encoder use).
-    encoder_has_internal_source_ = _encoder->InternalSource();
-  }
-
-  LOG(LS_VERBOSE) << " max bitrate " << sendCodec->maxBitrate
-                  << " start bitrate " << sendCodec->startBitrate
-                  << " max frame rate " << sendCodec->maxFramerate
-                  << " max payload size " << maxPayloadSize;
-  _mediaOpt.SetEncodingData(sendCodec->maxBitrate * 1000,
-                            sendCodec->startBitrate * 1000, sendCodec->width,
-                            sendCodec->height, sendCodec->maxFramerate,
-                            numLayers, maxPayloadSize);
-  return VCM_OK;
-}
-
-// Register an external decoder object.
-// This can not be used together with external decoder callbacks.
-void VideoSender::RegisterExternalEncoder(VideoEncoder* externalEncoder,
-                                          uint8_t payloadType,
-                                          bool internalSource /*= false*/) {
-  RTC_DCHECK(sequenced_checker_.CalledSequentially());
-
-  rtc::CritScope lock(&encoder_crit_);
-
-  if (externalEncoder == nullptr) {
-    bool wasSendCodec = false;
-    RTC_CHECK(
-        _codecDataBase.DeregisterExternalEncoder(payloadType, &wasSendCodec));
-    if (wasSendCodec) {
-      // Make sure the VCM doesn't use the de-registered codec
-      rtc::CritScope params_lock(&params_crit_);
-      _encoder = nullptr;
-      encoder_has_internal_source_ = false;
-    }
-    return;
-  }
-  _codecDataBase.RegisterExternalEncoder(externalEncoder, payloadType,
-                                         internalSource);
-}
-
-// Get encode bitrate
-int VideoSender::Bitrate(unsigned int* bitrate) const {
-  RTC_DCHECK(sequenced_checker_.CalledSequentially());
-  // Since we're running on the thread that's the only thread known to modify
-  // the value of _encoder, we don't need to grab the lock here.
-
-  if (!_encoder)
-    return VCM_UNINITIALIZED;
-  *bitrate = _encoder->GetEncoderParameters().target_bitrate.get_sum_bps();
-  return 0;
-}
-
-// Get encode frame rate
-int VideoSender::FrameRate(unsigned int* framerate) const {
-  RTC_DCHECK(sequenced_checker_.CalledSequentially());
-  // Since we're running on the thread that's the only thread known to modify
-  // the value of _encoder, we don't need to grab the lock here.
-
-  if (!_encoder)
-    return VCM_UNINITIALIZED;
-
-  *framerate = _encoder->GetEncoderParameters().input_frame_rate;
-  return 0;
-}
-
-EncoderParameters VideoSender::UpdateEncoderParameters(
-    const EncoderParameters& params,
-    VideoBitrateAllocator* bitrate_allocator,
-    uint32_t target_bitrate_bps) {
-  uint32_t video_target_rate_bps = _mediaOpt.SetTargetRates(target_bitrate_bps);
-  uint32_t input_frame_rate = _mediaOpt.InputFrameRate();
-  if (input_frame_rate == 0)
-    input_frame_rate = current_codec_.maxFramerate;
-
-  BitrateAllocation bitrate_allocation;
-  if (bitrate_allocator) {
-    bitrate_allocation = bitrate_allocator->GetAllocation(video_target_rate_bps,
-                                                          input_frame_rate);
-  } else {
-    DefaultVideoBitrateAllocator default_allocator(current_codec_);
-    bitrate_allocation = default_allocator.GetAllocation(video_target_rate_bps,
-                                                         input_frame_rate);
-  }
-  EncoderParameters new_encoder_params = {bitrate_allocation, params.loss_rate,
-                                          params.rtt, input_frame_rate};
-  return new_encoder_params;
-}
-
-void VideoSender::UpdateChannelParemeters(
-    VideoBitrateAllocator* bitrate_allocator,
-    VideoBitrateAllocationObserver* bitrate_updated_callback) {
-  BitrateAllocation target_rate;
-  {
-    rtc::CritScope cs(&params_crit_);
-    encoder_params_ =
-        UpdateEncoderParameters(encoder_params_, bitrate_allocator,
-                                encoder_params_.target_bitrate.get_sum_bps());
-    target_rate = encoder_params_.target_bitrate;
-  }
-  if (bitrate_updated_callback)
-    bitrate_updated_callback->OnBitrateAllocationUpdated(target_rate);
-}
-
-int32_t VideoSender::SetChannelParameters(
-    uint32_t target_bitrate_bps,
-    uint8_t loss_rate,
-    int64_t rtt,
-    VideoBitrateAllocator* bitrate_allocator,
-    VideoBitrateAllocationObserver* bitrate_updated_callback) {
-  EncoderParameters encoder_params;
-  encoder_params.loss_rate = loss_rate;
-  encoder_params.rtt = rtt;
-  encoder_params = UpdateEncoderParameters(encoder_params, bitrate_allocator,
-                                           target_bitrate_bps);
-  if (bitrate_updated_callback) {
-    bitrate_updated_callback->OnBitrateAllocationUpdated(
-        encoder_params.target_bitrate);
-  }
-
-  bool encoder_has_internal_source;
-  {
-    rtc::CritScope cs(&params_crit_);
-    encoder_params_ = encoder_params;
-    encoder_has_internal_source = encoder_has_internal_source_;
-  }
-
-  // For encoders with internal sources, we need to tell the encoder directly,
-  // instead of waiting for an AddVideoFrame that will never come (internal
-  // source encoders don't get input frames).
-  if (encoder_has_internal_source) {
-    rtc::CritScope cs(&encoder_crit_);
-    if (_encoder) {
-      SetEncoderParameters(encoder_params, encoder_has_internal_source);
-    }
-  }
-
-  return VCM_OK;
-}
-
-void VideoSender::SetEncoderParameters(EncoderParameters params,
-                                       bool has_internal_source) {
-  // |target_bitrate == 0 | means that the network is down or the send pacer is
-  // full. We currently only report this if the encoder has an internal source.
-  // If the encoder does not have an internal source, higher levels are expected
-  // to not call AddVideoFrame. We do this since its unclear how current
-  // encoder implementations behave when given a zero target bitrate.
-  // TODO(perkj): Make sure all known encoder implementations handle zero
-  // target bitrate and remove this check.
-  if (!has_internal_source && params.target_bitrate.get_sum_bps() == 0)
-    return;
-
-  if (params.input_frame_rate == 0) {
-    // No frame rate estimate available, use default.
-    params.input_frame_rate = current_codec_.maxFramerate;
-  }
-  if (_encoder != nullptr)
-    _encoder->SetEncoderParameters(params);
-}
-
-// Deprecated:
-// TODO(perkj): Remove once no projects call this method. It currently do
-// nothing.
-int32_t VideoSender::RegisterProtectionCallback(
-    VCMProtectionCallback* protection_callback) {
-  // Deprecated:
-  // TODO(perkj): Remove once no projects call this method. It currently do
-  // nothing.
-  return VCM_OK;
-}
-
-// Add one raw video frame to the encoder, blocking.
-int32_t VideoSender::AddVideoFrame(const VideoFrame& videoFrame,
-                                   const CodecSpecificInfo* codecSpecificInfo) {
-  EncoderParameters encoder_params;
-  std::vector<FrameType> next_frame_types;
-  bool encoder_has_internal_source = false;
-  {
-    rtc::CritScope lock(&params_crit_);
-    encoder_params = encoder_params_;
-    next_frame_types = next_frame_types_;
-    encoder_has_internal_source = encoder_has_internal_source_;
-  }
-  rtc::CritScope lock(&encoder_crit_);
-  if (_encoder == nullptr)
-    return VCM_UNINITIALIZED;
-  SetEncoderParameters(encoder_params, encoder_has_internal_source);
-  if (_mediaOpt.DropFrame()) {
-    LOG(LS_VERBOSE) << "Drop Frame "
-                    << "target bitrate "
-                    << encoder_params.target_bitrate.get_sum_bps()
-                    << " loss rate " << encoder_params.loss_rate << " rtt "
-                    << encoder_params.rtt << " input frame rate "
-                    << encoder_params.input_frame_rate;
-    post_encode_callback_->OnDroppedFrame();
-    return VCM_OK;
-  }
-  // TODO(pbos): Make sure setting send codec is synchronized with video
-  // processing so frame size always matches.
-  if (!_codecDataBase.MatchesCurrentResolution(videoFrame.width(),
-                                               videoFrame.height())) {
-    LOG(LS_ERROR) << "Incoming frame doesn't match set resolution. Dropping.";
-    return VCM_PARAMETER_ERROR;
-  }
-  VideoFrame converted_frame = videoFrame;
-  if (converted_frame.video_frame_buffer()->native_handle() &&
-      !_encoder->SupportsNativeHandle()) {
-    // This module only supports software encoding.
-    // TODO(pbos): Offload conversion from the encoder thread.
-    rtc::scoped_refptr<VideoFrameBuffer> converted_buffer(
-        converted_frame.video_frame_buffer()->NativeToI420Buffer());
-
-    if (!converted_buffer) {
-      LOG(LS_ERROR) << "Frame conversion failed, dropping frame.";
-      return VCM_PARAMETER_ERROR;
-    }
-    converted_frame = VideoFrame(converted_buffer,
-                                 converted_frame.timestamp(),
-                                 converted_frame.render_time_ms(),
-                                 converted_frame.rotation());
-  }
-  int32_t ret =
-      _encoder->Encode(converted_frame, codecSpecificInfo, next_frame_types);
-  if (ret < 0) {
-    LOG(LS_ERROR) << "Failed to encode frame. Error code: " << ret;
-    return ret;
-  }
-
-  {
-    rtc::CritScope lock(&params_crit_);
-    // Change all keyframe requests to encode delta frames the next time.
-    for (size_t i = 0; i < next_frame_types_.size(); ++i) {
-      // Check for equality (same requested as before encoding) to not
-      // accidentally drop a keyframe request while encoding.
-      if (next_frame_types[i] == next_frame_types_[i])
-        next_frame_types_[i] = kVideoFrameDelta;
-    }
-  }
-  return VCM_OK;
-}
-
-int32_t VideoSender::IntraFrameRequest(size_t stream_index) {
-  {
-    rtc::CritScope lock(&params_crit_);
-    if (stream_index >= next_frame_types_.size()) {
-      return -1;
-    }
-    next_frame_types_[stream_index] = kVideoFrameKey;
-    if (!encoder_has_internal_source_)
-      return VCM_OK;
-  }
-  // TODO(pbos): Remove when InternalSource() is gone. Both locks have to be
-  // held here for internal consistency, since _encoder could be removed while
-  // not holding encoder_crit_. Checks have to be performed again since
-  // params_crit_ was dropped to not cause lock-order inversions with
-  // encoder_crit_.
-  rtc::CritScope lock(&encoder_crit_);
-  rtc::CritScope params_lock(&params_crit_);
-  if (stream_index >= next_frame_types_.size())
-    return -1;
-  if (_encoder != nullptr && _encoder->InternalSource()) {
-    // Try to request the frame if we have an external encoder with
-    // internal source since AddVideoFrame never will be called.
-    if (_encoder->RequestFrame(next_frame_types_) == WEBRTC_VIDEO_CODEC_OK) {
-      // Try to remove just-performed keyframe request, if stream still exists.
-      next_frame_types_[stream_index] = kVideoFrameDelta;
-    }
-  }
-  return VCM_OK;
-}
-
-int32_t VideoSender::EnableFrameDropper(bool enable) {
-  rtc::CritScope lock(&encoder_crit_);
-  frame_dropper_enabled_ = enable;
-  _mediaOpt.EnableFrameDropper(enable);
-  return VCM_OK;
-}
-}  // namespace vcm
-}  // namespace webrtc
+/*
+ *  Copyright (c) 2013 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+
+#include <algorithm>  // std::max
+
+#include "webrtc/base/checks.h"
+#include "webrtc/base/logging.h"
+#include "webrtc/common_types.h"
+#include "webrtc/common_video/include/video_bitrate_allocator.h"
+#include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
+#include "webrtc/modules/video_coding/codecs/vp8/temporal_layers.h"
+#include "webrtc/modules/video_coding/include/video_codec_interface.h"
+#include "webrtc/modules/video_coding/encoded_frame.h"
+#include "webrtc/modules/video_coding/utility/default_video_bitrate_allocator.h"
+#include "webrtc/modules/video_coding/utility/quality_scaler.h"
+#include "webrtc/modules/video_coding/video_coding_impl.h"
+#include "webrtc/system_wrappers/include/clock.h"
+
+namespace webrtc {
+namespace vcm {
+
+VideoSender::VideoSender(Clock* clock,
+                         EncodedImageCallback* post_encode_callback,
+                         VCMSendStatisticsCallback* send_stats_callback)
+    : clock_(clock),
+      _encoder(nullptr),
+      _mediaOpt(clock_),
+      _encodedFrameCallback(post_encode_callback, &_mediaOpt),
+      post_encode_callback_(post_encode_callback),
+      send_stats_callback_(send_stats_callback),
+      _codecDataBase(&_encodedFrameCallback),
+      frame_dropper_enabled_(true),
+      _sendStatsTimer(VCMProcessTimer::kDefaultProcessIntervalMs, clock_),
+      current_codec_(),
+      encoder_params_({BitrateAllocation(), 0, 0, 0}),
+      encoder_has_internal_source_(false),
+      next_frame_types_(1, kVideoFrameDelta) {
+  _mediaOpt.Reset();
+  // Allow VideoSender to be created on one thread but used on another, post
+  // construction. This is currently how this class is being used by at least
+  // one external project (diffractor).
+  sequenced_checker_.Detach();
+}
+
+VideoSender::~VideoSender() {}
+
+void VideoSender::Process() {
+  if (_sendStatsTimer.TimeUntilProcess() == 0) {
+    // |_sendStatsTimer.Processed()| must be called. Otherwise
+    // VideoSender::Process() will be called in an infinite loop.
+    _sendStatsTimer.Processed();
+    if (send_stats_callback_) {
+      uint32_t bitRate = _mediaOpt.SentBitRate();
+      uint32_t frameRate = _mediaOpt.SentFrameRate();
+      send_stats_callback_->SendStatistics(bitRate, frameRate);
+    }
+  }
+}
+
+int64_t VideoSender::TimeUntilNextProcess() {
+  return _sendStatsTimer.TimeUntilProcess();
+}
+
+// Register the send codec to be used.
+int32_t VideoSender::RegisterSendCodec(const VideoCodec* sendCodec,
+                                       uint32_t numberOfCores,
+                                       uint32_t maxPayloadSize) {
+  RTC_DCHECK(sequenced_checker_.CalledSequentially());
+  rtc::CritScope lock(&encoder_crit_);
+  if (sendCodec == nullptr) {
+    return VCM_PARAMETER_ERROR;
+  }
+
+  bool ret =
+      _codecDataBase.SetSendCodec(sendCodec, numberOfCores, maxPayloadSize);
+
+  // Update encoder regardless of result to make sure that we're not holding on
+  // to a deleted instance.
+  _encoder = _codecDataBase.GetEncoder();
+  // Cache the current codec here so they can be fetched from this thread
+  // without requiring the _sendCritSect lock.
+  current_codec_ = *sendCodec;
+
+  if (!ret) {
+    LOG(LS_ERROR) << "Failed to initialize set encoder with payload name '"
+                  << sendCodec->plName << "'.";
+    return VCM_CODEC_ERROR;
+  }
+
+  // SetSendCodec succeeded, _encoder should be set.
+  RTC_DCHECK(_encoder);
+
+  int numLayers;
+  if (sendCodec->codecType == kVideoCodecVP8) {
+    numLayers = sendCodec->VP8().numberOfTemporalLayers;
+  } else if (sendCodec->codecType == kVideoCodecVP9) {
+    numLayers = sendCodec->VP9().numberOfTemporalLayers;
+  } else {
+    numLayers = 1;
+  }
+
+  // If we have screensharing and we have layers, we disable frame dropper.
+  bool disable_frame_dropper =
+      numLayers > 1 && sendCodec->mode == kScreensharing;
+  if (disable_frame_dropper) {
+    _mediaOpt.EnableFrameDropper(false);
+  } else if (frame_dropper_enabled_) {
+    _mediaOpt.EnableFrameDropper(true);
+  }
+
+  {
+    rtc::CritScope cs(&params_crit_);
+    next_frame_types_.clear();
+    next_frame_types_.resize(VCM_MAX(sendCodec->numberOfSimulcastStreams, 1),
+                             kVideoFrameKey);
+    // Cache InternalSource() to have this available from IntraFrameRequest()
+    // without having to acquire encoder_crit_ (avoid blocking on encoder use).
+    encoder_has_internal_source_ = _encoder->InternalSource();
+  }
+
+  LOG(LS_VERBOSE) << " max bitrate " << sendCodec->maxBitrate
+                  << " start bitrate " << sendCodec->startBitrate
+                  << " max frame rate " << sendCodec->maxFramerate
+                  << " max payload size " << maxPayloadSize;
+  _mediaOpt.SetEncodingData(sendCodec->maxBitrate * 1000,
+                            sendCodec->startBitrate * 1000, sendCodec->width,
+                            sendCodec->height, sendCodec->maxFramerate,
+                            numLayers, maxPayloadSize);
+  return VCM_OK;
+}
+
+// Register an external decoder object.
+// This can not be used together with external decoder callbacks.
+void VideoSender::RegisterExternalEncoder(VideoEncoder* externalEncoder,
+                                          uint8_t payloadType,
+                                          bool internalSource /*= false*/) {
+  RTC_DCHECK(sequenced_checker_.CalledSequentially());
+
+  rtc::CritScope lock(&encoder_crit_);
+
+  if (externalEncoder == nullptr) {
+    bool wasSendCodec = false;
+    RTC_CHECK(
+        _codecDataBase.DeregisterExternalEncoder(payloadType, &wasSendCodec));
+    if (wasSendCodec) {
+      // Make sure the VCM doesn't use the de-registered codec
+      rtc::CritScope params_lock(&params_crit_);
+      _encoder = nullptr;
+      encoder_has_internal_source_ = false;
+    }
+    return;
+  }
+  _codecDataBase.RegisterExternalEncoder(externalEncoder, payloadType,
+                                         internalSource);
+}
+
+// Get encode bitrate
+int VideoSender::Bitrate(unsigned int* bitrate) const {
+  RTC_DCHECK(sequenced_checker_.CalledSequentially());
+  // Since we're running on the thread that's the only thread known to modify
+  // the value of _encoder, we don't need to grab the lock here.
+
+  if (!_encoder)
+    return VCM_UNINITIALIZED;
+  *bitrate = _encoder->GetEncoderParameters().target_bitrate.get_sum_bps();
+  return 0;
+}
+
+// Get encode frame rate
+int VideoSender::FrameRate(unsigned int* framerate) const {
+  RTC_DCHECK(sequenced_checker_.CalledSequentially());
+  // Since we're running on the thread that's the only thread known to modify
+  // the value of _encoder, we don't need to grab the lock here.
+
+  if (!_encoder)
+    return VCM_UNINITIALIZED;
+
+  *framerate = _encoder->GetEncoderParameters().input_frame_rate;
+  return 0;
+}
+
+EncoderParameters VideoSender::UpdateEncoderParameters(
+    const EncoderParameters& params,
+    VideoBitrateAllocator* bitrate_allocator,
+    uint32_t target_bitrate_bps) {
+  uint32_t video_target_rate_bps = _mediaOpt.SetTargetRates(target_bitrate_bps);
+  uint32_t input_frame_rate = _mediaOpt.InputFrameRate();
+  if (input_frame_rate == 0)
+    input_frame_rate = current_codec_.maxFramerate;
+
+  BitrateAllocation bitrate_allocation;
+  if (bitrate_allocator) {
+    bitrate_allocation = bitrate_allocator->GetAllocation(video_target_rate_bps,
+                                                          input_frame_rate);
+  } else {
+    DefaultVideoBitrateAllocator default_allocator(current_codec_);
+    bitrate_allocation = default_allocator.GetAllocation(video_target_rate_bps,
+                                                         input_frame_rate);
+  }
+  EncoderParameters new_encoder_params = {bitrate_allocation, params.loss_rate,
+                                          params.rtt, input_frame_rate};
+  return new_encoder_params;
+}
+
+void VideoSender::UpdateChannelParemeters(
+    VideoBitrateAllocator* bitrate_allocator,
+    VideoBitrateAllocationObserver* bitrate_updated_callback) {
+  BitrateAllocation target_rate;
+  {
+    rtc::CritScope cs(&params_crit_);
+    encoder_params_ =
+        UpdateEncoderParameters(encoder_params_, bitrate_allocator,
+                                encoder_params_.target_bitrate.get_sum_bps());
+    target_rate = encoder_params_.target_bitrate;
+  }
+  if (bitrate_updated_callback)
+    bitrate_updated_callback->OnBitrateAllocationUpdated(target_rate);
+}
+
+int32_t VideoSender::SetChannelParameters(
+    uint32_t target_bitrate_bps,
+    uint8_t loss_rate,
+    int64_t rtt,
+    VideoBitrateAllocator* bitrate_allocator,
+    VideoBitrateAllocationObserver* bitrate_updated_callback) {
+  EncoderParameters encoder_params;
+  encoder_params.loss_rate = loss_rate;
+  encoder_params.rtt = rtt;
+  encoder_params = UpdateEncoderParameters(encoder_params, bitrate_allocator,
+                                           target_bitrate_bps);
+  if (bitrate_updated_callback) {
+    bitrate_updated_callback->OnBitrateAllocationUpdated(
+        encoder_params.target_bitrate);
+  }
+
+  bool encoder_has_internal_source;
+  {
+    rtc::CritScope cs(&params_crit_);
+    encoder_params_ = encoder_params;
+    encoder_has_internal_source = encoder_has_internal_source_;
+  }
+
+  // For encoders with internal sources, we need to tell the encoder directly,
+  // instead of waiting for an AddVideoFrame that will never come (internal
+  // source encoders don't get input frames).
+  if (encoder_has_internal_source) {
+    rtc::CritScope cs(&encoder_crit_);
+    if (_encoder) {
+      SetEncoderParameters(encoder_params, encoder_has_internal_source);
+    }
+  }
+
+  return VCM_OK;
+}
+
+void VideoSender::SetEncoderParameters(EncoderParameters params,
+                                       bool has_internal_source) {
+  // |target_bitrate == 0 | means that the network is down or the send pacer is
+  // full. We currently only report this if the encoder has an internal source.
+  // If the encoder does not have an internal source, higher levels are expected
+  // to not call AddVideoFrame. We do this since its unclear how current
+  // encoder implementations behave when given a zero target bitrate.
+  // TODO(perkj): Make sure all known encoder implementations handle zero
+  // target bitrate and remove this check.
+  if (!has_internal_source && params.target_bitrate.get_sum_bps() == 0)
+    return;
+
+  if (params.input_frame_rate == 0) {
+    // No frame rate estimate available, use default.
+    params.input_frame_rate = current_codec_.maxFramerate;
+  }
+  if (_encoder != nullptr)
+    _encoder->SetEncoderParameters(params);
+}
+
+// Deprecated:
+// TODO(perkj): Remove once no projects call this method. It currently do
+// nothing.
+int32_t VideoSender::RegisterProtectionCallback(
+    VCMProtectionCallback* protection_callback) {
+  // Deprecated:
+  // TODO(perkj): Remove once no projects call this method. It currently do
+  // nothing.
+  return VCM_OK;
+}
+
+// Add one raw video frame to the encoder, blocking.
+int32_t VideoSender::AddVideoFrame(const VideoFrame& videoFrame,
+                                   const CodecSpecificInfo* codecSpecificInfo) {
+  EncoderParameters encoder_params;
+  std::vector<FrameType> next_frame_types;
+  bool encoder_has_internal_source = false;
+  {
+    rtc::CritScope lock(&params_crit_);
+    encoder_params = encoder_params_;
+    next_frame_types = next_frame_types_;
+    encoder_has_internal_source = encoder_has_internal_source_;
+  }
+  rtc::CritScope lock(&encoder_crit_);
+  if (_encoder == nullptr)
+    return VCM_UNINITIALIZED;
+  SetEncoderParameters(encoder_params, encoder_has_internal_source);
+#if 0
+  if (_mediaOpt.DropFrame()) {
+    LOG(LS_VERBOSE) << "Drop Frame "
+                    << "target bitrate "
+                    << encoder_params.target_bitrate.get_sum_bps()
+                    << " loss rate " << encoder_params.loss_rate << " rtt "
+                    << encoder_params.rtt << " input frame rate "
+                    << encoder_params.input_frame_rate;
+    post_encode_callback_->OnDroppedFrame();
+    return VCM_OK;
+  }
+#endif
+  // TODO(pbos): Make sure setting send codec is synchronized with video
+  // processing so frame size always matches.
+  if (!_codecDataBase.MatchesCurrentResolution(videoFrame.width(),
+                                               videoFrame.height())) {
+    LOG(LS_ERROR) << "Incoming frame doesn't match set resolution. Dropping.";
+    return VCM_PARAMETER_ERROR;
+  }
+  VideoFrame converted_frame = videoFrame;
+  if (converted_frame.video_frame_buffer()->native_handle() &&
+      !_encoder->SupportsNativeHandle()) {
+    // This module only supports software encoding.
+    // TODO(pbos): Offload conversion from the encoder thread.
+    rtc::scoped_refptr<VideoFrameBuffer> converted_buffer(
+        converted_frame.video_frame_buffer()->NativeToI420Buffer());
+
+    if (!converted_buffer) {
+      LOG(LS_ERROR) << "Frame conversion failed, dropping frame.";
+      return VCM_PARAMETER_ERROR;
+    }
+    converted_frame = VideoFrame(converted_buffer,
+                                 converted_frame.timestamp(),
+                                 converted_frame.render_time_ms(),
+                                 converted_frame.rotation());
+  }
+  int32_t ret =
+      _encoder->Encode(converted_frame, codecSpecificInfo, next_frame_types);
+  if (ret < 0) {
+    LOG(LS_ERROR) << "Failed to encode frame. Error code: " << ret;
+    return ret;
+  }
+
+  {
+    rtc::CritScope lock(&params_crit_);
+    // Change all keyframe requests to encode delta frames the next time.
+    for (size_t i = 0; i < next_frame_types_.size(); ++i) {
+      // Check for equality (same requested as before encoding) to not
+      // accidentally drop a keyframe request while encoding.
+      if (next_frame_types[i] == next_frame_types_[i])
+        next_frame_types_[i] = kVideoFrameDelta;
+    }
+  }
+  return VCM_OK;
+}
+
+int32_t VideoSender::IntraFrameRequest(size_t stream_index) {
+  {
+    rtc::CritScope lock(&params_crit_);
+    if (stream_index >= next_frame_types_.size()) {
+      return -1;
+    }
+    next_frame_types_[stream_index] = kVideoFrameKey;
+    if (!encoder_has_internal_source_)
+      return VCM_OK;
+  }
+  // TODO(pbos): Remove when InternalSource() is gone. Both locks have to be
+  // held here for internal consistency, since _encoder could be removed while
+  // not holding encoder_crit_. Checks have to be performed again since
+  // params_crit_ was dropped to not cause lock-order inversions with
+  // encoder_crit_.
+  rtc::CritScope lock(&encoder_crit_);
+  rtc::CritScope params_lock(&params_crit_);
+  if (stream_index >= next_frame_types_.size())
+    return -1;
+  if (_encoder != nullptr && _encoder->InternalSource()) {
+    // Try to request the frame if we have an external encoder with
+    // internal source since AddVideoFrame never will be called.
+    if (_encoder->RequestFrame(next_frame_types_) == WEBRTC_VIDEO_CODEC_OK) {
+      // Try to remove just-performed keyframe request, if stream still exists.
+      next_frame_types_[stream_index] = kVideoFrameDelta;
+    }
+  }
+  return VCM_OK;
+}
+
+int32_t VideoSender::EnableFrameDropper(bool enable) {
+  rtc::CritScope lock(&encoder_crit_);
+  frame_dropper_enabled_ = enable;
+  _mediaOpt.EnableFrameDropper(enable);
+  return VCM_OK;
+}
+}  // namespace vcm
+}  // namespace webrtc
diff --git a/webrtc/video/video_loopback.cc b/webrtc/video/video_loopback.cc
index f86078e..aacf412 100644
--- a/webrtc/video/video_loopback.cc
+++ b/webrtc/video/video_loopback.cc
@@ -1,294 +1,295 @@
-/*
- *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
- *
- *  Use of this source code is governed by a BSD-style license
- *  that can be found in the LICENSE file in the root of the source
- *  tree. An additional intellectual property rights grant can be found
- *  in the file PATENTS.  All contributing project authors may
- *  be found in the AUTHORS file in the root of the source tree.
- */
-
-#include <stdio.h>
-
-#include "gflags/gflags.h"
-#include "webrtc/test/field_trial.h"
-#include "webrtc/test/gtest.h"
-#include "webrtc/test/run_test.h"
-#include "webrtc/video/video_quality_test.h"
-
-namespace webrtc {
-namespace flags {
-
-// Flags common with screenshare loopback, with different default values.
-DEFINE_int32(width, 640, "Video width.");
-size_t Width() {
-  return static_cast<size_t>(FLAGS_width);
-}
-
-DEFINE_int32(height, 480, "Video height.");
-size_t Height() {
-  return static_cast<size_t>(FLAGS_height);
-}
-
-DEFINE_int32(fps, 30, "Frames per second.");
-int Fps() {
-  return static_cast<int>(FLAGS_fps);
-}
-
-DEFINE_int32(min_bitrate, 50, "Call and stream min bitrate in kbps.");
-int MinBitrateKbps() {
-  return static_cast<int>(FLAGS_min_bitrate);
-}
-
-DEFINE_int32(start_bitrate, 300, "Call start bitrate in kbps.");
-int StartBitrateKbps() {
-  return static_cast<int>(FLAGS_start_bitrate);
-}
-
-DEFINE_int32(target_bitrate, 800, "Stream target bitrate in kbps.");
-int TargetBitrateKbps() {
-  return static_cast<int>(FLAGS_target_bitrate);
-}
-
-DEFINE_int32(max_bitrate, 800, "Call and stream max bitrate in kbps.");
-int MaxBitrateKbps() {
-  return static_cast<int>(FLAGS_max_bitrate);
-}
-
-DEFINE_bool(suspend_below_min_bitrate,
-            false,
-            "Suspends video below the configured min bitrate.");
-
-DEFINE_int32(num_temporal_layers,
-             1,
-             "Number of temporal layers. Set to 1-4 to override.");
-int NumTemporalLayers() {
-  return static_cast<int>(FLAGS_num_temporal_layers);
-}
-
-// Flags common with screenshare loopback, with equal default values.
-DEFINE_string(codec, "VP8", "Video codec to use.");
-std::string Codec() {
-  return static_cast<std::string>(FLAGS_codec);
-}
-
-DEFINE_int32(selected_tl,
-             -1,
-             "Temporal layer to show or analyze. -1 to disable filtering.");
-int SelectedTL() {
-  return static_cast<int>(FLAGS_selected_tl);
-}
-
-DEFINE_int32(
-    duration,
-    0,
-    "Duration of the test in seconds. If 0, rendered will be shown instead.");
-int DurationSecs() {
-  return static_cast<int>(FLAGS_duration);
-}
-
-DEFINE_string(output_filename, "", "Target graph data filename.");
-std::string OutputFilename() {
-  return static_cast<std::string>(FLAGS_output_filename);
-}
-
-DEFINE_string(graph_title,
-              "",
-              "If empty, title will be generated automatically.");
-std::string GraphTitle() {
-  return static_cast<std::string>(FLAGS_graph_title);
-}
-
-DEFINE_int32(loss_percent, 0, "Percentage of packets randomly lost.");
-int LossPercent() {
-  return static_cast<int>(FLAGS_loss_percent);
-}
-
-DEFINE_int32(avg_burst_loss_length,
-             -1,
-             "Average burst length of lost packets.");
-int AvgBurstLossLength() {
-  return static_cast<int>(FLAGS_avg_burst_loss_length);
-}
-
-DEFINE_int32(link_capacity,
-             0,
-             "Capacity (kbps) of the fake link. 0 means infinite.");
-int LinkCapacityKbps() {
-  return static_cast<int>(FLAGS_link_capacity);
-}
-
-DEFINE_int32(queue_size, 0, "Size of the bottleneck link queue in packets.");
-int QueueSize() {
-  return static_cast<int>(FLAGS_queue_size);
-}
-
-DEFINE_int32(avg_propagation_delay_ms,
-             0,
-             "Average link propagation delay in ms.");
-int AvgPropagationDelayMs() {
-  return static_cast<int>(FLAGS_avg_propagation_delay_ms);
-}
-
-DEFINE_int32(std_propagation_delay_ms,
-             0,
-             "Link propagation delay standard deviation in ms.");
-int StdPropagationDelayMs() {
-  return static_cast<int>(FLAGS_std_propagation_delay_ms);
-}
-
-DEFINE_int32(selected_stream, 0, "ID of the stream to show or analyze.");
-int SelectedStream() {
-  return static_cast<int>(FLAGS_selected_stream);
-}
-
-DEFINE_int32(num_spatial_layers, 1, "Number of spatial layers to use.");
-int NumSpatialLayers() {
-  return static_cast<int>(FLAGS_num_spatial_layers);
-}
-
-DEFINE_int32(selected_sl,
-             -1,
-             "Spatial layer to show or analyze. -1 to disable filtering.");
-int SelectedSL() {
-  return static_cast<int>(FLAGS_selected_sl);
-}
-
-DEFINE_string(stream0,
-              "",
-              "Comma separated values describing VideoStream for stream #0.");
-std::string Stream0() {
-  return static_cast<std::string>(FLAGS_stream0);
-}
-
-DEFINE_string(stream1,
-              "",
-              "Comma separated values describing VideoStream for stream #1.");
-std::string Stream1() {
-  return static_cast<std::string>(FLAGS_stream1);
-}
-
-DEFINE_string(sl0,
-              "",
-              "Comma separated values describing SpatialLayer for layer #0.");
-std::string SL0() {
-  return static_cast<std::string>(FLAGS_sl0);
-}
-
-DEFINE_string(sl1,
-              "",
-              "Comma separated values describing SpatialLayer for layer #1.");
-std::string SL1() {
-  return static_cast<std::string>(FLAGS_sl1);
-}
-
-DEFINE_string(encoded_frame_path,
-              "",
-              "The base path for encoded frame logs. Created files will have "
-              "the form <encoded_frame_path>.<n>.(recv|send.<m>).ivf");
-std::string EncodedFramePath() {
-  return static_cast<std::string>(FLAGS_encoded_frame_path);
-}
-
-DEFINE_bool(logs, false, "print logs to stderr");
-
-DEFINE_bool(send_side_bwe, true, "Use send-side bandwidth estimation");
-
-DEFINE_bool(allow_reordering, false, "Allow packet reordering to occur");
-
-DEFINE_bool(use_ulpfec, false, "Use RED+ULPFEC forward error correction.");
-
-DEFINE_bool(use_flexfec, false, "Use FlexFEC forward error correction.");
-
-DEFINE_bool(audio, false, "Add audio stream");
-
-DEFINE_bool(audio_video_sync, false, "Sync audio and video stream (no effect if"
-    " audio is false)");
-
-DEFINE_bool(video, true, "Add video stream");
-
-DEFINE_string(
-    force_fieldtrials,
-    "",
-    "Field trials control experimental feature code which can be forced. "
-    "E.g. running with --force_fieldtrials=WebRTC-FooFeature/Enable/"
-    " will assign the group Enable to field trial WebRTC-FooFeature. Multiple "
-    "trials are separated by \"/\"");
-
-// Video-specific flags.
-DEFINE_string(clip,
-              "",
-              "Name of the clip to show. If empty, using chroma generator.");
-std::string Clip() {
-  return static_cast<std::string>(FLAGS_clip);
-}
-
-}  // namespace flags
-
-void Loopback() {
-  FakeNetworkPipe::Config pipe_config;
-  pipe_config.loss_percent = flags::LossPercent();
-  pipe_config.avg_burst_loss_length = flags::AvgBurstLossLength();
-  pipe_config.link_capacity_kbps = flags::LinkCapacityKbps();
-  pipe_config.queue_length_packets = flags::QueueSize();
-  pipe_config.queue_delay_ms = flags::AvgPropagationDelayMs();
-  pipe_config.delay_standard_deviation_ms = flags::StdPropagationDelayMs();
-  pipe_config.allow_reordering = flags::FLAGS_allow_reordering;
-
-  Call::Config::BitrateConfig call_bitrate_config;
-  call_bitrate_config.min_bitrate_bps = flags::MinBitrateKbps() * 1000;
-  call_bitrate_config.start_bitrate_bps = flags::StartBitrateKbps() * 1000;
-  call_bitrate_config.max_bitrate_bps = flags::MaxBitrateKbps() * 1000;
-
-  VideoQualityTest::Params params;
-  params.call = {flags::FLAGS_send_side_bwe, call_bitrate_config};
-  params.video = {flags::FLAGS_video,
-                  flags::Width(),
-                  flags::Height(),
-                  flags::Fps(),
-                  flags::MinBitrateKbps() * 1000,
-                  flags::TargetBitrateKbps() * 1000,
-                  flags::MaxBitrateKbps() * 1000,
-                  flags::FLAGS_suspend_below_min_bitrate,
-                  flags::Codec(),
-                  flags::NumTemporalLayers(),
-                  flags::SelectedTL(),
-                  0,  // No min transmit bitrate.
-                  flags::FLAGS_use_ulpfec,
-                  flags::FLAGS_use_flexfec,
-                  flags::EncodedFramePath(),
-                  flags::Clip()};
-  params.audio = {flags::FLAGS_audio, flags::FLAGS_audio_video_sync};
-  params.screenshare.enabled = false;
-  params.analyzer = {"video", 0.0, 0.0, flags::DurationSecs(),
-      flags::OutputFilename(), flags::GraphTitle()};
-  params.pipe = pipe_config;
-  params.logs = flags::FLAGS_logs;
-
-  std::vector<std::string> stream_descriptors;
-  stream_descriptors.push_back(flags::Stream0());
-  stream_descriptors.push_back(flags::Stream1());
-  std::vector<std::string> SL_descriptors;
-  SL_descriptors.push_back(flags::SL0());
-  SL_descriptors.push_back(flags::SL1());
-  VideoQualityTest::FillScalabilitySettings(
-      &params, stream_descriptors, flags::SelectedStream(),
-      flags::NumSpatialLayers(), flags::SelectedSL(), SL_descriptors);
-
-  VideoQualityTest test;
-  if (flags::DurationSecs()) {
-    test.RunWithAnalyzer(params);
-  } else {
-    test.RunWithRenderers(params);
-  }
-}
-}  // namespace webrtc
-
-int main(int argc, char* argv[]) {
-  ::testing::InitGoogleTest(&argc, argv);
-  google::ParseCommandLineFlags(&argc, &argv, true);
-  webrtc::test::InitFieldTrialsFromString(
-      webrtc::flags::FLAGS_force_fieldtrials);
-  webrtc::test::RunTest(webrtc::Loopback);
-  return 0;
-}
+/*
+ *  Copyright (c) 2015 The WebRTC project authors. All Rights Reserved.
+ *
+ *  Use of this source code is governed by a BSD-style license
+ *  that can be found in the LICENSE file in the root of the source
+ *  tree. An additional intellectual property rights grant can be found
+ *  in the file PATENTS.  All contributing project authors may
+ *  be found in the AUTHORS file in the root of the source tree.
+ */
+
+#include <stdio.h>
+
+#include "gflags/gflags.h"
+#include "webrtc/test/field_trial.h"
+#include "webrtc/test/gtest.h"
+#include "webrtc/test/run_test.h"
+#include "webrtc/video/video_quality_test.h"
+
+namespace webrtc {
+namespace flags {
+
+// Flags common with screenshare loopback, with different default values.
+DEFINE_int32(width, 640, "Video width.");
+size_t Width() {
+  return static_cast<size_t>(FLAGS_width);
+}
+
+DEFINE_int32(height, 480, "Video height.");
+size_t Height() {
+  return static_cast<size_t>(FLAGS_height);
+}
+
+DEFINE_int32(fps, 30, "Frames per second.");
+int Fps() {
+  return static_cast<int>(FLAGS_fps);
+}
+
+DEFINE_int32(min_bitrate, 50, "Call and stream min bitrate in kbps.");
+int MinBitrateKbps() {
+  return static_cast<int>(FLAGS_min_bitrate);
+}
+
+DEFINE_int32(start_bitrate, 300, "Call start bitrate in kbps.");
+int StartBitrateKbps() {
+  return static_cast<int>(FLAGS_start_bitrate);
+}
+
+DEFINE_int32(target_bitrate, 800, "Stream target bitrate in kbps.");
+int TargetBitrateKbps() {
+  return static_cast<int>(FLAGS_target_bitrate);
+}
+
+DEFINE_int32(max_bitrate, 800, "Call and stream max bitrate in kbps.");
+int MaxBitrateKbps() {
+  return static_cast<int>(FLAGS_max_bitrate);
+}
+
+DEFINE_bool(suspend_below_min_bitrate,
+            false,
+            "Suspends video below the configured min bitrate.");
+
+DEFINE_int32(num_temporal_layers,
+             1,
+             "Number of temporal layers. Set to 1-4 to override.");
+int NumTemporalLayers() {
+  return static_cast<int>(FLAGS_num_temporal_layers);
+}
+
+// Flags common with screenshare loopback, with equal default values.
+DEFINE_string(codec, "H264", "Video codec to use.");
+std::string Codec() {
+  return static_cast<std::string>(FLAGS_codec);
+}
+
+DEFINE_int32(selected_tl,
+             -1,
+             "Temporal layer to show or analyze. -1 to disable filtering.");
+int SelectedTL() {
+  return static_cast<int>(FLAGS_selected_tl);
+}
+
+DEFINE_int32(
+    duration,
+    0,
+    "Duration of the test in seconds. If 0, rendered will be shown instead.");
+int DurationSecs() {
+  return static_cast<int>(FLAGS_duration);
+}
+
+DEFINE_string(output_filename, "", "Target graph data filename.");
+std::string OutputFilename() {
+  return static_cast<std::string>(FLAGS_output_filename);
+}
+
+DEFINE_string(graph_title,
+              "",
+              "If empty, title will be generated automatically.");
+std::string GraphTitle() {
+  return static_cast<std::string>(FLAGS_graph_title);
+}
+
+DEFINE_int32(loss_percent, 0, "Percentage of packets randomly lost.");
+int LossPercent() {
+  return static_cast<int>(FLAGS_loss_percent);
+}
+
+DEFINE_int32(avg_burst_loss_length,
+             -1,
+             "Average burst length of lost packets.");
+int AvgBurstLossLength() {
+  return static_cast<int>(FLAGS_avg_burst_loss_length);
+}
+
+DEFINE_int32(link_capacity,
+             0,
+             "Capacity (kbps) of the fake link. 0 means infinite.");
+int LinkCapacityKbps() {
+  return static_cast<int>(FLAGS_link_capacity);
+}
+
+DEFINE_int32(queue_size, 0, "Size of the bottleneck link queue in packets.");
+int QueueSize() {
+  return static_cast<int>(FLAGS_queue_size);
+}
+
+DEFINE_int32(avg_propagation_delay_ms,
+             0,
+             "Average link propagation delay in ms.");
+int AvgPropagationDelayMs() {
+  return static_cast<int>(FLAGS_avg_propagation_delay_ms);
+}
+
+DEFINE_int32(std_propagation_delay_ms,
+             0,
+             "Link propagation delay standard deviation in ms.");
+int StdPropagationDelayMs() {
+  return static_cast<int>(FLAGS_std_propagation_delay_ms);
+}
+
+DEFINE_int32(selected_stream, 0, "ID of the stream to show or analyze.");
+int SelectedStream() {
+  return static_cast<int>(FLAGS_selected_stream);
+}
+
+DEFINE_int32(num_spatial_layers, 1, "Number of spatial layers to use.");
+int NumSpatialLayers() {
+  return static_cast<int>(FLAGS_num_spatial_layers);
+}
+
+DEFINE_int32(selected_sl,
+             -1,
+             "Spatial layer to show or analyze. -1 to disable filtering.");
+int SelectedSL() {
+  return static_cast<int>(FLAGS_selected_sl);
+}
+
+DEFINE_string(stream0,
+              "",
+              "Comma separated values describing VideoStream for stream #0.");
+std::string Stream0() {
+  return static_cast<std::string>(FLAGS_stream0);
+}
+
+DEFINE_string(stream1,
+              "",
+              "Comma separated values describing VideoStream for stream #1.");
+std::string Stream1() {
+  return static_cast<std::string>(FLAGS_stream1);
+}
+
+DEFINE_string(sl0,
+              "",
+              "Comma separated values describing SpatialLayer for layer #0.");
+std::string SL0() {
+  return static_cast<std::string>(FLAGS_sl0);
+}
+
+DEFINE_string(sl1,
+              "",
+              "Comma separated values describing SpatialLayer for layer #1.");
+std::string SL1() {
+  return static_cast<std::string>(FLAGS_sl1);
+}
+
+DEFINE_string(encoded_frame_path,
+              "",
+              "The base path for encoded frame logs. Created files will have "
+              "the form <encoded_frame_path>.<n>.(recv|send.<m>).ivf");
+std::string EncodedFramePath() {
+  return static_cast<std::string>(FLAGS_encoded_frame_path);
+}
+
+DEFINE_bool(logs, false, "print logs to stderr");
+
+DEFINE_bool(send_side_bwe, true, "Use send-side bandwidth estimation");
+
+DEFINE_bool(allow_reordering, false, "Allow packet reordering to occur");
+
+DEFINE_bool(use_ulpfec, false, "Use RED+ULPFEC forward error correction.");
+
+DEFINE_bool(use_flexfec, false, "Use FlexFEC forward error correction.");
+
+DEFINE_bool(audio, false, "Add audio stream");
+
+DEFINE_bool(audio_video_sync, false, "Sync audio and video stream (no effect if"
+    " audio is false)");
+
+DEFINE_bool(video, true, "Add video stream");
+
+DEFINE_string(
+    force_fieldtrials,
+    "",
+    "Field trials control experimental feature code which can be forced. "
+    "E.g. running with --force_fieldtrials=WebRTC-FooFeature/Enable/"
+    " will assign the group Enable to field trial WebRTC-FooFeature. Multiple "
+    "trials are separated by \"/\"");
+
+// Video-specific flags.
+DEFINE_string(clip,
+              "",
+              "Name of the clip to show. If empty, using chroma generator.");
+std::string Clip() {
+  return static_cast<std::string>(FLAGS_clip);
+}
+
+}  // namespace flags
+
+void Loopback() {
+  FakeNetworkPipe::Config pipe_config;
+  pipe_config.loss_percent = flags::LossPercent();
+  pipe_config.avg_burst_loss_length = flags::AvgBurstLossLength();
+  pipe_config.link_capacity_kbps = flags::LinkCapacityKbps();
+  pipe_config.queue_length_packets = flags::QueueSize();
+  pipe_config.queue_delay_ms = flags::AvgPropagationDelayMs();
+  pipe_config.delay_standard_deviation_ms = flags::StdPropagationDelayMs();
+  pipe_config.allow_reordering = flags::FLAGS_allow_reordering;
+
+  Call::Config::BitrateConfig call_bitrate_config;
+  call_bitrate_config.min_bitrate_bps = flags::MinBitrateKbps() * 1000;
+  call_bitrate_config.start_bitrate_bps = flags::StartBitrateKbps() * 1000;
+  call_bitrate_config.max_bitrate_bps = flags::MaxBitrateKbps() * 1000;
+
+  VideoQualityTest::Params params;
+  params.call = {flags::FLAGS_send_side_bwe, call_bitrate_config};
+  params.video = {flags::FLAGS_video,
+                  flags::Width(),
+                  flags::Height(),
+                  flags::Fps(),
+                  flags::MinBitrateKbps() * 1000,
+                  flags::TargetBitrateKbps() * 1000,
+                  flags::MaxBitrateKbps() * 1000,
+                  flags::FLAGS_suspend_below_min_bitrate,
+                  flags::Codec(),
+                  flags::NumTemporalLayers(),
+                  flags::SelectedTL(),
+                  0,  // No min transmit bitrate.
+                  flags::FLAGS_use_ulpfec,
+                  flags::FLAGS_use_flexfec,
+                  flags::EncodedFramePath(),
+                  flags::Clip()};
+  params.audio = {flags::FLAGS_audio, flags::FLAGS_audio_video_sync};
+  params.screenshare.enabled = false;
+  params.analyzer = {"video", 0.0, 0.0, flags::DurationSecs(),
+      flags::OutputFilename(), flags::GraphTitle()};
+  params.pipe = pipe_config;
+  params.logs = flags::FLAGS_logs;
+
+  std::vector<std::string> stream_descriptors;
+  stream_descriptors.push_back(flags::Stream0());
+  stream_descriptors.push_back(flags::Stream1());
+  std::vector<std::string> SL_descriptors;
+  SL_descriptors.push_back(flags::SL0());
+  SL_descriptors.push_back(flags::SL1());
+  VideoQualityTest::FillScalabilitySettings(
+      &params, stream_descriptors, flags::SelectedStream(),
+      flags::NumSpatialLayers(), flags::SelectedSL(), SL_descriptors);
+
+  VideoQualityTest test;
+  if (flags::DurationSecs()) {
+    test.RunWithAnalyzer(params);
+  } else {
+    test.RunWithRenderers(params);
+  }
+}
+}  // namespace webrtc
+#if 1
+int main(int argc, char* argv[]) {
+  ::testing::InitGoogleTest(&argc, argv);
+  google::ParseCommandLineFlags(&argc, &argv, true);
+  webrtc::test::InitFieldTrialsFromString(
+      webrtc::flags::FLAGS_force_fieldtrials);
+  webrtc::test::RunTest(webrtc::Loopback);
+  return 0;
+}
+#endif
diff --git a/webrtc/video/vie_encoder.cc b/webrtc/video/vie_encoder.cc
index c0228f9..9bd298a 100644
--- a/webrtc/video/vie_encoder.cc
+++ b/webrtc/video/vie_encoder.cc
@@ -44,7 +44,7 @@ const int kMinPixelsPerFrame = 320 * 180;
 
 // The maximum number of frames to drop at beginning of stream
 // to try and achieve desired bitrate.
-const int kMaxInitialFramedrop = 4;
+const int kMaxInitialFramedrop = 0;
 
 // TODO(pbos): Lower these thresholds (to closer to 100%) when we handle
 // pipelining encoders better (multiple input frames before something comes
