From 0ac98f148b4be03471baa2565d6012ed6232a52a Mon Sep 17 00:00:00 2001
From: Tyler Gibson <tgibson@microsoft.com>
Date: Wed, 12 Apr 2017 08:53:12 +0000
Subject: [PATCH] [PATCH] Andrei's support for nvencode h264 encoder

---
 webrtc/api/video/i420_buffer.cc                    |  24 +-
 webrtc/api/video/i420_buffer.h                     |   6 +-
 webrtc/api/video/video_frame_buffer.h              |   1 +
 webrtc/common_video/include/video_frame_buffer.h   |   2 +
 webrtc/common_video/video_frame_buffer.cc          |   4 +
 webrtc/media/engine/webrtcvideoengine2.cc          |   2 +-
 .../video_coding/codecs/h264/h264_encoder_impl.cc  | 310 +++++++++++++++++++--
 .../video_coding/codecs/h264/h264_encoder_impl.h   |  32 ++-
 webrtc/modules/video_coding/video_sender.cc        |   2 +
 webrtc/video/video_loopback.cc                     |   5 +-
 10 files changed, 353 insertions(+), 35 deletions(-)

diff --git a/webrtc/api/video/i420_buffer.cc b/webrtc/api/video/i420_buffer.cc
index 81f5789..3ef687c 100644
--- a/webrtc/api/video/i420_buffer.cc
+++ b/webrtc/api/video/i420_buffer.cc
@@ -34,21 +34,28 @@ int I420DataSize(int height, int stride_y, int stride_u, int stride_v) {
 }  // namespace
 
 I420Buffer::I420Buffer(int width, int height)
-    : I420Buffer(width, height, width, (width + 1) / 2, (width + 1) / 2) {
+    : I420Buffer(width, height, width, 0, (width + 1) / 2, (width + 1) / 2) {
 }
 
+I420Buffer::I420Buffer(int width, int height, int encoded_length)
+	: I420Buffer(width, height, encoded_length, width, (width + 1) / 2, (width + 1) / 2) {
+}
+
+
 I420Buffer::I420Buffer(int width,
                        int height,
+					   int encoded_length,
                        int stride_y,
                        int stride_u,
                        int stride_v)
     : width_(width),
       height_(height),
+	  encoded_length_(encoded_length),
       stride_y_(stride_y),
       stride_u_(stride_u),
       stride_v_(stride_v),
       data_(static_cast<uint8_t*>(AlignedMalloc(
-          I420DataSize(height, stride_y, stride_u, stride_v),
+		  encoded_length > 0 ? encoded_length : I420DataSize(height, stride_y, stride_u, stride_v),
           kBufferAlignment))) {
   RTC_DCHECK_GT(width, 0);
   RTC_DCHECK_GT(height, 0);
@@ -65,6 +72,10 @@ rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width, int height) {
   return new rtc::RefCountedObject<I420Buffer>(width, height);
 }
 
+rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width, int height, int encoded_length) {
+	return new rtc::RefCountedObject<I420Buffer>(width, height, encoded_length);
+}
+
 // static
 rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width,
                                                   int height,
@@ -72,7 +83,7 @@ rtc::scoped_refptr<I420Buffer> I420Buffer::Create(int width,
                                                   int stride_u,
                                                   int stride_v) {
   return new rtc::RefCountedObject<I420Buffer>(
-      width, height, stride_y, stride_u, stride_v);
+      width, height, 0, stride_y, stride_u, stride_v);
 }
 
 // static
@@ -155,6 +166,10 @@ int I420Buffer::height() const {
   return height_;
 }
 
+int I420Buffer::encoded_length() const {
+	return encoded_length_;
+}
+
 const uint8_t* I420Buffer::DataY() const {
   return data_.get();
 }
@@ -180,7 +195,8 @@ void* I420Buffer::native_handle() const {
 }
 
 rtc::scoped_refptr<VideoFrameBuffer> I420Buffer::NativeToI420Buffer() {
-  return this;
+  RTC_NOTREACHED();
+  return nullptr;
 }
 
 uint8_t* I420Buffer::MutableDataY() {
diff --git a/webrtc/api/video/i420_buffer.h b/webrtc/api/video/i420_buffer.h
index 388a3dd..bda0bb4 100644
--- a/webrtc/api/video/i420_buffer.h
+++ b/webrtc/api/video/i420_buffer.h
@@ -23,6 +23,7 @@ namespace webrtc {
 class I420Buffer : public VideoFrameBuffer {
  public:
   static rtc::scoped_refptr<I420Buffer> Create(int width, int height);
+  static rtc::scoped_refptr<I420Buffer> Create(int width, int height, int encoded_length);
   static rtc::scoped_refptr<I420Buffer> Create(int width,
                                                int height,
                                                int stride_y,
@@ -58,6 +59,7 @@ class I420Buffer : public VideoFrameBuffer {
 
   int width() const override;
   int height() const override;
+  int encoded_length() const override;
   const uint8_t* DataY() const override;
   const uint8_t* DataU() const override;
   const uint8_t* DataV() const override;
@@ -98,13 +100,15 @@ class I420Buffer : public VideoFrameBuffer {
 
  protected:
   I420Buffer(int width, int height);
-  I420Buffer(int width, int height, int stride_y, int stride_u, int stride_v);
+  I420Buffer(int width, int height, int encoded_length);
+  I420Buffer(int width, int height, int encoded_length, int stride_y, int stride_u, int stride_v);
 
   ~I420Buffer() override;
 
  private:
   const int width_;
   const int height_;
+  const int encoded_length_;
   const int stride_y_;
   const int stride_u_;
   const int stride_v_;
diff --git a/webrtc/api/video/video_frame_buffer.h b/webrtc/api/video/video_frame_buffer.h
index c8c2e5d..ec3c633 100644
--- a/webrtc/api/video/video_frame_buffer.h
+++ b/webrtc/api/video/video_frame_buffer.h
@@ -26,6 +26,7 @@ class VideoFrameBuffer : public rtc::RefCountInterface {
   // subsampled, this is the highest-resolution plane.
   virtual int width() const = 0;
   virtual int height() const = 0;
+  virtual int encoded_length() const = 0;
 
   // Returns pointer to the pixel data for a given plane. The memory is owned by
   // the VideoFrameBuffer object and must not be freed by the caller.
diff --git a/webrtc/common_video/include/video_frame_buffer.h b/webrtc/common_video/include/video_frame_buffer.h
index dfdd480..7cb48ba 100644
--- a/webrtc/common_video/include/video_frame_buffer.h
+++ b/webrtc/common_video/include/video_frame_buffer.h
@@ -60,6 +60,7 @@ class WrappedI420Buffer : public webrtc::VideoFrameBuffer {
                     const rtc::Callback0<void>& no_longer_used);
   int width() const override;
   int height() const override;
+  int encoded_length() const override;
 
   const uint8_t* DataY() const override;
   const uint8_t* DataU() const override;
@@ -78,6 +79,7 @@ class WrappedI420Buffer : public webrtc::VideoFrameBuffer {
 
   const int width_;
   const int height_;
+  const int encoded_length_;
   const uint8_t* const y_plane_;
   const uint8_t* const u_plane_;
   const uint8_t* const v_plane_;
diff --git a/webrtc/common_video/video_frame_buffer.cc b/webrtc/common_video/video_frame_buffer.cc
index 4646bf4..e4b14aa 100644
--- a/webrtc/common_video/video_frame_buffer.cc
+++ b/webrtc/common_video/video_frame_buffer.cc
@@ -79,6 +79,7 @@ WrappedI420Buffer::WrappedI420Buffer(int width,
                                      const rtc::Callback0<void>& no_longer_used)
     : width_(width),
       height_(height),
+	  encoded_length_(0),
       y_plane_(y_plane),
       u_plane_(u_plane),
       v_plane_(v_plane),
@@ -100,6 +101,9 @@ int WrappedI420Buffer::height() const {
   return height_;
 }
 
+int WrappedI420Buffer::encoded_length() const {
+	return encoded_length_;
+}
 const uint8_t* WrappedI420Buffer::DataY() const {
   return y_plane_;
 }
diff --git a/webrtc/media/engine/webrtcvideoengine2.cc b/webrtc/media/engine/webrtcvideoengine2.cc
index 087fc4e..9b0ab26 100644
--- a/webrtc/media/engine/webrtcvideoengine2.cc
+++ b/webrtc/media/engine/webrtcvideoengine2.cc
@@ -573,7 +573,7 @@ static void AppendVideoCodecs(const std::vector<VideoCodec>& input_codecs,
         codec.name != kFlexfecCodecName)
       AddDefaultFeedbackParams(&codec);
     // Don't add same codec twice.
-    if (FindMatchingCodec(*unified_codecs, codec))
+    if (codec.name != kH264CodecName || FindMatchingCodec(*unified_codecs, codec))
       continue;
 
     unified_codecs->push_back(codec);
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
index 315d347..f421cc4 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
+++ b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.cc
@@ -10,27 +10,49 @@
  */
 
 #include "webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h"
+#include "webrtc/modules/video_coding/codecs/h264/h264_decoder_impl.h"
+#include "webrtc/common_video/h264/h264_common.h"
 
 #include <limits>
 #include <string>
 
+#if USEOPENH264 
 #include "third_party/openh264/src/codec/api/svc/codec_api.h"
 #include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
 #include "third_party/openh264/src/codec/api/svc/codec_def.h"
 #include "third_party/openh264/src/codec/api/svc/codec_ver.h"
 
+#elif USEX264
+//#define __STDC_CONSTANT_MACROS
+//x264 and ffmpeg headers
+extern "C"
+ {
+	#include "third_party/x264/x264.h"
+	#include "third_party/ffmpeg/libavcodec/avcodec.h"
+	#include "third_party/ffmpeg/libavformat/avformat.h"
+	#include "third_party/ffmpeg/libswscale/swscale.h"
+}
+#endif
+
 #include "webrtc/base/checks.h"
 #include "webrtc/base/logging.h"
 #include "webrtc/common_video/libyuv/include/webrtc_libyuv.h"
 #include "webrtc/media/base/mediaconstants.h"
 #include "webrtc/system_wrappers/include/metrics.h"
 
+#include <memory>
+#include <utility>
+#include <vector>
+#include <iostream>
+#include <fstream>
+#include "webrtc/base/thread.h"
+#include "webrtc/base/bind.h"
+#include "webrtc/base/asyncinvoker.h"
+
 namespace webrtc {
 
 namespace {
 
-const bool kOpenH264EncoderDetailedLogging = false;
-
 // Used by histograms. Values of entries should not be changed.
 enum H264EncoderImplEvent {
   kH264EncoderEventInit = 0,
@@ -38,6 +60,9 @@ enum H264EncoderImplEvent {
   kH264EncoderEventMax = 16,
 };
 
+#if USEOPENH264
+const bool kOpenH264EncoderDetailedLogging = false;
+
 int NumberOfThreads(int width, int height, int number_of_cores) {
   // TODO(hbos): In Chromium, multiple threads do not work with sandbox on Mac,
   // see crbug.com/583348. Until further investigated, only use one thread.
@@ -70,9 +95,11 @@ FrameType ConvertToVideoFrameType(EVideoFrameType type) {
   RTC_NOTREACHED() << "Unexpected/invalid frame type: " << type;
   return kEmptyFrame;
 }
-
+#endif
 }  // namespace
 
+#if USEOPENH264
+
 // Helper method used by H264EncoderImpl::Encode.
 // Copies the encoded bytes from |info| to |encoded_image| and updates the
 // fragmentation information of |frag_header|. The |encoded_image->_buffer| may
@@ -151,9 +178,18 @@ static void RtpFragmentize(EncodedImage* encoded_image,
     encoded_image->_length += layer_len;
   }
 }
+#endif
 
 H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
-    : openh264_encoder_(nullptr),
+    : 
+	#if USEOPENH264
+	 encoder_(nullptr),
+	number_of_cores_(0),
+	#elif USEX264
+	 encoder_(nullptr),
+	number_of_cores_(0),
+	nal(nullptr),
+	#endif
       width_(0),
       height_(0),
       max_frame_rate_(0.0f),
@@ -164,7 +200,6 @@ H264EncoderImpl::H264EncoderImpl(const cricket::VideoCodec& codec)
       key_frame_interval_(0),
       packetization_mode_(H264PacketizationMode::SingleNalUnit),
       max_payload_size_(0),
-      number_of_cores_(0),
       encoded_image_callback_(nullptr),
       has_reported_init_(false),
       has_reported_error_(false) {
@@ -204,20 +239,26 @@ int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
     ReportError();
     return release_ret;
   }
-  RTC_DCHECK(!openh264_encoder_);
+ #if USEOPENH264 || USEX264
+	  RTC_DCHECK(!encoder_);
+  #endif
+
+	//codec_settings_ = *codec_settings;
+	  
+#if USEOPENH264
 
   // Create encoder.
-  if (WelsCreateSVCEncoder(&openh264_encoder_) != 0) {
+  if (WelsCreateSVCEncoder(&encoder_) != 0) {
     // Failed to create encoder.
     LOG(LS_ERROR) << "Failed to create OpenH264 encoder";
-    RTC_DCHECK(!openh264_encoder_);
+	RTC_DCHECK(!encoder_);
     ReportError();
     return WEBRTC_VIDEO_CODEC_ERROR;
   }
-  RTC_DCHECK(openh264_encoder_);
+  RTC_DCHECK(encoder_);
   if (kOpenH264EncoderDetailedLogging) {
     int trace_level = WELS_LOG_DETAIL;
-    openh264_encoder_->SetOption(ENCODER_OPTION_TRACE_LEVEL,
+	encoder_->SetOption(ENCODER_OPTION_TRACE_LEVEL,
                                  &trace_level);
   }
   // else WELS_LOG_DEFAULT is used by default.
@@ -242,7 +283,7 @@ int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
   SEncParamExt encoder_params = CreateEncoderParams();
 
   // Initialize.
-  if (openh264_encoder_->InitializeExt(&encoder_params) != 0) {
+  if (encoder_->InitializeExt(&encoder_params) != 0) {
     LOG(LS_ERROR) << "Failed to initialize OpenH264 encoder";
     Release();
     ReportError();
@@ -250,9 +291,88 @@ int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
   }
   // TODO(pbos): Base init params on these values before submitting.
   int video_format = EVideoFormatType::videoFormatI420;
-  openh264_encoder_->SetOption(ENCODER_OPTION_DATAFORMAT,
+  encoder_->SetOption(ENCODER_OPTION_DATAFORMAT,
                                &video_format);
 
+#elif USEX264
+	  number_of_cores_ = number_of_cores;
+	  /* Get default params for preset/tuning */
+	  x264_param_t param;
+	  int ret_val;
+	  ret_val = x264_param_default_preset(&param, "medium", NULL);
+	  if (ret_val != 0) {
+		  /*WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+						  "H264EncoderImpl::InitEncode() fails to initialize encoder ret_val %d",
+						  ret_val);*/
+		  x264_encoder_close(encoder_);
+		  encoder_ = NULL;
+		  return WEBRTC_VIDEO_CODEC_ERROR;
+	  }
+
+	  /* Configure non-default params */
+	  param.i_csp = X264_CSP_I420;
+	  param.i_width = codec_settings->width;
+	  param.i_height = codec_settings->height;
+	  param.b_vfr_input = 0;
+	  param.b_repeat_headers = 1;
+	  param.b_annexb = 0;
+	  param.i_bframe = 0;
+	  param.rc.i_lookahead = 0;
+	  param.b_sliced_threads = 1;
+	  param.b_cabac = 0;
+	  param.i_fps_den = 1;
+	  param.i_fps_num = codec_settings->maxFramerate;
+	  param.rc.i_bitrate = codec_settings->maxBitrate;
+	  /* Apply profile restrictions. */
+	  ret_val = x264_param_apply_profile(&param, "baseline");
+	  if (ret_val != 0) {
+		  /*WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+						  "H264EncoderImpl::InitEncode() fails to initialize encoder ret_val %d",
+						  ret_val);*/
+		  x264_encoder_close(encoder_);
+		  encoder_ = NULL;
+		  return WEBRTC_VIDEO_CODEC_ERROR;
+
+	  }
+
+	  ret_val = x264_picture_alloc(&pic, param.i_csp, param.i_width, param.i_height);
+	  if (ret_val != 0) {
+		  /*WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+								  "H264EncoderImpl::InitEncode() fails to initialize encoder ret_val %d",
+								  ret_val);*/
+		  x264_encoder_close(encoder_);
+		  encoder_ = NULL;
+		  return WEBRTC_VIDEO_CODEC_ERROR;
+
+	  }
+
+	  encoder_ = x264_encoder_open(&param);
+	  if (!encoder_) {
+		  /*WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+						  "H264EncoderImpl::InitEncode() fails to initialize encoder ret_val %d",
+						  ret_val);*/
+		  x264_encoder_close(encoder_);
+		  x264_picture_clean(&pic);
+		  encoder_ = NULL;
+		  return WEBRTC_VIDEO_CODEC_ERROR;
+
+	  }
+
+	  number_of_cores_ = number_of_cores;
+	  //codec_settings_ = *codec_settings;
+	  if (codec_settings_.targetBitrate == 0)
+		  codec_settings_.targetBitrate = codec_settings_.startBitrate;
+
+#if 1
+	  // TODO(pbos): Base init params on these values before submitting.
+	  quality_scaler_.Init(QualityScaler::kLowH264QpThreshold,
+		  QualityScaler::kBadH264QpThreshold,
+		  codec_settings_.startBitrate, codec_settings_.width,
+		  codec_settings_.height, codec_settings_.maxFramerate);
+#endif
+		  
+#endif
+
   // Initialize encoded image. Default buffer size: size of unencoded data.
   encoded_image_._size =
       CalcBufferSize(kI420, codec_settings->width, codec_settings->height);
@@ -266,11 +386,20 @@ int32_t H264EncoderImpl::InitEncode(const VideoCodec* codec_settings,
 }
 
 int32_t H264EncoderImpl::Release() {
-  if (openh264_encoder_) {
-    RTC_CHECK_EQ(0, openh264_encoder_->Uninitialize());
-    WelsDestroySVCEncoder(openh264_encoder_);
-    openh264_encoder_ = nullptr;
-  }
+#if USEOPENH264
+	if (encoder_) {
+		RTC_CHECK_EQ(0, encoder_->Uninitialize());
+		WelsDestroySVCEncoder(encoder_);
+		encoder_ = nullptr;
+
+	}
+#elif USEX264
+	if (encoder_) {
+		x264_encoder_close(encoder_);
+		encoder_ = nullptr;
+	}
+#endif
+
   encoded_image_._buffer = nullptr;
   encoded_image_buffer_.reset();
   return WEBRTC_VIDEO_CODEC_OK;
@@ -291,23 +420,27 @@ int32_t H264EncoderImpl::SetRateAllocation(
   target_bps_ = bitrate_allocation.get_sum_bps();
   max_frame_rate_ = static_cast<float>(framerate);
 
+#if USEOPENH264
   SBitrateInfo target_bitrate;
   memset(&target_bitrate, 0, sizeof(SBitrateInfo));
   target_bitrate.iLayer = SPATIAL_LAYER_ALL,
   target_bitrate.iBitrate = target_bps_;
-  openh264_encoder_->SetOption(ENCODER_OPTION_BITRATE,
+  encoder_->SetOption(ENCODER_OPTION_BITRATE,
                                &target_bitrate);
-  openh264_encoder_->SetOption(ENCODER_OPTION_FRAME_RATE, &max_frame_rate_);
+  encoder_->SetOption(ENCODER_OPTION_FRAME_RATE, &max_frame_rate_);
+#endif
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
 int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
                                 const CodecSpecificInfo* codec_specific_info,
                                 const std::vector<FrameType>* frame_types) {
+#if USEOPENH264 || USEX264
   if (!IsInitialized()) {
     ReportError();
     return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
   }
+#endif
   if (!encoded_image_callback_) {
     LOG(LS_WARNING) << "InitEncode() has been called, but a callback function "
                     << "has not been set with RegisterEncodeCompleteCallback()";
@@ -330,10 +463,38 @@ int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
     // API doc says ForceIntraFrame(false) does nothing, but calling this
     // function forces a key frame regardless of the |bIDR| argument's value.
     // (If every frame is a key frame we get lag/delays.)
-    openh264_encoder_->ForceIntraFrame(true);
+#if USEOPENH264
+	  encoder_->ForceIntraFrame(true);
+#elif USEX264
+	  pic.b_keyframe = true;
+#endif
   }
   rtc::scoped_refptr<const VideoFrameBuffer> frame_buffer =
-      input_frame.video_frame_buffer();
+	  input_frame.video_frame_buffer();
+
+#if USEX264
+  /* Read input frame */
+  pic.img.plane[0] = const_cast<uint8_t*>(frame_buffer->DataY());
+  pic.img.plane[1] = const_cast<uint8_t*>(frame_buffer->DataU());
+  pic.img.plane[2] = const_cast<uint8_t*>(frame_buffer->DataV());
+  pic.i_pts = i_frame;
+
+  int i_nal = 0;
+  pic_out = pic;
+  nal = nullptr;
+  int i_frame_size = x264_encoder_encode(encoder_, &nal, &i_nal, &pic, &pic_out);
+  if (i_frame_size < 0)
+  {
+	  /*WEBRTC_TRACE(webrtc::kTraceError, webrtc::kTraceVideoCoding, -1,
+					  "H264EncoderImpl::Encode() fails to encode %d",
+					  i_frame_size);*/
+	  x264_encoder_close(encoder_);
+	  x264_picture_clean(&pic);
+	  encoder_ = NULL;
+	  return WEBRTC_VIDEO_CODEC_ERROR;
+  }
+  +#elif USEOPENH264
+
   // EncodeFrame input.
   SSourcePicture picture;
   memset(&picture, 0, sizeof(SSourcePicture));
@@ -353,7 +514,7 @@ int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
   memset(&info, 0, sizeof(SFrameBSInfo));
 
   // Encode!
-  int enc_ret = openh264_encoder_->EncodeFrame(&picture, &info);
+  int enc_ret = encoder_->EncodeFrame(&picture, &info);
   if (enc_ret != 0) {
     LOG(LS_ERROR) << "OpenH264 frame encoding failed, EncodeFrame returned "
                   << enc_ret << ".";
@@ -361,6 +522,8 @@ int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
     return WEBRTC_VIDEO_CODEC_ERROR;
   }
 
+#endif
+
   encoded_image_._encodedWidth = frame_buffer->width();
   encoded_image_._encodedHeight = frame_buffer->height();
   encoded_image_._timeStamp = input_frame.timestamp();
@@ -370,20 +533,109 @@ int32_t H264EncoderImpl::Encode(const VideoFrame& input_frame,
   encoded_image_.content_type_ = (mode_ == kScreensharing)
                                      ? VideoContentType::SCREENSHARE
                                      : VideoContentType::UNSPECIFIED;
+
+#if USEOPENH264
   encoded_image_._frameType = ConvertToVideoFrameType(info.eFrameType);
+#endif
 
   // Split encoded image up into fragments. This also updates |encoded_image_|.
   RTPFragmentationHeader frag_header;
+
+#if USEOPENH264
   RtpFragmentize(&encoded_image_, &encoded_image_buffer_, *frame_buffer, &info,
                  &frag_header);
 
+#elif USEX264	
+  if (i_frame_size)
+  {
+	  if (i_nal == 0) {
+		  return WEBRTC_VIDEO_CODEC_OK;
+
+	  }
+	  frag_header.VerifyAndAllocateFragmentationHeader(i_nal);
+
+	  encoded_image_._length = 0;
+
+	  uint32_t totalNaluIndex = 0;
+	  for (int nal_index = 0; nal_index < i_nal; nal_index++)
+	  {
+		  uint32_t currentNaluSize = 0;
+		  currentNaluSize = nal[nal_index].i_payload - 4; //i_frame_size
+		  memcpy(encoded_image_._buffer + encoded_image_._length, nal[nal_index].p_payload + 4, currentNaluSize);//will add start code automatically
+		  encoded_image_._length += currentNaluSize;
+
+		  /*WEBRTC_TRACE(webrtc::kTraceApiCall, webrtc::kTraceVideoCoding, -1,
+							  "H264EncoderImpl::Encode() nal_type %d, length:%d",
+							  nal[nal_index].i_type, encoded_image_._length);*/
+
+		  frag_header.fragmentationOffset[totalNaluIndex] = encoded_image_._length - currentNaluSize;
+		  frag_header.fragmentationLength[totalNaluIndex] = currentNaluSize;
+		  frag_header.fragmentationPlType[totalNaluIndex] = nal[nal_index].i_type;
+		  frag_header.fragmentationTimeDiff[totalNaluIndex] = 0;
+		  totalNaluIndex++;
+	  }
+  }
+  i_frame++;
+#endif
+
+#if !USEOPENH264 && !USEX264
+  uint8_t * p_nal = const_cast<uint8_t*>(frame_buffer->DataY());
+  int encoded_buffer_size = frame_buffer->encoded_length();
+  size_t i_nal;
+
+  std::vector<H264::NaluIndex> NALUidx;
+
+  if ((p_nal[4] & 0x0F) != 0x07) {
+	  NALUidx = H264::FindNaluIndices(p_nal, encoded_buffer_size);
+	  if (NALUidx.size() < 1)
+			return WEBRTC_VIDEO_CODEC_OK;
+	  
+	  i_nal = NALUidx.size();
+	  if (i_nal == 1)
+	  {
+		  NALUidx[0].payload_size = encoded_buffer_size - NALUidx[0].payload_start_offset;
+	  }
+	  else for (int i = 0; i < i_nal; i++)
+	  {
+		  NALUidx[i].payload_size = i + 1 >= i_nal ? encoded_buffer_size - NALUidx[i].payload_start_offset : NALUidx[i + 1].start_offset - NALUidx[i].payload_start_offset;
+	  }
+  }
+  else {
+	  NALUidx = H264::FindNaluIndices(p_nal, 200); 
+	  i_nal = NALUidx.size();
+	  if (i_nal > 2)
+		  NALUidx[i_nal - 1].payload_size = encoded_buffer_size - NALUidx[i_nal - 1].payload_start_offset;
+  }
+
+  frag_header.VerifyAndAllocateFragmentationHeader(i_nal);
+  encoded_image_._length = 0;
+
+  uint32_t totalNaluIndex = 0;
+  for (int nal_index = 0; nal_index < i_nal; nal_index++)
+  {
+	  size_t currentNaluSize = 0;
+	  currentNaluSize = NALUidx[nal_index].payload_size; //i_frame_size
+	  memcpy(encoded_image_._buffer + encoded_image_._length, &p_nal[NALUidx[nal_index].payload_start_offset], currentNaluSize);//will add start code automatically
+	  encoded_image_._length += currentNaluSize;
+
+	  frag_header.fragmentationOffset[totalNaluIndex] = encoded_image_._length - currentNaluSize;
+	  frag_header.fragmentationLength[totalNaluIndex] = currentNaluSize;
+	  frag_header.fragmentationPlType[totalNaluIndex] = H264::ParseNaluType(p_nal[NALUidx[nal_index].start_offset]);
+	  frag_header.fragmentationTimeDiff[totalNaluIndex] = 0;
+	  totalNaluIndex++;
+  }
+  //encoded_image_._length = encoded_buffer_size;
+
+  //memcpy(encoded_image_._buffer, p_encoded_buffer, encoded_buffer_size);
+
+#endif
+
   // Encoder can skip frames to save bandwidth in which case
   // |encoded_image_._length| == 0.
   if (encoded_image_._length > 0) {
+
+#if USEOPENH264
     // Parse QP.
     h264_bitstream_parser_.ParseBitstream(encoded_image_._buffer,
                                           encoded_image_._length);
     h264_bitstream_parser_.GetLastSliceQp(&encoded_image_.qp_);
+#endif
 
     // Deliver encoded image.
     CodecSpecificInfo codec_specific;
@@ -400,18 +652,24 @@ const char* H264EncoderImpl::ImplementationName() const {
 }
 
 bool H264EncoderImpl::IsInitialized() const {
-  return openh264_encoder_ != nullptr;
+#if USEOPENH264 || USEX264
+	return encoder_ != nullptr;
+#else
+	return true;
+#endif
 }
 
+#if USEOPENH264
+
 // Initialization parameters.
 // There are two ways to initialize. There is SEncParamBase (cleared with
 // memset(&p, 0, sizeof(SEncParamBase)) used in Initialize, and SEncParamExt
 // which is a superset of SEncParamBase (cleared with GetDefaultParams) used
 // in InitializeExt.
 SEncParamExt H264EncoderImpl::CreateEncoderParams() const {
-  RTC_DCHECK(openh264_encoder_);
+  RTC_DCHECK(encoder_);
   SEncParamExt encoder_params;
-  openh264_encoder_->GetDefaultParams(&encoder_params);
+  encoder_->GetDefaultParams(&encoder_params);
   if (mode_ == kRealtimeVideo) {
     encoder_params.iUsageType = CAMERA_VIDEO_REAL_TIME;
   } else if (mode_ == kScreensharing) {
@@ -472,6 +730,8 @@ SEncParamExt H264EncoderImpl::CreateEncoderParams() const {
   return encoder_params;
 }
 
+#endif
+
 void H264EncoderImpl::ReportInit() {
   if (has_reported_init_)
     return;
diff --git a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
index a455259..8cd59c3 100644
--- a/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
+++ b/webrtc/modules/video_coding/codecs/h264/h264_encoder_impl.h
@@ -19,9 +19,24 @@
 #include "webrtc/modules/video_coding/codecs/h264/include/h264.h"
 #include "webrtc/modules/video_coding/utility/quality_scaler.h"
 
-#include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
+//#define USEOPENH264 1
+//#define USEX264 1
 
+// #include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
+#if USEOPENH264
+ #include "third_party/openh264/src/codec/api/svc/codec_app_def.h"
 class ISVCEncoder;
+#elif USEX264
+//#define __STDC_CONSTANT_MACROS
+//x264 and ffmpeg headers
+extern "C"
+ {
+	+#include "third_party/x264/x264.h"
+		+ #include "third_party/ffmpeg/libavcodec/avcodec.h"
+		+ #include "third_party/ffmpeg/libavformat/avformat.h"
+		+ #include "third_party/ffmpeg/libswscale/swscale.h"
+		+ }
+#endif
 
 namespace webrtc {
 
@@ -68,14 +83,25 @@ class H264EncoderImpl : public H264Encoder {
 
  private:
   bool IsInitialized() const;
+#if USEOPENH264
   SEncParamExt CreateEncoderParams() const;
+#endif
 
   webrtc::H264BitstreamParser h264_bitstream_parser_;
   // Reports statistics with histograms.
   void ReportInit();
   void ReportError();
 
-  ISVCEncoder* openh264_encoder_;
+#if USEOPENH264
+  ISVCEncoder* encoder_;
+#elif  USEX264
+  //x264
+  x264_picture_t pic;
+  x264_picture_t pic_out;
+  x264_t *encoder_;
+  int i_frame = 0;
+  x264_nal_t *nal;
+#endif
   // Settings that are used by this encoder.
   int width_;
   int height_;
@@ -89,7 +115,9 @@ class H264EncoderImpl : public H264Encoder {
   H264PacketizationMode packetization_mode_;
 
   size_t max_payload_size_;
+#if USEOPENH264 || USEX264
   int32_t number_of_cores_;
+#endif
 
   EncodedImage encoded_image_;
   std::unique_ptr<uint8_t[]> encoded_image_buffer_;
diff --git a/webrtc/modules/video_coding/video_sender.cc b/webrtc/modules/video_coding/video_sender.cc
index 0b54d13..6f958fa 100644
--- a/webrtc/modules/video_coding/video_sender.cc
+++ b/webrtc/modules/video_coding/video_sender.cc
@@ -308,6 +308,7 @@ int32_t VideoSender::AddVideoFrame(const VideoFrame& videoFrame,
   if (_encoder == nullptr)
     return VCM_UNINITIALIZED;
   SetEncoderParameters(encoder_params, encoder_has_internal_source);
+#if 0
   if (_mediaOpt.DropFrame()) {
     LOG(LS_VERBOSE) << "Drop Frame "
                     << "target bitrate "
@@ -318,6 +319,7 @@ int32_t VideoSender::AddVideoFrame(const VideoFrame& videoFrame,
     post_encode_callback_->OnDroppedFrame();
     return VCM_OK;
   }
+#endif
   // TODO(pbos): Make sure setting send codec is synchronized with video
   // processing so frame size always matches.
   if (!_codecDataBase.MatchesCurrentResolution(videoFrame.width(),
diff --git a/webrtc/video/video_loopback.cc b/webrtc/video/video_loopback.cc
index ec206a8..ed6e011 100644
--- a/webrtc/video/video_loopback.cc
+++ b/webrtc/video/video_loopback.cc
@@ -67,7 +67,7 @@ int NumTemporalLayers() {
 }
 
 // Flags common with screenshare loopback, with equal default values.
-DEFINE_string(codec, "VP8", "Video codec to use.");
+DEFINE_string(codec, "H264", "Video codec to use.");
 std::string Codec() {
   return static_cast<std::string>(FLAGS_codec);
 }
@@ -286,7 +286,7 @@ void Loopback() {
   }
 }
 }  // namespace webrtc
-
+#if 1
 int main(int argc, char* argv[]) {
   ::testing::InitGoogleTest(&argc, argv);
   google::ParseCommandLineFlags(&argc, &argv, true);
@@ -295,3 +295,4 @@ int main(int argc, char* argv[]) {
   webrtc::test::RunTest(webrtc::Loopback);
   return 0;
 }
+#endif
-- 
2.9.2.windows.1

