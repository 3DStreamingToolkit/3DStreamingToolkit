//
// Generated by NVIDIA NVVM Compiler
// Compiler built on Fri Jul 25 19:36:16 2014 (1406288176)
// Cuda compilation tools, release 6.5, V6.5.13
//

.version 4.1
.target sm_30
.address_size 64

.const .align 4 .u32 constAlpha;
.const .align 4 .b8 constHueColorSpaceMat[36];

.visible .func _Z7YUV2RGBPjPfS0_S0_(
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_0,
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_1,
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_2,
	.param .b64 _Z7YUV2RGBPjPfS0_S0__param_3
)
{
	.reg .s32 	%r<4>;
	.reg .f32 	%f<24>;
	.reg .s64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z7YUV2RGBPjPfS0_S0__param_0];
	ld.param.u64 	%rd2, [_Z7YUV2RGBPjPfS0_S0__param_1];
	ld.param.u64 	%rd3, [_Z7YUV2RGBPjPfS0_S0__param_2];
	ld.param.u64 	%rd4, [_Z7YUV2RGBPjPfS0_S0__param_3];
	ld.u32 	%r1, [%rd1];
	cvt.rn.f32.u32	%f1, %r1;
	ld.u32 	%r2, [%rd1+4];
	cvt.rn.f32.s32	%f2, %r2;
	add.f32 	%f3, %f2, 0fC4000000;
	ld.u32 	%r3, [%rd1+8];
	cvt.rn.f32.s32	%f4, %r3;
	add.f32 	%f5, %f4, 0fC4000000;
	ld.const.f32 	%f6, [constHueColorSpaceMat];
	ld.const.f32 	%f7, [constHueColorSpaceMat+4];
	mul.f32 	%f8, %f3, %f7;
	fma.rn.f32 	%f9, %f1, %f6, %f8;
	ld.const.f32 	%f10, [constHueColorSpaceMat+8];
	fma.rn.f32 	%f11, %f5, %f10, %f9;
	st.f32 	[%rd2], %f11;
	ld.const.f32 	%f12, [constHueColorSpaceMat+12];
	ld.const.f32 	%f13, [constHueColorSpaceMat+16];
	mul.f32 	%f14, %f3, %f13;
	fma.rn.f32 	%f15, %f1, %f12, %f14;
	ld.const.f32 	%f16, [constHueColorSpaceMat+20];
	fma.rn.f32 	%f17, %f5, %f16, %f15;
	st.f32 	[%rd3], %f17;
	ld.const.f32 	%f18, [constHueColorSpaceMat+24];
	ld.const.f32 	%f19, [constHueColorSpaceMat+28];
	mul.f32 	%f20, %f3, %f19;
	fma.rn.f32 	%f21, %f1, %f18, %f20;
	ld.const.f32 	%f22, [constHueColorSpaceMat+32];
	fma.rn.f32 	%f23, %f5, %f22, %f21;
	st.f32 	[%rd4], %f23;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z13RGBAPACK_8bitfffj(
	.param .b32 _Z13RGBAPACK_8bitfffj_param_0,
	.param .b32 _Z13RGBAPACK_8bitfffj_param_1,
	.param .b32 _Z13RGBAPACK_8bitfffj_param_2,
	.param .b32 _Z13RGBAPACK_8bitfffj_param_3
)
{
	.reg .s32 	%r<10>;
	.reg .f32 	%f<12>;


	ld.param.f32 	%f1, [_Z13RGBAPACK_8bitfffj_param_0];
	ld.param.f32 	%f2, [_Z13RGBAPACK_8bitfffj_param_1];
	ld.param.f32 	%f3, [_Z13RGBAPACK_8bitfffj_param_2];
	ld.param.u32 	%r1, [_Z13RGBAPACK_8bitfffj_param_3];
	mov.f32 	%f4, 0f00000000;
	max.f32 	%f5, %f1, %f4;
	mov.f32 	%f6, 0f437F0000;
	min.f32 	%f7, %f5, %f6;
	max.f32 	%f8, %f2, %f4;
	min.f32 	%f9, %f8, %f6;
	max.f32 	%f10, %f3, %f4;
	min.f32 	%f11, %f10, %f6;
	cvt.rzi.u32.f32	%r2, %f11;
	cvt.rzi.u32.f32	%r3, %f9;
	shl.b32 	%r4, %r3, 8;
	cvt.rzi.u32.f32	%r5, %f7;
	shl.b32 	%r6, %r5, 16;
	or.b32  	%r7, %r2, %r1;
	or.b32  	%r8, %r7, %r4;
	or.b32  	%r9, %r8, %r6;
	st.param.b32	[func_retval0+0], %r9;
	ret;
}

.visible .func  (.param .b32 func_retval0) _Z14RGBAPACK_10bitfffj(
	.param .b32 _Z14RGBAPACK_10bitfffj_param_0,
	.param .b32 _Z14RGBAPACK_10bitfffj_param_1,
	.param .b32 _Z14RGBAPACK_10bitfffj_param_2,
	.param .b32 _Z14RGBAPACK_10bitfffj_param_3
)
{
	.reg .s32 	%r<13>;
	.reg .f32 	%f<12>;


	ld.param.f32 	%f1, [_Z14RGBAPACK_10bitfffj_param_0];
	ld.param.f32 	%f2, [_Z14RGBAPACK_10bitfffj_param_1];
	ld.param.f32 	%f3, [_Z14RGBAPACK_10bitfffj_param_2];
	ld.param.u32 	%r1, [_Z14RGBAPACK_10bitfffj_param_3];
	mov.f32 	%f4, 0f00000000;
	max.f32 	%f5, %f1, %f4;
	mov.f32 	%f6, 0f447FC000;
	min.f32 	%f7, %f5, %f6;
	max.f32 	%f8, %f2, %f4;
	min.f32 	%f9, %f8, %f6;
	max.f32 	%f10, %f3, %f4;
	min.f32 	%f11, %f10, %f6;
	cvt.rzi.u32.f32	%r2, %f11;
	shr.u32 	%r3, %r2, 2;
	cvt.rzi.u32.f32	%r4, %f9;
	shl.b32 	%r5, %r4, 6;
	and.b32  	%r6, %r5, -256;
	cvt.rzi.u32.f32	%r7, %f7;
	shl.b32 	%r8, %r7, 14;
	and.b32  	%r9, %r8, -65536;
	or.b32  	%r10, %r3, %r1;
	or.b32  	%r11, %r10, %r6;
	or.b32  	%r12, %r11, %r9;
	st.param.b32	[func_retval0+0], %r12;
	ret;
}

.visible .entry Passthru_drvapi(
	.param .u64 Passthru_drvapi_param_0,
	.param .u64 Passthru_drvapi_param_1,
	.param .u64 Passthru_drvapi_param_2,
	.param .u64 Passthru_drvapi_param_3,
	.param .u32 Passthru_drvapi_param_4,
	.param .u32 Passthru_drvapi_param_5
)
{
	.reg .pred 	%p<4>;
	.reg .s16 	%rs<3>;
	.reg .s32 	%r<32>;
	.reg .f32 	%f<9>;
	.reg .s64 	%rd<16>;


	ld.param.u64 	%rd1, [Passthru_drvapi_param_0];
	ld.param.u64 	%rd2, [Passthru_drvapi_param_1];
	ld.param.u64 	%rd3, [Passthru_drvapi_param_2];
	ld.param.u64 	%rd4, [Passthru_drvapi_param_3];
	ld.param.u32 	%r3, [Passthru_drvapi_param_4];
	ld.param.u32 	%r4, [Passthru_drvapi_param_5];
	mov.u32 	%r5, %ctaid.x;
	shl.b32 	%r6, %r5, 1;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.x;
	shl.b32 	%r9, %r8, 1;
	mad.lo.s32 	%r1, %r6, %r7, %r9;
	mov.u32 	%r10, %ntid.y;
	mov.u32 	%r11, %ctaid.y;
	mov.u32 	%r12, %tid.y;
	mad.lo.s32 	%r2, %r10, %r11, %r12;
	setp.lt.u32	%p1, %r1, %r3;
	setp.lt.u32	%p2, %r2, %r4;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB3_2;
	bra.uni 	BB3_1;

BB3_1:
	cvta.to.global.u64 	%rd5, %rd3;
	cvta.to.global.u64 	%rd6, %rd1;
	shr.u64 	%rd7, %rd4, 2;
	cvt.u32.u64	%r13, %rd7;
	cvt.u32.u64	%r14, %rd2;
	mad.lo.s32 	%r15, %r2, %r14, %r1;
	cvt.u64.u32	%rd8, %r15;
	add.s64 	%rd9, %rd6, %rd8;
	add.s32 	%r16, %r15, 1;
	cvt.u64.u32	%rd10, %r16;
	add.s64 	%rd11, %rd6, %rd10;
	ld.global.u8 	%rs1, [%rd9];
	cvt.rn.f32.u16	%f1, %rs1;
	ld.global.u8 	%rs2, [%rd11];
	cvt.rn.f32.u16	%f2, %rs2;
	mov.f32 	%f3, 0f00000000;
	max.f32 	%f4, %f1, %f3;
	mov.f32 	%f5, 0f437F0000;
	min.f32 	%f6, %f4, %f5;
	cvt.rzi.u32.f32	%r17, %f6;
	shl.b32 	%r18, %r17, 8;
	shl.b32 	%r19, %r17, 16;
	ld.const.u32 	%r20, [constAlpha];
	or.b32  	%r21, %r17, %r20;
	or.b32  	%r22, %r21, %r18;
	or.b32  	%r23, %r22, %r19;
	mad.lo.s32 	%r24, %r2, %r13, %r1;
	mul.wide.u32 	%rd12, %r24, 4;
	add.s64 	%rd13, %rd5, %rd12;
	st.global.u32 	[%rd13], %r23;
	max.f32 	%f7, %f2, %f3;
	min.f32 	%f8, %f7, %f5;
	cvt.rzi.u32.f32	%r25, %f8;
	shl.b32 	%r26, %r25, 8;
	shl.b32 	%r27, %r25, 16;
	or.b32  	%r28, %r25, %r20;
	or.b32  	%r29, %r28, %r26;
	or.b32  	%r30, %r29, %r27;
	add.s32 	%r31, %r24, 1;
	mul.wide.u32 	%rd14, %r31, 4;
	add.s64 	%rd15, %rd5, %rd14;
	st.global.u32 	[%rd15], %r30;

BB3_2:
	ret;
}

.visible .entry NV12ToARGB_drvapi(
	.param .u64 NV12ToARGB_drvapi_param_0,
	.param .u64 NV12ToARGB_drvapi_param_1,
	.param .u64 NV12ToARGB_drvapi_param_2,
	.param .u64 NV12ToARGB_drvapi_param_3,
	.param .u32 NV12ToARGB_drvapi_param_4,
	.param .u32 NV12ToARGB_drvapi_param_5
)
{
	.reg .pred 	%p<6>;
	.reg .s32 	%r<98>;
	.reg .f32 	%f<48>;
	.reg .s64 	%rd<24>;


	ld.param.u64 	%rd3, [NV12ToARGB_drvapi_param_0];
	ld.param.u64 	%rd4, [NV12ToARGB_drvapi_param_2];
	ld.param.u64 	%rd5, [NV12ToARGB_drvapi_param_3];
	ld.param.u32 	%r21, [NV12ToARGB_drvapi_param_4];
	ld.param.u32 	%r20, [NV12ToARGB_drvapi_param_5];
	ld.param.u32 	%r1, [NV12ToARGB_drvapi_param_1];
	mov.u32 	%r22, %ctaid.x;
	shl.b32 	%r23, %r22, 1;
	mov.u32 	%r24, %ntid.x;
	mov.u32 	%r25, %tid.x;
	shl.b32 	%r26, %r25, 1;
	mad.lo.s32 	%r2, %r23, %r24, %r26;
	mov.u32 	%r27, %ntid.y;
	mov.u32 	%r28, %ctaid.y;
	mov.u32 	%r29, %tid.y;
	mad.lo.s32 	%r3, %r27, %r28, %r29;
	setp.lt.u32	%p1, %r2, %r21;
	setp.lt.u32	%p2, %r3, %r20;
	and.pred  	%p3, %p1, %p2;
	@!%p3 bra 	BB4_7;
	bra.uni 	BB4_1;

BB4_1:
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd6, %rd3;
	shr.u64 	%rd7, %rd5, 2;
	cvt.u32.u64	%r4, %rd7;
	mad.lo.s32 	%r30, %r3, %r1, %r2;
	cvt.u64.u32	%rd8, %r30;
	add.s64 	%rd9, %rd6, %rd8;
	ld.global.u8 	%r31, [%rd9];
	shl.b32 	%r5, %r31, 2;
	add.s32 	%r32, %r30, 1;
	cvt.u64.u32	%rd10, %r32;
	add.s64 	%rd11, %rd6, %rd10;
	ld.global.u8 	%r33, [%rd11];
	shl.b32 	%r6, %r33, 2;
	shr.s32 	%r7, %r3, 1;
	add.s32 	%r34, %r7, %r20;
	mad.lo.s32 	%r35, %r34, %r1, %r2;
	cvt.u64.u32	%rd12, %r35;
	add.s64 	%rd13, %rd6, %rd12;
	ld.global.u8 	%r94, [%rd13];
	add.s32 	%r36, %r35, 1;
	cvt.u64.u32	%rd14, %r36;
	add.s64 	%rd2, %rd6, %rd14;
	and.b32  	%r37, %r3, 1;
	setp.eq.b32	%p4, %r37, 1;
	@!%p4 bra 	BB4_5;
	bra.uni 	BB4_2;

BB4_2:
	ld.global.u8 	%r95, [%rd2];
	shr.u32 	%r38, %r20, 1;
	add.s32 	%r39, %r38, -1;
	setp.ge.u32	%p5, %r7, %r39;
	@%p5 bra 	BB4_4;

	add.s32 	%r40, %r20, %r7;
	add.s32 	%r41, %r40, 1;
	mad.lo.s32 	%r42, %r41, %r1, %r2;
	cvt.u64.u32	%rd16, %r42;
	add.s64 	%rd17, %rd6, %rd16;
	ld.global.u8 	%r43, [%rd17];
	add.s32 	%r44, %r94, %r43;
	add.s32 	%r45, %r44, 1;
	shr.u32 	%r94, %r45, 1;
	add.s32 	%r46, %r42, 1;
	cvt.u64.u32	%rd18, %r46;
	add.s64 	%rd19, %rd6, %rd18;
	ld.global.u8 	%r47, [%rd19];
	add.s32 	%r48, %r95, %r47;
	add.s32 	%r49, %r48, 1;
	shr.u32 	%r95, %r49, 1;

BB4_4:
	shl.b32 	%r50, %r94, 12;
	or.b32  	%r51, %r50, %r5;
	shl.b32 	%r52, %r95, 22;
	or.b32  	%r97, %r51, %r52;
	or.b32  	%r53, %r50, %r6;
	or.b32  	%r96, %r53, %r52;
	bra.uni 	BB4_6;

BB4_5:
	shl.b32 	%r54, %r94, 12;
	ld.global.u8 	%r55, [%rd2];
	shl.b32 	%r56, %r55, 22;
	or.b32  	%r57, %r54, %r5;
	or.b32  	%r97, %r57, %r56;
	or.b32  	%r58, %r54, %r6;
	or.b32  	%r96, %r58, %r56;

BB4_6:
	bfe.u32 	%r59, %r97, 10, 10;
	bfe.u32 	%r60, %r97, 20, 10;
	bfe.u32 	%r61, %r96, 10, 10;
	bfe.u32 	%r62, %r96, 20, 10;
	and.b32  	%r63, %r97, 1023;
	cvt.rn.f32.u32	%f1, %r63;
	add.s32 	%r64, %r59, -512;
	cvt.rn.f32.s32	%f2, %r64;
	add.s32 	%r65, %r60, -512;
	cvt.rn.f32.s32	%f3, %r65;
	ld.const.f32 	%f4, [constHueColorSpaceMat];
	ld.const.f32 	%f5, [constHueColorSpaceMat+4];
	mul.f32 	%f6, %f2, %f5;
	fma.rn.f32 	%f7, %f1, %f4, %f6;
	ld.const.f32 	%f8, [constHueColorSpaceMat+8];
	fma.rn.f32 	%f9, %f3, %f8, %f7;
	ld.const.f32 	%f10, [constHueColorSpaceMat+12];
	ld.const.f32 	%f11, [constHueColorSpaceMat+16];
	mul.f32 	%f12, %f2, %f11;
	fma.rn.f32 	%f13, %f1, %f10, %f12;
	ld.const.f32 	%f14, [constHueColorSpaceMat+20];
	fma.rn.f32 	%f15, %f3, %f14, %f13;
	ld.const.f32 	%f16, [constHueColorSpaceMat+24];
	ld.const.f32 	%f17, [constHueColorSpaceMat+28];
	mul.f32 	%f18, %f2, %f17;
	fma.rn.f32 	%f19, %f1, %f16, %f18;
	ld.const.f32 	%f20, [constHueColorSpaceMat+32];
	fma.rn.f32 	%f21, %f3, %f20, %f19;
	and.b32  	%r66, %r96, 1023;
	cvt.rn.f32.u32	%f22, %r66;
	add.s32 	%r67, %r61, -512;
	cvt.rn.f32.s32	%f23, %r67;
	add.s32 	%r68, %r62, -512;
	cvt.rn.f32.s32	%f24, %r68;
	mul.f32 	%f25, %f23, %f5;
	fma.rn.f32 	%f26, %f22, %f4, %f25;
	fma.rn.f32 	%f27, %f24, %f8, %f26;
	mul.f32 	%f28, %f23, %f11;
	fma.rn.f32 	%f29, %f22, %f10, %f28;
	fma.rn.f32 	%f30, %f24, %f14, %f29;
	mul.f32 	%f31, %f23, %f17;
	fma.rn.f32 	%f32, %f22, %f16, %f31;
	fma.rn.f32 	%f33, %f24, %f20, %f32;
	mov.f32 	%f34, 0f00000000;
	max.f32 	%f35, %f9, %f34;
	mov.f32 	%f36, 0f447FC000;
	min.f32 	%f37, %f35, %f36;
	max.f32 	%f38, %f15, %f34;
	min.f32 	%f39, %f38, %f36;
	max.f32 	%f40, %f21, %f34;
	min.f32 	%f41, %f40, %f36;
	cvt.rzi.u32.f32	%r69, %f41;
	shr.u32 	%r70, %r69, 2;
	cvt.rzi.u32.f32	%r71, %f39;
	shl.b32 	%r72, %r71, 6;
	and.b32  	%r73, %r72, -256;
	cvt.rzi.u32.f32	%r74, %f37;
	shl.b32 	%r75, %r74, 14;
	and.b32  	%r76, %r75, -65536;
	ld.const.u32 	%r77, [constAlpha];
	or.b32  	%r78, %r70, %r77;
	or.b32  	%r79, %r78, %r73;
	or.b32  	%r80, %r79, %r76;
	mad.lo.s32 	%r81, %r3, %r4, %r2;
	mul.wide.u32 	%rd20, %r81, 4;
	add.s64 	%rd21, %rd1, %rd20;
	st.global.u32 	[%rd21], %r80;
	max.f32 	%f42, %f27, %f34;
	min.f32 	%f43, %f42, %f36;
	max.f32 	%f44, %f30, %f34;
	min.f32 	%f45, %f44, %f36;
	max.f32 	%f46, %f33, %f34;
	min.f32 	%f47, %f46, %f36;
	cvt.rzi.u32.f32	%r82, %f47;
	shr.u32 	%r83, %r82, 2;
	cvt.rzi.u32.f32	%r84, %f45;
	shl.b32 	%r85, %r84, 6;
	and.b32  	%r86, %r85, -256;
	cvt.rzi.u32.f32	%r87, %f43;
	shl.b32 	%r88, %r87, 14;
	and.b32  	%r89, %r88, -65536;
	or.b32  	%r90, %r83, %r77;
	or.b32  	%r91, %r90, %r86;
	or.b32  	%r92, %r91, %r89;
	add.s32 	%r93, %r81, 1;
	mul.wide.u32 	%rd22, %r93, 4;
	add.s64 	%rd23, %rd1, %rd22;
	st.global.u32 	[%rd23], %r92;

BB4_7:
	ret;
}


